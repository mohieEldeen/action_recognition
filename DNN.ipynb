{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCF101 Training on normal DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries we need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import re\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import *\n",
    "from  models.FFNNModel import FFNNModel\n",
    "from models.trainFFNN import trainNN\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the type of device that we will work on\n",
    "#device =  torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the names of the frames and thier classes\n",
    "train_frames = pd.read_csv('frames_train_1.csv') \n",
    "test_frames = pd.read_csv('frames_test_1.csv') \n",
    "\n",
    "train_videos = pd.read_csv('video_train_1.csv') \n",
    "test_videos = pd.read_csv('video_test_1_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c01.avi_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c01.avi_2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c01.avi_3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c01.avi_4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c01.avi_5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  class\n",
       "0  v_ApplyEyeMakeup_g08_c01.avi_1.jpg      1\n",
       "1  v_ApplyEyeMakeup_g08_c01.avi_2.jpg      1\n",
       "2  v_ApplyEyeMakeup_g08_c01.avi_3.jpg      1\n",
       "3  v_ApplyEyeMakeup_g08_c01.avi_4.jpg      1\n",
       "4  v_ApplyEyeMakeup_g08_c01.avi_5.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  class\n",
       "0  v_ApplyEyeMakeup_g01_c01.avi_1.jpg      1\n",
       "1  v_ApplyEyeMakeup_g01_c01.avi_2.jpg      1\n",
       "2  v_ApplyEyeMakeup_g01_c01.avi_3.jpg      1\n",
       "3  v_ApplyEyeMakeup_g01_c01.avi_4.jpg      1\n",
       "4  v_ApplyEyeMakeup_g01_c01.avi_5.jpg      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>num_frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c01.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c02.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c03.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c04.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_ApplyEyeMakeup_g08_c05.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  class  num_frames\n",
       "0  v_ApplyEyeMakeup_g08_c01.avi      1          24\n",
       "1  v_ApplyEyeMakeup_g08_c02.avi      1          23\n",
       "2  v_ApplyEyeMakeup_g08_c03.avi      1          29\n",
       "3  v_ApplyEyeMakeup_g08_c04.avi      1          44\n",
       "4  v_ApplyEyeMakeup_g08_c05.avi      1          55"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c02.avi</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c03.avi</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c04.avi</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c05.avi</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  num_frames  class\n",
       "0  v_ApplyEyeMakeup_g01_c01.avi          32      1\n",
       "1  v_ApplyEyeMakeup_g01_c02.avi          24      1\n",
       "2  v_ApplyEyeMakeup_g01_c03.avi          51      1\n",
       "3  v_ApplyEyeMakeup_g01_c04.avi          47      1\n",
       "4  v_ApplyEyeMakeup_g01_c05.avi          59      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *First we will work on normal FFNNs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convert2Gray (object):\n",
    "    \"\"\"Conver the image from RGB to Gray.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "\n",
    "        return cv2.cvtColor(image , cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "\n",
    "class Resize(object):\n",
    "    \"\"\"Resize the image to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple): Desired output size of the image. should be like (new_h , new_w)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        \n",
    "        assert len(output_size) == 2 , \"the output size must be of lenght 2 >>> (new_h , new_w)\"\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        new_h , new_w = self.output_size\n",
    "\n",
    "        image = cv2.resize(src = image, dsize = (new_w,new_h))\n",
    "\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class Scale(object):\n",
    "    \"\"\"Rescale the image pixel values to be between zero and one.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple): Desired output size of the image. should be like (new_h , new_w)\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "\n",
    "        return image / 255\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Reshaping the ndarrays then Converting them to Tensors to be ready to fed to a FFNN.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        \n",
    "        #Reshaping numpy image: H x W x C to torch vector: C*H*W\n",
    "        \n",
    "        return torch.from_numpy(image).flatten(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation/train ratio\n",
    "validation_ratio = 0.1\n",
    "\n",
    "Image_output_size = (75,75) #output size of the images\n",
    "\n",
    "train_batch_size = 32\n",
    "val_batch_size = 16\n",
    "\n",
    "#splitting the train_videos into train and validation frames\n",
    "#the output from the function below is a data frame that holds the names of the *frames* and thier labels for train and validation\n",
    "tr_frames , val_frames = trainValSpliteFromVideoNames(validation_ratio , train_videos) \n",
    "\n",
    "#the transform steps that we will execute on the images\n",
    "transform  =torchvision.transforms.Compose([\n",
    "    #Convert2Gray() , #conver the RGB images to gray\n",
    "    Resize(Image_output_size), #resizing the images\n",
    "    ToTensor(), #transforming the images to Tensor form on the available device (GPU or CPU)\n",
    "    Scale()   #scaling the images pixel values to be in range zero to one\n",
    "    \n",
    "])\n",
    "\n",
    "#intializing the image generator\n",
    "train_gen = UCF101DatasetFrames(frame_name =tr_frames, img_dir ='Train_Frames_1/', shuffle = True , transform = transform)\n",
    "\n",
    "#intializing the validation image generator\n",
    "val_gen = UCF101DatasetFrames(frame_name =val_frames, img_dir ='Train_Frames_1/', shuffle = True , transform = transform)\n",
    "\n",
    "#intializing the train batches loader !!!\n",
    "train_loader = DataLoader(train_gen , batch_size= train_batch_size , shuffle = True)\n",
    "\n",
    "#intializing the val batches loader !!!\n",
    "val_loader = DataLoader(val_gen , batch_size= val_batch_size , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = Image_output_size[0]*Image_output_size[1]*3 #the number of features that will enter the ff neural network\n",
    "output_features = 101 #the number of labels\n",
    "lr = 0.0001 #learning rate\n",
    "\n",
    "model = FFNNModel(input_features , output_features).to(device)   #intializing the model\n",
    "lossFunc = nn.NLLLoss().to(device) #the loss funstion to train on (Negative Likelihood loss since it's a classification task and the logits are log softmax)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr) #the optimization algorithm we use during training\n",
    "\n",
    "epochs = 2 #num of epoches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1] train_loss: 4.60254 train_acc: 12.50000 val_loss: 4.56147 val_acc: 0.00000\n",
      "[1, 10] train_loss: 4.63311 train_acc: 3.75000 val_loss: 4.66499 val_acc: 1.25000\n",
      "[1, 20] train_loss: 4.62450 train_acc: 1.56250 val_loss: 4.57361 val_acc: 0.62500\n",
      "[1, 30] train_loss: 4.56788 train_acc: 1.87500 val_loss: 4.57680 val_acc: 1.87500\n",
      "[1, 40] train_loss: 4.58229 train_acc: 2.81250 val_loss: 4.63122 val_acc: 3.12500\n",
      "[1, 50] train_loss: 4.47050 train_acc: 5.62500 val_loss: 4.49674 val_acc: 1.25000\n",
      "[1, 60] train_loss: 4.49726 train_acc: 6.25000 val_loss: 4.52229 val_acc: 3.75000\n",
      "[1, 70] train_loss: 4.52685 train_acc: 3.75000 val_loss: 4.51292 val_acc: 1.87500\n",
      "[1, 80] train_loss: 4.43903 train_acc: 4.06250 val_loss: 4.46979 val_acc: 1.87500\n",
      "[1, 90] train_loss: 4.43324 train_acc: 6.25000 val_loss: 4.43360 val_acc: 4.37500\n",
      "[1, 100] train_loss: 4.42952 train_acc: 4.68750 val_loss: 4.49474 val_acc: 3.12500\n",
      "[1, 110] train_loss: 4.40212 train_acc: 4.68750 val_loss: 4.39211 val_acc: 5.62500\n",
      "[1, 120] train_loss: 4.37529 train_acc: 5.93750 val_loss: 4.42126 val_acc: 6.87500\n",
      "[1, 130] train_loss: 4.34288 train_acc: 7.18750 val_loss: 4.46457 val_acc: 4.37500\n",
      "[1, 140] train_loss: 4.35135 train_acc: 7.81250 val_loss: 4.33335 val_acc: 9.37500\n",
      "[1, 150] train_loss: 4.33745 train_acc: 4.68750 val_loss: 4.44663 val_acc: 5.62500\n",
      "[1, 160] train_loss: 4.40112 train_acc: 4.37500 val_loss: 4.35218 val_acc: 8.12500\n",
      "[1, 170] train_loss: 4.26631 train_acc: 8.43750 val_loss: 4.34752 val_acc: 8.75000\n",
      "[1, 180] train_loss: 4.38153 train_acc: 4.68750 val_loss: 4.33663 val_acc: 4.37500\n",
      "[1, 190] train_loss: 4.22777 train_acc: 8.75000 val_loss: 4.15047 val_acc: 13.75000\n",
      "[1, 200] train_loss: 4.27071 train_acc: 7.18750 val_loss: 4.37418 val_acc: 10.00000\n",
      "[1, 210] train_loss: 4.35684 train_acc: 5.62500 val_loss: 4.29008 val_acc: 7.50000\n",
      "[1, 220] train_loss: 4.23565 train_acc: 8.43750 val_loss: 4.29805 val_acc: 5.00000\n",
      "[1, 230] train_loss: 4.23960 train_acc: 6.56250 val_loss: 4.23106 val_acc: 5.62500\n",
      "[1, 240] train_loss: 4.22573 train_acc: 7.50000 val_loss: 4.32702 val_acc: 2.50000\n",
      "[1, 250] train_loss: 4.27056 train_acc: 9.06250 val_loss: 4.22646 val_acc: 8.12500\n",
      "[1, 260] train_loss: 4.16068 train_acc: 8.12500 val_loss: 4.16030 val_acc: 8.75000\n",
      "[1, 270] train_loss: 4.21245 train_acc: 10.31250 val_loss: 4.22626 val_acc: 6.87500\n",
      "[1, 280] train_loss: 4.18436 train_acc: 7.50000 val_loss: 4.14483 val_acc: 9.37500\n",
      "[1, 290] train_loss: 4.20954 train_acc: 5.93750 val_loss: 4.20854 val_acc: 11.87500\n",
      "[1, 300] train_loss: 4.08671 train_acc: 10.93750 val_loss: 4.25916 val_acc: 6.25000\n",
      "[1, 310] train_loss: 4.17351 train_acc: 7.81250 val_loss: 4.20996 val_acc: 10.62500\n",
      "[1, 320] train_loss: 4.18174 train_acc: 10.00000 val_loss: 4.18757 val_acc: 7.50000\n",
      "[1, 330] train_loss: 4.04732 train_acc: 11.87500 val_loss: 4.10888 val_acc: 10.00000\n",
      "[1, 340] train_loss: 4.14245 train_acc: 8.43750 val_loss: 4.16386 val_acc: 6.87500\n",
      "[1, 350] train_loss: 3.98635 train_acc: 12.81250 val_loss: 3.96045 val_acc: 8.75000\n",
      "[1, 360] train_loss: 4.03810 train_acc: 9.37500 val_loss: 4.28069 val_acc: 6.25000\n",
      "[1, 370] train_loss: 4.16320 train_acc: 9.68750 val_loss: 4.18782 val_acc: 10.62500\n",
      "[1, 380] train_loss: 4.05751 train_acc: 9.06250 val_loss: 4.18804 val_acc: 8.12500\n",
      "[1, 390] train_loss: 4.04473 train_acc: 13.12500 val_loss: 4.09135 val_acc: 11.25000\n",
      "[1, 400] train_loss: 4.03034 train_acc: 8.75000 val_loss: 3.94717 val_acc: 13.75000\n",
      "[1, 410] train_loss: 4.03803 train_acc: 11.56250 val_loss: 4.09903 val_acc: 8.75000\n",
      "[1, 420] train_loss: 4.08795 train_acc: 7.18750 val_loss: 4.06429 val_acc: 11.25000\n",
      "[1, 430] train_loss: 3.97342 train_acc: 11.56250 val_loss: 4.10717 val_acc: 6.87500\n",
      "[1, 440] train_loss: 4.04159 train_acc: 7.50000 val_loss: 4.11274 val_acc: 6.25000\n",
      "[1, 450] train_loss: 4.03166 train_acc: 10.62500 val_loss: 4.00000 val_acc: 13.12500\n",
      "[1, 460] train_loss: 3.89687 train_acc: 11.56250 val_loss: 3.95296 val_acc: 9.37500\n",
      "[1, 470] train_loss: 3.97645 train_acc: 9.68750 val_loss: 3.93935 val_acc: 10.00000\n",
      "[1, 480] train_loss: 3.89989 train_acc: 13.43750 val_loss: 3.87908 val_acc: 14.37500\n",
      "[1, 490] train_loss: 3.81857 train_acc: 12.50000 val_loss: 4.07207 val_acc: 11.87500\n",
      "[1, 500] train_loss: 3.95746 train_acc: 12.50000 val_loss: 4.10470 val_acc: 13.75000\n",
      "[1, 510] train_loss: 3.98286 train_acc: 10.62500 val_loss: 3.86041 val_acc: 11.87500\n",
      "[1, 520] train_loss: 3.91293 train_acc: 13.75000 val_loss: 3.83075 val_acc: 14.37500\n",
      "[1, 530] train_loss: 3.92752 train_acc: 12.18750 val_loss: 3.97261 val_acc: 16.87500\n",
      "[1, 540] train_loss: 3.77712 train_acc: 13.43750 val_loss: 3.98482 val_acc: 13.75000\n",
      "[1, 550] train_loss: 3.87442 train_acc: 11.56250 val_loss: 4.00656 val_acc: 12.50000\n",
      "[1, 560] train_loss: 3.89882 train_acc: 10.31250 val_loss: 4.01176 val_acc: 10.00000\n",
      "[1, 570] train_loss: 3.84206 train_acc: 12.50000 val_loss: 3.82112 val_acc: 8.12500\n",
      "[1, 580] train_loss: 3.87380 train_acc: 13.75000 val_loss: 3.82460 val_acc: 14.37500\n",
      "[1, 590] train_loss: 3.81121 train_acc: 15.31250 val_loss: 3.87327 val_acc: 11.25000\n",
      "[1, 600] train_loss: 3.90975 train_acc: 13.75000 val_loss: 3.81461 val_acc: 18.12500\n",
      "[1, 610] train_loss: 3.86215 train_acc: 12.81250 val_loss: 3.87201 val_acc: 14.37500\n",
      "[1, 620] train_loss: 3.90799 train_acc: 13.75000 val_loss: 3.76993 val_acc: 23.12500\n",
      "[1, 630] train_loss: 3.84122 train_acc: 12.50000 val_loss: 3.99228 val_acc: 13.75000\n",
      "[1, 640] train_loss: 3.78017 train_acc: 17.81250 val_loss: 3.94449 val_acc: 13.12500\n",
      "[1, 650] train_loss: 3.83695 train_acc: 14.06250 val_loss: 4.00972 val_acc: 13.12500\n",
      "[1, 660] train_loss: 3.79946 train_acc: 14.37500 val_loss: 3.70740 val_acc: 18.12500\n",
      "[1, 670] train_loss: 3.75223 train_acc: 16.56250 val_loss: 3.69910 val_acc: 20.00000\n",
      "[1, 680] train_loss: 3.72703 train_acc: 13.43750 val_loss: 3.69166 val_acc: 19.37500\n",
      "[1, 690] train_loss: 3.77865 train_acc: 10.93750 val_loss: 3.93078 val_acc: 11.87500\n",
      "[1, 700] train_loss: 3.85931 train_acc: 10.93750 val_loss: 3.75850 val_acc: 20.00000\n",
      "[1, 710] train_loss: 3.64895 train_acc: 17.81250 val_loss: 3.76012 val_acc: 17.50000\n",
      "[1, 720] train_loss: 3.76625 train_acc: 14.68750 val_loss: 3.87814 val_acc: 13.75000\n",
      "[1, 730] train_loss: 3.52566 train_acc: 17.81250 val_loss: 3.62125 val_acc: 13.12500\n",
      "[1, 740] train_loss: 3.64240 train_acc: 15.93750 val_loss: 3.80634 val_acc: 15.00000\n",
      "[1, 750] train_loss: 3.78290 train_acc: 15.00000 val_loss: 3.71704 val_acc: 16.25000\n",
      "[1, 760] train_loss: 3.82517 train_acc: 15.31250 val_loss: 3.59413 val_acc: 21.87500\n",
      "[1, 770] train_loss: 3.74220 train_acc: 15.62500 val_loss: 3.57152 val_acc: 16.87500\n",
      "[1, 780] train_loss: 3.78193 train_acc: 12.81250 val_loss: 3.78261 val_acc: 15.00000\n",
      "[1, 790] train_loss: 3.70473 train_acc: 15.93750 val_loss: 3.47728 val_acc: 20.62500\n",
      "[1, 800] train_loss: 3.66353 train_acc: 17.18750 val_loss: 3.63167 val_acc: 14.37500\n",
      "[1, 810] train_loss: 3.73583 train_acc: 17.18750 val_loss: 3.71912 val_acc: 17.50000\n",
      "[1, 820] train_loss: 3.61975 train_acc: 18.75000 val_loss: 3.83171 val_acc: 13.75000\n",
      "[1, 830] train_loss: 3.66809 train_acc: 15.00000 val_loss: 3.59473 val_acc: 16.87500\n",
      "[1, 840] train_loss: 3.61361 train_acc: 18.43750 val_loss: 3.71723 val_acc: 15.00000\n",
      "[1, 850] train_loss: 3.68875 train_acc: 15.93750 val_loss: 3.58657 val_acc: 17.50000\n",
      "[1, 860] train_loss: 3.61718 train_acc: 16.87500 val_loss: 3.47580 val_acc: 21.87500\n",
      "[1, 870] train_loss: 3.52825 train_acc: 18.12500 val_loss: 3.63523 val_acc: 17.50000\n",
      "[1, 880] train_loss: 3.63505 train_acc: 15.31250 val_loss: 3.68979 val_acc: 17.50000\n",
      "[1, 890] train_loss: 3.61390 train_acc: 16.25000 val_loss: 3.62041 val_acc: 16.87500\n",
      "[1, 900] train_loss: 3.61729 train_acc: 19.68750 val_loss: 3.55691 val_acc: 21.25000\n",
      "[1, 910] train_loss: 3.55124 train_acc: 20.62500 val_loss: 3.57010 val_acc: 23.75000\n",
      "[1, 920] train_loss: 3.57441 train_acc: 17.81250 val_loss: 3.59230 val_acc: 15.00000\n",
      "[1, 930] train_loss: 3.63680 train_acc: 15.00000 val_loss: 3.62939 val_acc: 20.62500\n",
      "[1, 940] train_loss: 3.55183 train_acc: 17.18750 val_loss: 3.45466 val_acc: 18.12500\n",
      "[1, 950] train_loss: 3.55356 train_acc: 16.56250 val_loss: 3.71454 val_acc: 18.75000\n",
      "[1, 960] train_loss: 3.61633 train_acc: 15.93750 val_loss: 3.72483 val_acc: 16.25000\n",
      "[1, 970] train_loss: 3.51092 train_acc: 20.31250 val_loss: 3.62809 val_acc: 22.50000\n",
      "[1, 980] train_loss: 3.47482 train_acc: 23.43750 val_loss: 3.48947 val_acc: 21.25000\n",
      "[1, 990] train_loss: 3.36869 train_acc: 24.37500 val_loss: 3.36139 val_acc: 28.12500\n",
      "[1, 1000] train_loss: 3.49997 train_acc: 20.31250 val_loss: 3.55749 val_acc: 19.37500\n",
      "[1, 1010] train_loss: 3.53376 train_acc: 16.25000 val_loss: 3.73803 val_acc: 14.37500\n",
      "[1, 1020] train_loss: 3.50976 train_acc: 20.31250 val_loss: 3.50743 val_acc: 23.12500\n",
      "[1, 1030] train_loss: 3.42143 train_acc: 22.18750 val_loss: 3.40620 val_acc: 26.25000\n",
      "[1, 1040] train_loss: 3.57994 train_acc: 15.93750 val_loss: 3.43730 val_acc: 20.62500\n",
      "[1, 1050] train_loss: 3.34342 train_acc: 24.37500 val_loss: 3.60109 val_acc: 17.50000\n",
      "[1, 1060] train_loss: 3.40512 train_acc: 23.43750 val_loss: 3.49113 val_acc: 18.12500\n",
      "[1, 1070] train_loss: 3.29973 train_acc: 22.81250 val_loss: 3.58390 val_acc: 20.00000\n",
      "[1, 1080] train_loss: 3.39686 train_acc: 21.25000 val_loss: 3.41692 val_acc: 21.87500\n",
      "[1, 1090] train_loss: 3.39375 train_acc: 22.18750 val_loss: 3.42527 val_acc: 21.87500\n",
      "[1, 1100] train_loss: 3.36164 train_acc: 22.18750 val_loss: 3.37991 val_acc: 25.62500\n",
      "[1, 1110] train_loss: 3.35115 train_acc: 21.87500 val_loss: 3.54223 val_acc: 17.50000\n",
      "[1, 1120] train_loss: 3.46025 train_acc: 23.75000 val_loss: 3.32211 val_acc: 24.37500\n",
      "[1, 1130] train_loss: 3.33725 train_acc: 21.25000 val_loss: 3.17165 val_acc: 27.50000\n",
      "[1, 1140] train_loss: 3.39951 train_acc: 22.18750 val_loss: 3.45490 val_acc: 25.00000\n",
      "[1, 1150] train_loss: 3.34535 train_acc: 21.87500 val_loss: 3.41714 val_acc: 24.37500\n",
      "[1, 1160] train_loss: 3.27559 train_acc: 24.06250 val_loss: 3.52232 val_acc: 18.12500\n",
      "[1, 1170] train_loss: 3.50768 train_acc: 20.31250 val_loss: 3.36686 val_acc: 24.37500\n",
      "[1, 1180] train_loss: 3.40469 train_acc: 17.50000 val_loss: 3.44914 val_acc: 20.00000\n",
      "[1, 1190] train_loss: 3.28694 train_acc: 25.31250 val_loss: 3.46096 val_acc: 21.87500\n",
      "[1, 1200] train_loss: 3.41369 train_acc: 22.81250 val_loss: 3.36428 val_acc: 24.37500\n",
      "[1, 1210] train_loss: 3.42770 train_acc: 22.18750 val_loss: 3.35756 val_acc: 20.62500\n",
      "[1, 1220] train_loss: 3.36028 train_acc: 23.43750 val_loss: 3.34408 val_acc: 19.37500\n",
      "[1, 1230] train_loss: 3.19151 train_acc: 24.37500 val_loss: 3.46134 val_acc: 15.62500\n",
      "[1, 1240] train_loss: 3.26895 train_acc: 24.06250 val_loss: 3.21078 val_acc: 27.50000\n",
      "[1, 1250] train_loss: 3.34731 train_acc: 22.50000 val_loss: 3.48175 val_acc: 22.50000\n",
      "[1, 1260] train_loss: 3.29019 train_acc: 29.06250 val_loss: 3.32408 val_acc: 20.62500\n",
      "[1, 1270] train_loss: 3.15328 train_acc: 30.31250 val_loss: 3.32072 val_acc: 24.37500\n",
      "[1, 1280] train_loss: 3.27619 train_acc: 25.00000 val_loss: 3.23683 val_acc: 25.62500\n",
      "[1, 1290] train_loss: 3.22942 train_acc: 28.12500 val_loss: 3.23723 val_acc: 28.75000\n",
      "[1, 1300] train_loss: 3.06398 train_acc: 29.37500 val_loss: 3.18604 val_acc: 25.62500\n",
      "[1, 1310] train_loss: 3.23525 train_acc: 24.68750 val_loss: 3.20352 val_acc: 23.12500\n",
      "[1, 1320] train_loss: 3.21734 train_acc: 27.81250 val_loss: 3.26532 val_acc: 23.75000\n",
      "[1, 1330] train_loss: 3.00788 train_acc: 27.18750 val_loss: 3.36602 val_acc: 26.87500\n",
      "[1, 1340] train_loss: 3.13284 train_acc: 27.50000 val_loss: 3.24092 val_acc: 28.12500\n",
      "[1, 1350] train_loss: 3.27784 train_acc: 23.43750 val_loss: 3.08182 val_acc: 32.50000\n",
      "[1, 1360] train_loss: 3.31630 train_acc: 23.12500 val_loss: 3.13436 val_acc: 27.50000\n",
      "[1, 1370] train_loss: 3.13420 train_acc: 28.75000 val_loss: 3.42719 val_acc: 21.25000\n",
      "[1, 1380] train_loss: 3.14883 train_acc: 26.56250 val_loss: 3.21355 val_acc: 23.75000\n",
      "[1, 1390] train_loss: 3.10125 train_acc: 23.43750 val_loss: 3.46972 val_acc: 16.87500\n",
      "[1, 1400] train_loss: 3.25608 train_acc: 27.50000 val_loss: 3.37193 val_acc: 21.25000\n",
      "[1, 1410] train_loss: 3.25441 train_acc: 22.81250 val_loss: 3.30516 val_acc: 21.87500\n",
      "[1, 1420] train_loss: 3.15872 train_acc: 26.56250 val_loss: 3.21857 val_acc: 30.00000\n",
      "[1, 1430] train_loss: 3.09238 train_acc: 29.06250 val_loss: 3.24335 val_acc: 24.37500\n",
      "[1, 1440] train_loss: 3.24880 train_acc: 26.25000 val_loss: 3.34271 val_acc: 23.12500\n",
      "[1, 1450] train_loss: 3.32765 train_acc: 26.25000 val_loss: 3.22278 val_acc: 25.62500\n",
      "[1, 1460] train_loss: 3.23711 train_acc: 22.18750 val_loss: 3.13590 val_acc: 28.75000\n",
      "[1, 1470] train_loss: 3.08564 train_acc: 26.56250 val_loss: 3.24634 val_acc: 23.75000\n",
      "[1, 1480] train_loss: 2.89929 train_acc: 31.25000 val_loss: 2.96810 val_acc: 32.50000\n",
      "[1, 1490] train_loss: 3.13551 train_acc: 27.18750 val_loss: 3.36045 val_acc: 25.62500\n",
      "[1, 1500] train_loss: 3.11741 train_acc: 29.68750 val_loss: 3.19127 val_acc: 23.75000\n",
      "[1, 1510] train_loss: 3.00791 train_acc: 32.50000 val_loss: 3.25987 val_acc: 25.62500\n",
      "[1, 1520] train_loss: 2.96362 train_acc: 32.18750 val_loss: 3.10535 val_acc: 26.25000\n",
      "[1, 1530] train_loss: 3.07630 train_acc: 30.00000 val_loss: 3.08366 val_acc: 30.62500\n",
      "[1, 1540] train_loss: 3.09840 train_acc: 27.50000 val_loss: 3.16670 val_acc: 31.25000\n",
      "[1, 1550] train_loss: 3.00653 train_acc: 31.56250 val_loss: 3.04090 val_acc: 38.12500\n",
      "[1, 1560] train_loss: 3.03365 train_acc: 32.18750 val_loss: 3.25877 val_acc: 27.50000\n",
      "[1, 1570] train_loss: 3.00630 train_acc: 28.12500 val_loss: 2.85992 val_acc: 34.37500\n",
      "[1, 1580] train_loss: 3.18484 train_acc: 26.87500 val_loss: 2.92887 val_acc: 30.00000\n",
      "[1, 1590] train_loss: 2.94066 train_acc: 33.75000 val_loss: 3.03689 val_acc: 29.37500\n",
      "[1, 1600] train_loss: 2.98115 train_acc: 30.62500 val_loss: 2.91201 val_acc: 33.75000\n",
      "[1, 1610] train_loss: 3.00222 train_acc: 30.00000 val_loss: 2.81855 val_acc: 36.87500\n",
      "[1, 1620] train_loss: 2.91109 train_acc: 32.50000 val_loss: 2.88134 val_acc: 35.00000\n",
      "[1, 1630] train_loss: 2.96297 train_acc: 31.25000 val_loss: 3.07891 val_acc: 26.87500\n",
      "[1, 1640] train_loss: 2.97872 train_acc: 30.62500 val_loss: 2.93286 val_acc: 35.00000\n",
      "[1, 1650] train_loss: 2.91223 train_acc: 33.75000 val_loss: 2.97834 val_acc: 27.50000\n",
      "[1, 1660] train_loss: 2.90693 train_acc: 35.00000 val_loss: 3.04255 val_acc: 33.12500\n",
      "[1, 1670] train_loss: 3.07361 train_acc: 25.00000 val_loss: 2.98767 val_acc: 31.25000\n",
      "[1, 1680] train_loss: 2.98845 train_acc: 30.00000 val_loss: 3.10548 val_acc: 28.75000\n",
      "[1, 1690] train_loss: 2.98404 train_acc: 26.25000 val_loss: 2.81735 val_acc: 36.87500\n",
      "[1, 1700] train_loss: 2.89449 train_acc: 31.56250 val_loss: 3.00087 val_acc: 28.75000\n",
      "[1, 1710] train_loss: 3.00469 train_acc: 33.12500 val_loss: 2.86367 val_acc: 32.50000\n",
      "[1, 1720] train_loss: 2.95010 train_acc: 29.68750 val_loss: 2.95554 val_acc: 30.62500\n",
      "[1, 1730] train_loss: 3.02378 train_acc: 25.00000 val_loss: 3.10722 val_acc: 26.25000\n",
      "[1, 1740] train_loss: 2.86097 train_acc: 33.12500 val_loss: 3.14498 val_acc: 26.87500\n",
      "[1, 1750] train_loss: 2.79027 train_acc: 32.81250 val_loss: 2.76941 val_acc: 33.12500\n",
      "[1, 1760] train_loss: 2.98481 train_acc: 28.75000 val_loss: 3.02991 val_acc: 31.25000\n",
      "[1, 1770] train_loss: 2.93618 train_acc: 29.37500 val_loss: 2.85471 val_acc: 33.75000\n",
      "[1, 1780] train_loss: 2.99238 train_acc: 27.18750 val_loss: 2.79958 val_acc: 35.62500\n",
      "[1, 1790] train_loss: 2.89811 train_acc: 33.43750 val_loss: 3.01556 val_acc: 32.50000\n",
      "[1, 1800] train_loss: 2.69482 train_acc: 39.68750 val_loss: 3.01730 val_acc: 31.25000\n",
      "[1, 1810] train_loss: 2.94944 train_acc: 30.00000 val_loss: 3.01510 val_acc: 30.00000\n",
      "[1, 1820] train_loss: 2.89994 train_acc: 31.87500 val_loss: 2.97750 val_acc: 26.87500\n",
      "[1, 1830] train_loss: 2.99541 train_acc: 31.87500 val_loss: 2.95879 val_acc: 27.50000\n",
      "[1, 1840] train_loss: 2.82988 train_acc: 37.81250 val_loss: 2.76590 val_acc: 31.87500\n",
      "[1, 1850] train_loss: 2.83618 train_acc: 32.50000 val_loss: 3.22502 val_acc: 28.12500\n",
      "[1, 1860] train_loss: 2.73925 train_acc: 37.81250 val_loss: 2.79919 val_acc: 31.87500\n",
      "[1, 1870] train_loss: 2.82786 train_acc: 33.43750 val_loss: 2.98490 val_acc: 25.62500\n",
      "[1, 1880] train_loss: 3.01247 train_acc: 29.06250 val_loss: 2.84553 val_acc: 34.37500\n",
      "[1, 1890] train_loss: 2.82009 train_acc: 34.06250 val_loss: 2.76776 val_acc: 34.37500\n",
      "[1, 1900] train_loss: 2.86662 train_acc: 32.50000 val_loss: 2.96458 val_acc: 33.12500\n",
      "[1, 1910] train_loss: 2.70735 train_acc: 35.00000 val_loss: 2.86003 val_acc: 38.75000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1920] train_loss: 2.75019 train_acc: 33.75000 val_loss: 2.80070 val_acc: 33.75000\n",
      "[1, 1930] train_loss: 2.68503 train_acc: 37.81250 val_loss: 2.78644 val_acc: 35.62500\n",
      "[1, 1940] train_loss: 2.86687 train_acc: 33.75000 val_loss: 3.01164 val_acc: 33.12500\n",
      "[1, 1950] train_loss: 2.72996 train_acc: 35.62500 val_loss: 2.64474 val_acc: 40.00000\n",
      "[1, 1960] train_loss: 2.69443 train_acc: 39.37500 val_loss: 3.06189 val_acc: 28.12500\n",
      "[1, 1970] train_loss: 2.68997 train_acc: 37.18750 val_loss: 2.81365 val_acc: 33.75000\n",
      "[1, 1980] train_loss: 2.83039 train_acc: 32.81250 val_loss: 3.00981 val_acc: 32.50000\n",
      "[1, 1990] train_loss: 2.49552 train_acc: 38.43750 val_loss: 2.89807 val_acc: 36.87500\n",
      "[1, 2000] train_loss: 2.69986 train_acc: 36.25000 val_loss: 2.71879 val_acc: 33.75000\n",
      "[1, 2010] train_loss: 2.71829 train_acc: 35.93750 val_loss: 2.97477 val_acc: 28.75000\n",
      "[1, 2020] train_loss: 2.79332 train_acc: 33.75000 val_loss: 2.81947 val_acc: 35.00000\n",
      "[1, 2030] train_loss: 2.75919 train_acc: 36.56250 val_loss: 2.62990 val_acc: 34.37500\n",
      "[1, 2040] train_loss: 2.73190 train_acc: 32.81250 val_loss: 2.80947 val_acc: 36.87500\n",
      "[1, 2050] train_loss: 2.66290 train_acc: 37.81250 val_loss: 2.87921 val_acc: 35.00000\n",
      "[1, 2060] train_loss: 2.74896 train_acc: 33.12500 val_loss: 2.74369 val_acc: 34.37500\n",
      "[1, 2070] train_loss: 2.78117 train_acc: 35.00000 val_loss: 2.70695 val_acc: 36.25000\n",
      "[1, 2080] train_loss: 2.68759 train_acc: 37.50000 val_loss: 2.53646 val_acc: 41.25000\n",
      "[1, 2090] train_loss: 2.77462 train_acc: 34.06250 val_loss: 3.01725 val_acc: 32.50000\n",
      "[1, 2100] train_loss: 2.65359 train_acc: 36.87500 val_loss: 2.88964 val_acc: 32.50000\n",
      "[1, 2110] train_loss: 2.65368 train_acc: 38.12500 val_loss: 2.93018 val_acc: 28.75000\n",
      "[1, 2120] train_loss: 2.50590 train_acc: 40.93750 val_loss: 2.70484 val_acc: 38.12500\n",
      "[1, 2130] train_loss: 2.67783 train_acc: 38.43750 val_loss: 2.80912 val_acc: 34.37500\n",
      "[1, 2140] train_loss: 2.65739 train_acc: 35.62500 val_loss: 2.86084 val_acc: 35.62500\n",
      "[1, 2150] train_loss: 2.58931 train_acc: 36.87500 val_loss: 2.53190 val_acc: 44.37500\n",
      "[1, 2160] train_loss: 2.50049 train_acc: 42.81250 val_loss: 2.61101 val_acc: 38.75000\n",
      "[1, 2170] train_loss: 2.54443 train_acc: 38.12500 val_loss: 2.78478 val_acc: 38.12500\n",
      "[1, 2180] train_loss: 2.44797 train_acc: 43.75000 val_loss: 2.42786 val_acc: 40.00000\n",
      "[1, 2190] train_loss: 2.58327 train_acc: 36.25000 val_loss: 2.59298 val_acc: 39.37500\n",
      "[1, 2200] train_loss: 2.46790 train_acc: 40.31250 val_loss: 2.49478 val_acc: 39.37500\n",
      "[1, 2210] train_loss: 2.61821 train_acc: 37.50000 val_loss: 2.93416 val_acc: 31.87500\n",
      "[1, 2220] train_loss: 2.63240 train_acc: 37.50000 val_loss: 2.62829 val_acc: 38.75000\n",
      "[1, 2230] train_loss: 2.57979 train_acc: 38.43750 val_loss: 2.56984 val_acc: 39.37500\n",
      "[1, 2240] train_loss: 2.69472 train_acc: 34.68750 val_loss: 2.39804 val_acc: 44.37500\n",
      "[1, 2250] train_loss: 2.66477 train_acc: 37.50000 val_loss: 2.66621 val_acc: 38.12500\n",
      "[1, 2260] train_loss: 2.57536 train_acc: 39.06250 val_loss: 2.68211 val_acc: 37.50000\n",
      "[1, 2270] train_loss: 2.49939 train_acc: 39.37500 val_loss: 2.54469 val_acc: 43.75000\n",
      "[1, 2280] train_loss: 2.56076 train_acc: 36.25000 val_loss: 2.76494 val_acc: 31.87500\n",
      "[1, 2290] train_loss: 2.50078 train_acc: 41.56250 val_loss: 2.67660 val_acc: 37.50000\n",
      "[1, 2300] train_loss: 2.39061 train_acc: 43.75000 val_loss: 2.43723 val_acc: 41.25000\n",
      "[1, 2310] train_loss: 2.40549 train_acc: 43.12500 val_loss: 2.72391 val_acc: 35.62500\n",
      "[1, 2320] train_loss: 2.46810 train_acc: 41.25000 val_loss: 2.37385 val_acc: 40.00000\n",
      "[1, 2330] train_loss: 2.53047 train_acc: 38.12500 val_loss: 2.60671 val_acc: 39.37500\n",
      "[1, 2340] train_loss: 2.46903 train_acc: 41.87500 val_loss: 2.66978 val_acc: 37.50000\n",
      "[1, 2350] train_loss: 2.53091 train_acc: 40.93750 val_loss: 2.70352 val_acc: 34.37500\n",
      "[1, 2360] train_loss: 2.52955 train_acc: 40.93750 val_loss: 2.69183 val_acc: 37.50000\n",
      "[1, 2370] train_loss: 2.49116 train_acc: 41.56250 val_loss: 2.74862 val_acc: 39.37500\n",
      "[1, 2380] train_loss: 2.62161 train_acc: 39.06250 val_loss: 2.77231 val_acc: 36.25000\n",
      "[1, 2390] train_loss: 2.61861 train_acc: 39.06250 val_loss: 2.91066 val_acc: 33.75000\n",
      "[1, 2400] train_loss: 2.30390 train_acc: 42.18750 val_loss: 2.69388 val_acc: 35.62500\n",
      "[1, 2410] train_loss: 2.46628 train_acc: 40.93750 val_loss: 2.53275 val_acc: 39.37500\n",
      "[1, 2420] train_loss: 2.47398 train_acc: 40.31250 val_loss: 2.79468 val_acc: 32.50000\n",
      "[1, 2430] train_loss: 2.62508 train_acc: 38.75000 val_loss: 2.71388 val_acc: 33.75000\n",
      "[1, 2440] train_loss: 2.42510 train_acc: 44.68750 val_loss: 2.81987 val_acc: 30.62500\n",
      "[1, 2450] train_loss: 2.52972 train_acc: 41.87500 val_loss: 2.48592 val_acc: 43.75000\n",
      "[1, 2460] train_loss: 2.36651 train_acc: 46.56250 val_loss: 2.73390 val_acc: 35.00000\n",
      "[1, 2470] train_loss: 2.36088 train_acc: 41.25000 val_loss: 2.45289 val_acc: 40.00000\n",
      "[1, 2480] train_loss: 2.39150 train_acc: 44.06250 val_loss: 2.45528 val_acc: 44.37500\n",
      "[1, 2490] train_loss: 2.28089 train_acc: 46.25000 val_loss: 2.63090 val_acc: 38.75000\n",
      "[1, 2500] train_loss: 2.33547 train_acc: 45.00000 val_loss: 2.75795 val_acc: 36.25000\n",
      "[1, 2510] train_loss: 2.40249 train_acc: 44.68750 val_loss: 2.45030 val_acc: 45.00000\n",
      "[1, 2520] train_loss: 2.79421 train_acc: 35.62500 val_loss: 2.60813 val_acc: 37.50000\n",
      "[1, 2530] train_loss: 2.53560 train_acc: 38.75000 val_loss: 2.50933 val_acc: 40.00000\n",
      "[1, 2540] train_loss: 2.27086 train_acc: 47.18750 val_loss: 2.67132 val_acc: 39.37500\n",
      "[1, 2550] train_loss: 2.25233 train_acc: 48.75000 val_loss: 2.59579 val_acc: 37.50000\n",
      "[1, 2560] train_loss: 2.42781 train_acc: 41.87500 val_loss: 2.69015 val_acc: 36.87500\n",
      "[1, 2570] train_loss: 2.58742 train_acc: 38.12500 val_loss: 2.61011 val_acc: 36.87500\n",
      "[1, 2580] train_loss: 2.34307 train_acc: 41.87500 val_loss: 2.46443 val_acc: 45.00000\n",
      "[1, 2590] train_loss: 2.37831 train_acc: 42.18750 val_loss: 2.63744 val_acc: 39.37500\n",
      "[1, 2600] train_loss: 2.36808 train_acc: 42.81250 val_loss: 2.52015 val_acc: 41.25000\n",
      "[1, 2610] train_loss: 2.36412 train_acc: 46.87500 val_loss: 2.67421 val_acc: 39.37500\n",
      "[1, 2620] train_loss: 2.49071 train_acc: 40.93750 val_loss: 2.44836 val_acc: 41.87500\n",
      "[1, 2630] train_loss: 2.32041 train_acc: 41.87500 val_loss: 2.39309 val_acc: 41.25000\n",
      "[1, 2640] train_loss: 2.48503 train_acc: 41.25000 val_loss: 2.42925 val_acc: 41.87500\n",
      "[1, 2650] train_loss: 2.40159 train_acc: 42.50000 val_loss: 2.33687 val_acc: 41.87500\n",
      "[1, 2660] train_loss: 2.27075 train_acc: 47.81250 val_loss: 2.61228 val_acc: 41.25000\n",
      "[1, 2670] train_loss: 2.35372 train_acc: 42.50000 val_loss: 2.44449 val_acc: 45.00000\n",
      "[1, 2680] train_loss: 2.38699 train_acc: 42.81250 val_loss: 2.35932 val_acc: 48.12500\n",
      "[1, 2690] train_loss: 2.46984 train_acc: 41.56250 val_loss: 2.46127 val_acc: 41.87500\n",
      "[1, 2700] train_loss: 2.27117 train_acc: 45.93750 val_loss: 2.57696 val_acc: 37.50000\n",
      "[1, 2710] train_loss: 2.35674 train_acc: 45.00000 val_loss: 2.52615 val_acc: 40.62500\n",
      "[1, 2720] train_loss: 2.35908 train_acc: 41.56250 val_loss: 2.37891 val_acc: 43.12500\n",
      "[1, 2730] train_loss: 2.40921 train_acc: 43.75000 val_loss: 2.45779 val_acc: 41.87500\n",
      "[1, 2740] train_loss: 2.38879 train_acc: 48.43750 val_loss: 2.35969 val_acc: 45.62500\n",
      "[1, 2750] train_loss: 2.38872 train_acc: 42.81250 val_loss: 2.35581 val_acc: 44.37500\n",
      "[1, 2760] train_loss: 2.39254 train_acc: 41.25000 val_loss: 2.49022 val_acc: 40.00000\n",
      "[1, 2770] train_loss: 2.42352 train_acc: 40.93750 val_loss: 2.40056 val_acc: 41.87500\n",
      "[1, 2780] train_loss: 2.40692 train_acc: 45.31250 val_loss: 2.56667 val_acc: 38.12500\n",
      "[1, 2790] train_loss: 2.25265 train_acc: 41.56250 val_loss: 2.49880 val_acc: 41.25000\n",
      "[1, 2800] train_loss: 2.21687 train_acc: 49.06250 val_loss: 2.48910 val_acc: 43.75000\n",
      "[1, 2810] train_loss: 2.33663 train_acc: 42.50000 val_loss: 2.23529 val_acc: 45.62500\n",
      "[1, 2820] train_loss: 2.35850 train_acc: 44.06250 val_loss: 2.33599 val_acc: 46.25000\n",
      "[1, 2830] train_loss: 2.25637 train_acc: 42.18750 val_loss: 2.40102 val_acc: 41.87500\n",
      "[1, 2840] train_loss: 2.32180 train_acc: 45.00000 val_loss: 2.16131 val_acc: 50.00000\n",
      "[1, 2850] train_loss: 2.29761 train_acc: 45.31250 val_loss: 2.35506 val_acc: 46.87500\n",
      "[1, 2860] train_loss: 2.45721 train_acc: 40.62500 val_loss: 2.49195 val_acc: 45.00000\n",
      "[1, 2870] train_loss: 2.28438 train_acc: 45.31250 val_loss: 2.32346 val_acc: 47.50000\n",
      "[1, 2880] train_loss: 2.09869 train_acc: 48.43750 val_loss: 2.58571 val_acc: 40.00000\n",
      "[1, 2890] train_loss: 2.23961 train_acc: 46.87500 val_loss: 2.28825 val_acc: 46.25000\n",
      "[1, 2900] train_loss: 2.43188 train_acc: 43.43750 val_loss: 2.61095 val_acc: 41.25000\n",
      "[1, 2910] train_loss: 2.32705 train_acc: 42.81250 val_loss: 2.56549 val_acc: 44.37500\n",
      "[1, 2920] train_loss: 2.19612 train_acc: 45.93750 val_loss: 2.37027 val_acc: 41.87500\n",
      "[1, 2930] train_loss: 2.16073 train_acc: 50.62500 val_loss: 2.18152 val_acc: 51.87500\n",
      "[1, 2940] train_loss: 2.22519 train_acc: 45.62500 val_loss: 2.25323 val_acc: 45.62500\n",
      "[1, 2950] train_loss: 2.34115 train_acc: 39.68750 val_loss: 2.33929 val_acc: 46.87500\n",
      "[1, 2960] train_loss: 2.15930 train_acc: 49.06250 val_loss: 2.41725 val_acc: 44.37500\n",
      "[1, 2970] train_loss: 2.31431 train_acc: 44.68750 val_loss: 2.37628 val_acc: 43.75000\n",
      "[1, 2980] train_loss: 2.31944 train_acc: 44.68750 val_loss: 2.30316 val_acc: 47.50000\n",
      "[1, 2990] train_loss: 2.19802 train_acc: 46.56250 val_loss: 2.20718 val_acc: 51.25000\n",
      "[1, 3000] train_loss: 2.31088 train_acc: 45.00000 val_loss: 2.39718 val_acc: 38.75000\n",
      "[1, 3010] train_loss: 2.18296 train_acc: 51.25000 val_loss: 2.75305 val_acc: 37.50000\n",
      "[1, 3020] train_loss: 2.26515 train_acc: 43.75000 val_loss: 2.15149 val_acc: 49.37500\n",
      "[1, 3030] train_loss: 2.14892 train_acc: 49.68750 val_loss: 2.36216 val_acc: 45.62500\n",
      "[1, 3040] train_loss: 2.42326 train_acc: 42.50000 val_loss: 2.33283 val_acc: 47.50000\n",
      "[1, 3050] train_loss: 2.29904 train_acc: 44.68750 val_loss: 2.63941 val_acc: 41.25000\n",
      "[1, 3060] train_loss: 2.10907 train_acc: 48.75000 val_loss: 2.45947 val_acc: 43.75000\n",
      "[1, 3070] train_loss: 2.25506 train_acc: 45.00000 val_loss: 2.45823 val_acc: 45.62500\n",
      "[1, 3080] train_loss: 2.30764 train_acc: 45.62500 val_loss: 2.13082 val_acc: 48.75000\n",
      "[1, 3090] train_loss: 2.04268 train_acc: 48.75000 val_loss: 2.54178 val_acc: 43.75000\n",
      "[1, 3100] train_loss: 2.07233 train_acc: 49.06250 val_loss: 2.17641 val_acc: 48.12500\n",
      "[1, 3110] train_loss: 2.21338 train_acc: 47.81250 val_loss: 2.58481 val_acc: 38.75000\n",
      "[1, 3120] train_loss: 2.09815 train_acc: 50.62500 val_loss: 2.49323 val_acc: 41.25000\n",
      "[1, 3130] train_loss: 2.08445 train_acc: 51.56250 val_loss: 2.04191 val_acc: 51.25000\n",
      "[1, 3140] train_loss: 2.26794 train_acc: 44.37500 val_loss: 2.31554 val_acc: 45.62500\n",
      "[1, 3150] train_loss: 2.23039 train_acc: 47.18750 val_loss: 2.44913 val_acc: 40.00000\n",
      "[1, 3160] train_loss: 2.30436 train_acc: 47.18750 val_loss: 2.17580 val_acc: 50.00000\n",
      "[1, 3170] train_loss: 2.18866 train_acc: 46.56250 val_loss: 2.37701 val_acc: 46.87500\n",
      "[1, 3180] train_loss: 2.05039 train_acc: 47.81250 val_loss: 2.22326 val_acc: 47.50000\n",
      "[1, 3190] train_loss: 2.22448 train_acc: 47.18750 val_loss: 2.24118 val_acc: 46.87500\n",
      "[1, 3200] train_loss: 2.18159 train_acc: 47.81250 val_loss: 2.26556 val_acc: 48.75000\n",
      "[1, 3210] train_loss: 2.17660 train_acc: 47.50000 val_loss: 2.05262 val_acc: 48.75000\n",
      "[1, 3220] train_loss: 2.04226 train_acc: 50.00000 val_loss: 2.14781 val_acc: 43.75000\n",
      "[1, 3230] train_loss: 2.13324 train_acc: 48.43750 val_loss: 2.19643 val_acc: 44.37500\n",
      "[1, 3240] train_loss: 2.26003 train_acc: 44.68750 val_loss: 2.01756 val_acc: 51.25000\n",
      "[1, 3250] train_loss: 2.15503 train_acc: 47.50000 val_loss: 2.20857 val_acc: 46.25000\n",
      "[1, 3260] train_loss: 2.29292 train_acc: 45.93750 val_loss: 2.32511 val_acc: 49.37500\n",
      "[1, 3270] train_loss: 2.05700 train_acc: 50.62500 val_loss: 2.22081 val_acc: 46.87500\n",
      "[1, 3280] train_loss: 2.14303 train_acc: 47.50000 val_loss: 2.17486 val_acc: 47.50000\n",
      "[1, 3290] train_loss: 2.08602 train_acc: 49.37500 val_loss: 2.57037 val_acc: 37.50000\n",
      "[1, 3300] train_loss: 2.11918 train_acc: 49.06250 val_loss: 2.25078 val_acc: 43.12500\n",
      "[1, 3310] train_loss: 2.07352 train_acc: 50.93750 val_loss: 2.24615 val_acc: 46.87500\n",
      "[1, 3320] train_loss: 2.03911 train_acc: 48.75000 val_loss: 2.36500 val_acc: 44.37500\n",
      "[1, 3330] train_loss: 2.13860 train_acc: 47.18750 val_loss: 2.05015 val_acc: 50.62500\n",
      "[1, 3340] train_loss: 2.05018 train_acc: 50.31250 val_loss: 2.52805 val_acc: 43.12500\n",
      "[1, 3350] train_loss: 2.35850 train_acc: 44.06250 val_loss: 2.30982 val_acc: 43.12500\n",
      "[1, 3360] train_loss: 2.22294 train_acc: 46.25000 val_loss: 2.33383 val_acc: 46.25000\n",
      "[1, 3370] train_loss: 2.05105 train_acc: 53.12500 val_loss: 2.35077 val_acc: 46.25000\n",
      "[1, 3380] train_loss: 2.25249 train_acc: 48.43750 val_loss: 2.34809 val_acc: 43.12500\n",
      "[1, 3390] train_loss: 2.03277 train_acc: 54.06250 val_loss: 2.26519 val_acc: 44.37500\n",
      "[1, 3400] train_loss: 2.05255 train_acc: 49.37500 val_loss: 2.26907 val_acc: 47.50000\n",
      "[1, 3410] train_loss: 2.07398 train_acc: 51.56250 val_loss: 2.30782 val_acc: 49.37500\n",
      "[1, 3420] train_loss: 1.96877 train_acc: 54.06250 val_loss: 2.25805 val_acc: 44.37500\n",
      "[1, 3430] train_loss: 2.05144 train_acc: 48.43750 val_loss: 1.98590 val_acc: 51.25000\n",
      "[1, 3440] train_loss: 1.99831 train_acc: 52.18750 val_loss: 2.39543 val_acc: 45.00000\n",
      "[1, 3450] train_loss: 1.95531 train_acc: 51.56250 val_loss: 2.54402 val_acc: 41.25000\n",
      "[1, 3460] train_loss: 2.08853 train_acc: 46.56250 val_loss: 2.25141 val_acc: 50.00000\n",
      "[1, 3470] train_loss: 1.99758 train_acc: 50.00000 val_loss: 2.11357 val_acc: 48.12500\n",
      "[1, 3480] train_loss: 1.97006 train_acc: 49.37500 val_loss: 2.47897 val_acc: 44.37500\n",
      "[1, 3490] train_loss: 1.92824 train_acc: 55.00000 val_loss: 2.18179 val_acc: 45.62500\n",
      "[1, 3500] train_loss: 2.02993 train_acc: 53.43750 val_loss: 2.18733 val_acc: 48.12500\n",
      "[1, 3510] train_loss: 2.10194 train_acc: 49.37500 val_loss: 2.12943 val_acc: 49.37500\n",
      "[1, 3520] train_loss: 2.16431 train_acc: 48.43750 val_loss: 2.12482 val_acc: 51.25000\n",
      "[1, 3530] train_loss: 2.11807 train_acc: 49.37500 val_loss: 2.49895 val_acc: 41.87500\n",
      "[1, 3540] train_loss: 2.14207 train_acc: 50.62500 val_loss: 2.21881 val_acc: 46.87500\n",
      "[1, 3550] train_loss: 2.11972 train_acc: 50.62500 val_loss: 2.13460 val_acc: 48.75000\n",
      "[1, 3560] train_loss: 1.96201 train_acc: 51.25000 val_loss: 2.08893 val_acc: 50.00000\n",
      "[1, 3570] train_loss: 2.08577 train_acc: 48.43750 val_loss: 2.33496 val_acc: 38.12500\n",
      "[1, 3580] train_loss: 2.02514 train_acc: 50.00000 val_loss: 2.23132 val_acc: 46.25000\n",
      "[1, 3590] train_loss: 2.16640 train_acc: 47.50000 val_loss: 2.10339 val_acc: 47.50000\n",
      "[1, 3600] train_loss: 1.99534 train_acc: 49.37500 val_loss: 2.27709 val_acc: 48.75000\n",
      "[1, 3610] train_loss: 1.95467 train_acc: 52.50000 val_loss: 2.39044 val_acc: 45.00000\n",
      "[1, 3620] train_loss: 2.04507 train_acc: 51.87500 val_loss: 2.19526 val_acc: 51.25000\n",
      "[1, 3630] train_loss: 2.12125 train_acc: 49.06250 val_loss: 2.15074 val_acc: 50.00000\n",
      "[1, 3640] train_loss: 1.87569 train_acc: 53.75000 val_loss: 2.15127 val_acc: 50.00000\n",
      "[1, 3650] train_loss: 1.93424 train_acc: 52.81250 val_loss: 2.20141 val_acc: 48.12500\n",
      "[1, 3660] train_loss: 2.11685 train_acc: 50.93750 val_loss: 2.10472 val_acc: 51.87500\n",
      "[1, 3670] train_loss: 1.95104 train_acc: 52.50000 val_loss: 2.22495 val_acc: 48.12500\n",
      "[1, 3680] train_loss: 1.95099 train_acc: 54.68750 val_loss: 2.18868 val_acc: 49.37500\n",
      "[1, 3690] train_loss: 1.99876 train_acc: 51.87500 val_loss: 2.12833 val_acc: 55.00000\n",
      "[1, 3700] train_loss: 2.03150 train_acc: 50.31250 val_loss: 2.41669 val_acc: 43.75000\n",
      "[1, 3710] train_loss: 1.89831 train_acc: 54.37500 val_loss: 2.44299 val_acc: 45.00000\n",
      "[1, 3720] train_loss: 2.04297 train_acc: 48.75000 val_loss: 2.05653 val_acc: 50.62500\n",
      "[1, 3730] train_loss: 1.96252 train_acc: 49.37500 val_loss: 2.04611 val_acc: 53.75000\n",
      "[1, 3740] train_loss: 2.00917 train_acc: 48.75000 val_loss: 1.86291 val_acc: 51.25000\n",
      "[1, 3750] train_loss: 1.95819 train_acc: 51.56250 val_loss: 1.98969 val_acc: 51.25000\n",
      "[1, 3760] train_loss: 2.05397 train_acc: 49.68750 val_loss: 2.05724 val_acc: 51.25000\n",
      "[1, 3770] train_loss: 1.96855 train_acc: 52.81250 val_loss: 2.14444 val_acc: 54.37500\n",
      "[1, 3780] train_loss: 1.98208 train_acc: 53.12500 val_loss: 2.04706 val_acc: 53.12500\n",
      "[1, 3790] train_loss: 2.00240 train_acc: 49.68750 val_loss: 2.09084 val_acc: 50.62500\n",
      "[1, 3800] train_loss: 2.07221 train_acc: 52.18750 val_loss: 1.97294 val_acc: 53.75000\n",
      "[1, 3810] train_loss: 2.05773 train_acc: 51.56250 val_loss: 2.22301 val_acc: 49.37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3820] train_loss: 2.10910 train_acc: 49.37500 val_loss: 1.95116 val_acc: 50.00000\n",
      "[1, 3830] train_loss: 2.02768 train_acc: 50.62500 val_loss: 2.31601 val_acc: 43.75000\n",
      "[1, 3840] train_loss: 1.87643 train_acc: 53.43750 val_loss: 2.26164 val_acc: 50.62500\n",
      "[1, 3850] train_loss: 1.91527 train_acc: 51.56250 val_loss: 2.22082 val_acc: 48.75000\n",
      "[1, 3860] train_loss: 1.96155 train_acc: 53.12500 val_loss: 2.01185 val_acc: 55.62500\n",
      "[1, 3870] train_loss: 2.08589 train_acc: 49.37500 val_loss: 2.17830 val_acc: 45.62500\n",
      "[1, 3880] train_loss: 1.76030 train_acc: 59.06250 val_loss: 1.89517 val_acc: 55.00000\n",
      "[1, 3890] train_loss: 1.68335 train_acc: 61.25000 val_loss: 1.84143 val_acc: 56.87500\n",
      "[1, 3900] train_loss: 2.05587 train_acc: 48.43750 val_loss: 2.13905 val_acc: 48.75000\n",
      "[1, 3910] train_loss: 1.89878 train_acc: 54.68750 val_loss: 2.07844 val_acc: 51.87500\n",
      "[1, 3920] train_loss: 2.08955 train_acc: 51.25000 val_loss: 2.24568 val_acc: 48.12500\n",
      "[1, 3930] train_loss: 2.03738 train_acc: 50.00000 val_loss: 2.31283 val_acc: 46.25000\n",
      "[1, 3940] train_loss: 1.93704 train_acc: 50.00000 val_loss: 2.30513 val_acc: 45.62500\n",
      "[1, 3950] train_loss: 2.03239 train_acc: 50.31250 val_loss: 2.05660 val_acc: 48.12500\n",
      "[1, 3960] train_loss: 1.91298 train_acc: 54.37500 val_loss: 1.76222 val_acc: 58.75000\n",
      "[1, 3970] train_loss: 2.01685 train_acc: 50.93750 val_loss: 2.28474 val_acc: 46.25000\n",
      "[1, 3980] train_loss: 1.96756 train_acc: 52.18750 val_loss: 1.80288 val_acc: 55.62500\n",
      "[1, 3990] train_loss: 1.95693 train_acc: 51.56250 val_loss: 2.03421 val_acc: 50.62500\n",
      "[1, 4000] train_loss: 1.70282 train_acc: 57.50000 val_loss: 2.28300 val_acc: 47.50000\n",
      "[1, 4010] train_loss: 1.79328 train_acc: 52.50000 val_loss: 2.09422 val_acc: 52.50000\n",
      "[1, 4020] train_loss: 2.03931 train_acc: 51.25000 val_loss: 2.22402 val_acc: 52.50000\n",
      "[1, 4030] train_loss: 1.80560 train_acc: 57.81250 val_loss: 2.10088 val_acc: 53.12500\n",
      "[1, 4040] train_loss: 1.99026 train_acc: 53.12500 val_loss: 1.94419 val_acc: 52.50000\n",
      "[1, 4050] train_loss: 1.97216 train_acc: 50.93750 val_loss: 1.92868 val_acc: 54.37500\n",
      "[1, 4060] train_loss: 2.06390 train_acc: 47.81250 val_loss: 1.64153 val_acc: 61.25000\n",
      "[1, 4070] train_loss: 1.95147 train_acc: 56.25000 val_loss: 2.06208 val_acc: 50.62500\n",
      "[1, 4080] train_loss: 1.79334 train_acc: 55.31250 val_loss: 2.07979 val_acc: 53.75000\n",
      "[1, 4090] train_loss: 1.89740 train_acc: 53.43750 val_loss: 2.10673 val_acc: 50.62500\n",
      "[1, 4100] train_loss: 2.04806 train_acc: 48.75000 val_loss: 1.98366 val_acc: 53.75000\n",
      "[1, 4110] train_loss: 1.96285 train_acc: 52.18750 val_loss: 2.03754 val_acc: 50.00000\n",
      "[1, 4120] train_loss: 1.83878 train_acc: 55.00000 val_loss: 2.20120 val_acc: 47.50000\n",
      "[1, 4130] train_loss: 1.78352 train_acc: 55.31250 val_loss: 1.98103 val_acc: 55.62500\n",
      "[1, 4140] train_loss: 2.01715 train_acc: 47.18750 val_loss: 2.04386 val_acc: 54.37500\n",
      "[1, 4150] train_loss: 1.87482 train_acc: 54.37500 val_loss: 2.13647 val_acc: 52.50000\n",
      "[1, 4160] train_loss: 1.85171 train_acc: 55.93750 val_loss: 1.95663 val_acc: 53.12500\n",
      "[1, 4170] train_loss: 1.85628 train_acc: 54.37500 val_loss: 2.05066 val_acc: 52.50000\n",
      "[1, 4180] train_loss: 1.95980 train_acc: 52.50000 val_loss: 2.11637 val_acc: 48.75000\n",
      "[1, 4190] train_loss: 1.86540 train_acc: 54.68750 val_loss: 1.80802 val_acc: 56.87500\n",
      "[1, 4200] train_loss: 1.88056 train_acc: 54.37500 val_loss: 1.92981 val_acc: 55.62500\n",
      "[1, 4210] train_loss: 1.86623 train_acc: 55.31250 val_loss: 2.16301 val_acc: 49.37500\n",
      "[1, 4220] train_loss: 1.96751 train_acc: 49.06250 val_loss: 1.97763 val_acc: 49.37500\n",
      "[1, 4230] train_loss: 1.84283 train_acc: 56.56250 val_loss: 2.19130 val_acc: 46.87500\n",
      "[1, 4240] train_loss: 1.77901 train_acc: 57.18750 val_loss: 2.07593 val_acc: 50.62500\n",
      "[1, 4250] train_loss: 1.79636 train_acc: 56.56250 val_loss: 1.90999 val_acc: 55.62500\n",
      "[1, 4260] train_loss: 1.91292 train_acc: 52.81250 val_loss: 2.29338 val_acc: 48.75000\n",
      "[1, 4270] train_loss: 1.84134 train_acc: 53.12500 val_loss: 1.80494 val_acc: 53.75000\n",
      "[1, 4280] train_loss: 1.65439 train_acc: 56.56250 val_loss: 1.82779 val_acc: 60.00000\n",
      "[1, 4290] train_loss: 1.75644 train_acc: 53.43750 val_loss: 1.80578 val_acc: 65.00000\n",
      "[1, 4300] train_loss: 1.86779 train_acc: 50.00000 val_loss: 1.98001 val_acc: 55.00000\n",
      "[1, 4310] train_loss: 1.99111 train_acc: 54.37500 val_loss: 2.16221 val_acc: 46.87500\n",
      "[1, 4320] train_loss: 1.76684 train_acc: 58.12500 val_loss: 2.02119 val_acc: 51.87500\n",
      "[1, 4330] train_loss: 1.79660 train_acc: 54.68750 val_loss: 1.81754 val_acc: 61.25000\n",
      "[1, 4340] train_loss: 1.74297 train_acc: 57.81250 val_loss: 1.82701 val_acc: 56.87500\n",
      "[1, 4350] train_loss: 1.89095 train_acc: 52.18750 val_loss: 1.77267 val_acc: 57.50000\n",
      "[1, 4360] train_loss: 1.85423 train_acc: 54.06250 val_loss: 1.95245 val_acc: 53.12500\n",
      "[1, 4370] train_loss: 1.82697 train_acc: 58.12500 val_loss: 2.04676 val_acc: 49.37500\n",
      "[1, 4380] train_loss: 1.73591 train_acc: 58.12500 val_loss: 2.12824 val_acc: 45.62500\n",
      "[1, 4390] train_loss: 1.79702 train_acc: 55.93750 val_loss: 1.99493 val_acc: 52.50000\n",
      "[1, 4400] train_loss: 1.67525 train_acc: 60.62500 val_loss: 2.02640 val_acc: 53.12500\n",
      "[1, 4410] train_loss: 1.82064 train_acc: 55.00000 val_loss: 2.12367 val_acc: 48.75000\n",
      "[1, 4420] train_loss: 1.79013 train_acc: 57.18750 val_loss: 1.89181 val_acc: 58.75000\n",
      "[1, 4430] train_loss: 1.78204 train_acc: 55.31250 val_loss: 1.94273 val_acc: 51.87500\n",
      "[1, 4440] train_loss: 1.79729 train_acc: 57.18750 val_loss: 2.08618 val_acc: 50.00000\n",
      "[1, 4450] train_loss: 1.73563 train_acc: 54.68750 val_loss: 1.91713 val_acc: 55.00000\n",
      "[1, 4460] train_loss: 1.82813 train_acc: 54.37500 val_loss: 1.86199 val_acc: 56.25000\n",
      "[1, 4470] train_loss: 1.65704 train_acc: 56.87500 val_loss: 1.89554 val_acc: 58.12500\n",
      "[1, 4480] train_loss: 1.86688 train_acc: 53.75000 val_loss: 2.18986 val_acc: 48.12500\n",
      "[1, 4490] train_loss: 1.88288 train_acc: 54.68750 val_loss: 1.99915 val_acc: 51.87500\n",
      "[1, 4500] train_loss: 1.72158 train_acc: 59.37500 val_loss: 2.07607 val_acc: 51.25000\n",
      "[1, 4510] train_loss: 1.80298 train_acc: 55.62500 val_loss: 2.02932 val_acc: 48.12500\n",
      "[1, 4520] train_loss: 1.78415 train_acc: 55.00000 val_loss: 1.68597 val_acc: 58.12500\n",
      "[1, 4530] train_loss: 1.69908 train_acc: 56.25000 val_loss: 1.84489 val_acc: 56.25000\n",
      "[1, 4540] train_loss: 1.63556 train_acc: 58.75000 val_loss: 1.79813 val_acc: 59.37500\n",
      "[1, 4550] train_loss: 1.80841 train_acc: 53.75000 val_loss: 1.77592 val_acc: 61.87500\n",
      "[1, 4560] train_loss: 1.63040 train_acc: 58.43750 val_loss: 1.97881 val_acc: 53.75000\n",
      "[1, 4570] train_loss: 1.67412 train_acc: 58.43750 val_loss: 1.88153 val_acc: 54.37500\n",
      "[1, 4580] train_loss: 1.83223 train_acc: 56.25000 val_loss: 1.99580 val_acc: 51.25000\n",
      "[1, 4590] train_loss: 1.73759 train_acc: 56.87500 val_loss: 2.06665 val_acc: 48.12500\n",
      "[1, 4600] train_loss: 1.73312 train_acc: 55.93750 val_loss: 1.88374 val_acc: 58.75000\n",
      "[1, 4610] train_loss: 1.62719 train_acc: 60.31250 val_loss: 2.22650 val_acc: 48.75000\n",
      "[1, 4620] train_loss: 1.74287 train_acc: 55.00000 val_loss: 2.00511 val_acc: 56.87500\n",
      "[1, 4630] train_loss: 1.78599 train_acc: 55.00000 val_loss: 2.06415 val_acc: 53.75000\n",
      "[1, 4640] train_loss: 1.74222 train_acc: 56.25000 val_loss: 1.97046 val_acc: 55.00000\n",
      "[1, 4650] train_loss: 1.78510 train_acc: 55.00000 val_loss: 1.85300 val_acc: 57.50000\n",
      "[1, 4660] train_loss: 1.77451 train_acc: 56.87500 val_loss: 1.83727 val_acc: 54.37500\n",
      "[1, 4670] train_loss: 1.70441 train_acc: 58.12500 val_loss: 1.85311 val_acc: 53.12500\n",
      "[1, 4680] train_loss: 1.63791 train_acc: 62.18750 val_loss: 1.82150 val_acc: 56.25000\n",
      "[1, 4690] train_loss: 1.67010 train_acc: 57.50000 val_loss: 2.00995 val_acc: 52.50000\n",
      "[1, 4700] train_loss: 1.70515 train_acc: 60.31250 val_loss: 1.96765 val_acc: 56.87500\n",
      "[1, 4710] train_loss: 1.74310 train_acc: 56.25000 val_loss: 1.94445 val_acc: 56.25000\n",
      "[1, 4720] train_loss: 1.65906 train_acc: 61.25000 val_loss: 1.74984 val_acc: 62.50000\n",
      "[1, 4730] train_loss: 1.77941 train_acc: 53.43750 val_loss: 2.15720 val_acc: 53.12500\n",
      "[1, 4740] train_loss: 1.71975 train_acc: 57.50000 val_loss: 1.88261 val_acc: 57.50000\n",
      "[1, 4750] train_loss: 1.84514 train_acc: 52.18750 val_loss: 1.97573 val_acc: 54.37500\n",
      "[1, 4760] train_loss: 1.60572 train_acc: 62.18750 val_loss: 1.60482 val_acc: 63.12500\n",
      "[1, 4770] train_loss: 1.71170 train_acc: 56.56250 val_loss: 2.15062 val_acc: 49.37500\n",
      "[1, 4780] train_loss: 1.66196 train_acc: 56.87500 val_loss: 1.81319 val_acc: 55.62500\n",
      "[1, 4790] train_loss: 1.86662 train_acc: 52.81250 val_loss: 1.96445 val_acc: 50.62500\n",
      "[1, 4800] train_loss: 1.84244 train_acc: 54.06250 val_loss: 2.04097 val_acc: 57.50000\n",
      "[1, 4810] train_loss: 1.57744 train_acc: 60.31250 val_loss: 1.82946 val_acc: 58.12500\n",
      "[1, 4820] train_loss: 1.58879 train_acc: 63.75000 val_loss: 1.75445 val_acc: 63.12500\n",
      "[1, 4830] train_loss: 1.71564 train_acc: 57.81250 val_loss: 2.09910 val_acc: 55.00000\n",
      "[1, 4840] train_loss: 1.58748 train_acc: 64.06250 val_loss: 2.20229 val_acc: 48.12500\n",
      "[1, 4850] train_loss: 1.69725 train_acc: 56.25000 val_loss: 2.08337 val_acc: 48.75000\n",
      "[1, 4860] train_loss: 1.75932 train_acc: 54.06250 val_loss: 1.99040 val_acc: 54.37500\n",
      "[1, 4870] train_loss: 1.68957 train_acc: 56.56250 val_loss: 1.62402 val_acc: 61.25000\n",
      "[1, 4880] train_loss: 1.76155 train_acc: 56.56250 val_loss: 1.95377 val_acc: 54.37500\n",
      "[1, 4890] train_loss: 1.69550 train_acc: 58.12500 val_loss: 1.69133 val_acc: 61.87500\n",
      "[1, 4900] train_loss: 1.85607 train_acc: 53.75000 val_loss: 2.01697 val_acc: 57.50000\n",
      "[1, 4910] train_loss: 1.69340 train_acc: 55.93750 val_loss: 2.15242 val_acc: 51.87500\n",
      "[1, 4920] train_loss: 1.81923 train_acc: 56.56250 val_loss: 2.01035 val_acc: 55.00000\n",
      "[1, 4930] train_loss: 1.68383 train_acc: 58.75000 val_loss: 2.01285 val_acc: 51.87500\n",
      "[1, 4940] train_loss: 1.77481 train_acc: 55.00000 val_loss: 1.75895 val_acc: 56.87500\n",
      "[1, 4950] train_loss: 1.62288 train_acc: 59.68750 val_loss: 1.65666 val_acc: 61.87500\n",
      "[1, 4960] train_loss: 1.72563 train_acc: 55.62500 val_loss: 1.85502 val_acc: 58.75000\n",
      "[1, 4970] train_loss: 1.70144 train_acc: 59.06250 val_loss: 1.83641 val_acc: 60.62500\n",
      "[1, 4980] train_loss: 1.56811 train_acc: 63.43750 val_loss: 2.41419 val_acc: 47.50000\n",
      "[1, 4990] train_loss: 1.67345 train_acc: 58.12500 val_loss: 1.83918 val_acc: 60.00000\n",
      "[1, 5000] train_loss: 1.59990 train_acc: 59.68750 val_loss: 1.85319 val_acc: 56.25000\n",
      "[1, 5010] train_loss: 1.58513 train_acc: 60.93750 val_loss: 1.71181 val_acc: 58.75000\n",
      "[1, 5020] train_loss: 1.76701 train_acc: 56.25000 val_loss: 1.71247 val_acc: 63.12500\n",
      "[1, 5030] train_loss: 1.60736 train_acc: 60.31250 val_loss: 1.96592 val_acc: 56.25000\n",
      "[1, 5040] train_loss: 1.53720 train_acc: 63.75000 val_loss: 1.67376 val_acc: 61.87500\n",
      "[1, 5050] train_loss: 1.76381 train_acc: 58.43750 val_loss: 1.79115 val_acc: 56.25000\n",
      "[1, 5060] train_loss: 1.79977 train_acc: 55.93750 val_loss: 2.20831 val_acc: 48.75000\n",
      "[1, 5070] train_loss: 1.67388 train_acc: 57.81250 val_loss: 1.67481 val_acc: 59.37500\n",
      "[1, 5080] train_loss: 1.69739 train_acc: 60.62500 val_loss: 1.68628 val_acc: 61.25000\n",
      "[1, 5090] train_loss: 1.64485 train_acc: 62.81250 val_loss: 1.63307 val_acc: 66.25000\n",
      "[1, 5100] train_loss: 1.71328 train_acc: 60.31250 val_loss: 1.92560 val_acc: 57.50000\n",
      "[1, 5110] train_loss: 1.73354 train_acc: 56.56250 val_loss: 1.80948 val_acc: 55.62500\n",
      "[1, 5120] train_loss: 1.46877 train_acc: 65.00000 val_loss: 1.84991 val_acc: 58.12500\n",
      "[1, 5130] train_loss: 1.66739 train_acc: 60.00000 val_loss: 1.82719 val_acc: 57.50000\n",
      "[1, 5140] train_loss: 1.75449 train_acc: 53.43750 val_loss: 1.76400 val_acc: 57.50000\n",
      "[1, 5150] train_loss: 1.70928 train_acc: 58.43750 val_loss: 1.76716 val_acc: 58.75000\n",
      "[1, 5160] train_loss: 1.55259 train_acc: 62.50000 val_loss: 1.51548 val_acc: 60.62500\n",
      "[1, 5170] train_loss: 1.77794 train_acc: 58.75000 val_loss: 2.10581 val_acc: 48.75000\n",
      "[1, 5180] train_loss: 1.56133 train_acc: 58.75000 val_loss: 1.65483 val_acc: 58.12500\n",
      "[1, 5190] train_loss: 1.57268 train_acc: 62.50000 val_loss: 1.68341 val_acc: 63.75000\n",
      "[1, 5200] train_loss: 1.70682 train_acc: 57.81250 val_loss: 1.84396 val_acc: 59.37500\n",
      "[1, 5210] train_loss: 1.61140 train_acc: 58.43750 val_loss: 1.73534 val_acc: 60.00000\n",
      "[1, 5220] train_loss: 1.73706 train_acc: 54.68750 val_loss: 1.80944 val_acc: 58.12500\n",
      "[1, 5230] train_loss: 1.74139 train_acc: 60.00000 val_loss: 1.62793 val_acc: 61.25000\n",
      "[1, 5240] train_loss: 1.64732 train_acc: 58.75000 val_loss: 1.85181 val_acc: 56.25000\n",
      "[1, 5250] train_loss: 1.74740 train_acc: 57.18750 val_loss: 2.07921 val_acc: 50.00000\n",
      "[1, 5260] train_loss: 1.62318 train_acc: 63.75000 val_loss: 1.70710 val_acc: 59.37500\n",
      "[1, 5270] train_loss: 1.83406 train_acc: 57.50000 val_loss: 1.99654 val_acc: 50.62500\n",
      "[1, 5280] train_loss: 1.59452 train_acc: 63.43750 val_loss: 1.62514 val_acc: 63.75000\n",
      "[1, 5290] train_loss: 1.66980 train_acc: 57.81250 val_loss: 1.56280 val_acc: 64.37500\n",
      "[1, 5300] train_loss: 1.59116 train_acc: 62.18750 val_loss: 1.66944 val_acc: 61.87500\n",
      "[1, 5310] train_loss: 1.79379 train_acc: 54.37500 val_loss: 1.92094 val_acc: 53.75000\n",
      "[1, 5320] train_loss: 1.51885 train_acc: 62.81250 val_loss: 1.85540 val_acc: 54.37500\n",
      "[1, 5330] train_loss: 1.62618 train_acc: 64.06250 val_loss: 1.82408 val_acc: 55.62500\n",
      "[1, 5340] train_loss: 1.48631 train_acc: 61.56250 val_loss: 1.92564 val_acc: 55.62500\n",
      "[1, 5350] train_loss: 1.52444 train_acc: 59.68750 val_loss: 1.52639 val_acc: 63.75000\n",
      "[1, 5360] train_loss: 1.62435 train_acc: 62.18750 val_loss: 1.70375 val_acc: 61.87500\n",
      "[1, 5370] train_loss: 1.65392 train_acc: 55.93750 val_loss: 1.70443 val_acc: 63.75000\n",
      "[1, 5380] train_loss: 1.65021 train_acc: 57.18750 val_loss: 1.88225 val_acc: 56.87500\n",
      "[1, 5390] train_loss: 1.62268 train_acc: 57.50000 val_loss: 1.71668 val_acc: 55.00000\n",
      "[1, 5400] train_loss: 1.65882 train_acc: 58.75000 val_loss: 1.65873 val_acc: 60.62500\n",
      "[1, 5410] train_loss: 1.52688 train_acc: 59.37500 val_loss: 1.55993 val_acc: 58.12500\n",
      "[1, 5420] train_loss: 1.60671 train_acc: 60.62500 val_loss: 1.68455 val_acc: 61.87500\n",
      "[1, 5430] train_loss: 1.47047 train_acc: 64.68750 val_loss: 1.99436 val_acc: 53.75000\n",
      "[1, 5440] train_loss: 1.71438 train_acc: 59.06250 val_loss: 1.56789 val_acc: 61.87500\n",
      "[1, 5450] train_loss: 1.60061 train_acc: 61.56250 val_loss: 1.82694 val_acc: 58.12500\n",
      "[1, 5460] train_loss: 1.58974 train_acc: 61.87500 val_loss: 1.58723 val_acc: 62.50000\n",
      "[1, 5470] train_loss: 1.42458 train_acc: 63.75000 val_loss: 1.52037 val_acc: 64.37500\n",
      "[1, 5480] train_loss: 1.83621 train_acc: 55.31250 val_loss: 1.79389 val_acc: 55.00000\n",
      "[1, 5490] train_loss: 1.67077 train_acc: 59.06250 val_loss: 1.50209 val_acc: 61.25000\n",
      "[1, 5500] train_loss: 1.67154 train_acc: 59.37500 val_loss: 1.73819 val_acc: 60.62500\n",
      "[1, 5510] train_loss: 1.48310 train_acc: 63.12500 val_loss: 1.48137 val_acc: 69.37500\n",
      "[1, 5520] train_loss: 1.62553 train_acc: 57.81250 val_loss: 1.76348 val_acc: 61.87500\n",
      "[1, 5530] train_loss: 1.56477 train_acc: 61.56250 val_loss: 1.68738 val_acc: 60.62500\n",
      "[1, 5540] train_loss: 1.48789 train_acc: 65.00000 val_loss: 1.94224 val_acc: 55.62500\n",
      "[1, 5550] train_loss: 1.63825 train_acc: 58.43750 val_loss: 1.76012 val_acc: 59.37500\n",
      "[1, 5560] train_loss: 1.65860 train_acc: 58.12500 val_loss: 1.80801 val_acc: 59.37500\n",
      "[1, 5570] train_loss: 1.58117 train_acc: 54.06250 val_loss: 1.73166 val_acc: 60.00000\n",
      "[1, 5580] train_loss: 1.66195 train_acc: 59.68750 val_loss: 1.62123 val_acc: 63.12500\n",
      "[1, 5590] train_loss: 1.46124 train_acc: 63.43750 val_loss: 1.51285 val_acc: 63.75000\n",
      "[1, 5600] train_loss: 1.57507 train_acc: 63.12500 val_loss: 1.87943 val_acc: 56.25000\n",
      "[1, 5610] train_loss: 1.26507 train_acc: 67.18750 val_loss: 1.48404 val_acc: 63.12500\n",
      "[1, 5620] train_loss: 1.58902 train_acc: 59.37500 val_loss: 1.79436 val_acc: 58.12500\n",
      "[1, 5630] train_loss: 1.51990 train_acc: 62.18750 val_loss: 1.79593 val_acc: 56.87500\n",
      "[1, 5640] train_loss: 1.75860 train_acc: 54.06250 val_loss: 1.90171 val_acc: 60.62500\n",
      "[1, 5650] train_loss: 1.53702 train_acc: 60.93750 val_loss: 1.64559 val_acc: 61.25000\n",
      "[1, 5660] train_loss: 1.44096 train_acc: 64.68750 val_loss: 1.61286 val_acc: 57.50000\n",
      "[1, 5670] train_loss: 1.53420 train_acc: 62.50000 val_loss: 1.75025 val_acc: 59.37500\n",
      "[1, 5680] train_loss: 1.36647 train_acc: 66.56250 val_loss: 1.69730 val_acc: 57.50000\n",
      "[1, 5690] train_loss: 1.51885 train_acc: 62.81250 val_loss: 1.73112 val_acc: 61.25000\n",
      "[1, 5700] train_loss: 1.74825 train_acc: 55.93750 val_loss: 1.77221 val_acc: 56.87500\n",
      "[1, 5710] train_loss: 1.70604 train_acc: 59.37500 val_loss: 1.69292 val_acc: 59.37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5720] train_loss: 1.41976 train_acc: 66.56250 val_loss: 1.59055 val_acc: 63.12500\n",
      "[1, 5730] train_loss: 1.61125 train_acc: 64.06250 val_loss: 1.80956 val_acc: 56.87500\n",
      "[1, 5740] train_loss: 1.30091 train_acc: 67.18750 val_loss: 1.73321 val_acc: 57.50000\n",
      "[1, 5750] train_loss: 1.53677 train_acc: 59.68750 val_loss: 1.59134 val_acc: 63.12500\n",
      "[1, 5760] train_loss: 1.50625 train_acc: 60.62500 val_loss: 1.93314 val_acc: 54.37500\n",
      "[1, 5770] train_loss: 1.46670 train_acc: 62.50000 val_loss: 1.82024 val_acc: 55.62500\n",
      "[1, 5780] train_loss: 1.61097 train_acc: 61.56250 val_loss: 1.48408 val_acc: 65.00000\n",
      "[1, 5790] train_loss: 1.49657 train_acc: 64.06250 val_loss: 1.43776 val_acc: 64.37500\n",
      "[1, 5800] train_loss: 1.51005 train_acc: 58.43750 val_loss: 1.65653 val_acc: 58.75000\n",
      "[1, 5810] train_loss: 1.48550 train_acc: 61.56250 val_loss: 1.73988 val_acc: 59.37500\n",
      "[1, 5820] train_loss: 1.32139 train_acc: 68.43750 val_loss: 1.53954 val_acc: 61.87500\n",
      "[1, 5830] train_loss: 1.69923 train_acc: 60.93750 val_loss: 1.72049 val_acc: 56.87500\n",
      "[1, 5840] train_loss: 1.47853 train_acc: 63.12500 val_loss: 1.78681 val_acc: 58.12500\n",
      "[1, 5850] train_loss: 1.47497 train_acc: 60.31250 val_loss: 1.56788 val_acc: 67.50000\n",
      "[1, 5860] train_loss: 1.58350 train_acc: 61.25000 val_loss: 1.65794 val_acc: 61.25000\n",
      "[1, 5870] train_loss: 1.42784 train_acc: 66.87500 val_loss: 1.64570 val_acc: 59.37500\n",
      "[1, 5880] train_loss: 1.54020 train_acc: 62.81250 val_loss: 1.87688 val_acc: 53.12500\n",
      "[1, 5890] train_loss: 1.39075 train_acc: 66.25000 val_loss: 1.57336 val_acc: 60.62500\n",
      "[1, 5900] train_loss: 1.51027 train_acc: 65.00000 val_loss: 1.45631 val_acc: 65.62500\n",
      "[1, 5910] train_loss: 1.58949 train_acc: 60.93750 val_loss: 1.49489 val_acc: 63.75000\n",
      "[1, 5920] train_loss: 1.49237 train_acc: 65.00000 val_loss: 2.16117 val_acc: 46.25000\n",
      "[1, 5930] train_loss: 1.59196 train_acc: 58.75000 val_loss: 1.51871 val_acc: 65.62500\n",
      "[1, 5940] train_loss: 1.39031 train_acc: 65.62500 val_loss: 1.98477 val_acc: 54.37500\n",
      "[1, 5950] train_loss: 1.53861 train_acc: 60.93750 val_loss: 1.65287 val_acc: 58.75000\n",
      "[1, 5960] train_loss: 1.36906 train_acc: 64.68750 val_loss: 1.78277 val_acc: 59.37500\n",
      "[1, 5970] train_loss: 1.41026 train_acc: 66.25000 val_loss: 1.79434 val_acc: 56.25000\n",
      "[1, 5980] train_loss: 1.37469 train_acc: 65.31250 val_loss: 1.79809 val_acc: 61.87500\n",
      "[1, 5990] train_loss: 1.48686 train_acc: 61.87500 val_loss: 1.57938 val_acc: 63.12500\n",
      "[1, 6000] train_loss: 1.64716 train_acc: 59.37500 val_loss: 1.82899 val_acc: 58.75000\n",
      "[1, 6010] train_loss: 1.52632 train_acc: 63.43750 val_loss: 1.71582 val_acc: 55.62500\n",
      "[1, 6020] train_loss: 1.59644 train_acc: 61.56250 val_loss: 1.67101 val_acc: 60.62500\n",
      "[1, 6030] train_loss: 1.43038 train_acc: 67.18750 val_loss: 1.53440 val_acc: 64.37500\n",
      "[1, 6040] train_loss: 1.47696 train_acc: 61.87500 val_loss: 1.53102 val_acc: 68.12500\n",
      "[1, 6050] train_loss: 1.52175 train_acc: 63.43750 val_loss: 1.75888 val_acc: 58.12500\n",
      "[1, 6060] train_loss: 1.62898 train_acc: 61.56250 val_loss: 1.55288 val_acc: 62.50000\n",
      "[1, 6070] train_loss: 1.40901 train_acc: 64.06250 val_loss: 1.50798 val_acc: 60.00000\n",
      "[1, 6080] train_loss: 1.51409 train_acc: 63.75000 val_loss: 1.68436 val_acc: 55.62500\n",
      "[1, 6090] train_loss: 1.47061 train_acc: 62.81250 val_loss: 1.68150 val_acc: 59.37500\n",
      "[1, 6100] train_loss: 1.43048 train_acc: 64.68750 val_loss: 1.75857 val_acc: 55.62500\n",
      "[1, 6110] train_loss: 1.43096 train_acc: 63.43750 val_loss: 1.51369 val_acc: 63.12500\n",
      "[1, 6120] train_loss: 1.53190 train_acc: 62.18750 val_loss: 1.75295 val_acc: 59.37500\n",
      "[1, 6130] train_loss: 1.55048 train_acc: 60.62500 val_loss: 1.62616 val_acc: 59.37500\n",
      "[1, 6140] train_loss: 1.54497 train_acc: 61.25000 val_loss: 1.50656 val_acc: 66.25000\n",
      "[1, 6150] train_loss: 1.37366 train_acc: 64.68750 val_loss: 2.05332 val_acc: 46.87500\n",
      "[1, 6160] train_loss: 1.43387 train_acc: 64.06250 val_loss: 1.81658 val_acc: 55.00000\n",
      "[1, 6170] train_loss: 1.28392 train_acc: 65.31250 val_loss: 1.34019 val_acc: 68.12500\n",
      "[1, 6180] train_loss: 1.56592 train_acc: 59.68750 val_loss: 1.90213 val_acc: 55.00000\n",
      "[1, 6190] train_loss: 1.54419 train_acc: 63.43750 val_loss: 1.53968 val_acc: 63.12500\n",
      "[1, 6200] train_loss: 1.37130 train_acc: 64.37500 val_loss: 1.71952 val_acc: 65.00000\n",
      "[1, 6210] train_loss: 1.55347 train_acc: 61.56250 val_loss: 1.45937 val_acc: 69.37500\n",
      "[1, 6220] train_loss: 1.48638 train_acc: 60.93750 val_loss: 1.73343 val_acc: 59.37500\n",
      "[1, 6230] train_loss: 1.55741 train_acc: 61.87500 val_loss: 1.66214 val_acc: 58.75000\n",
      "[1, 6240] train_loss: 1.46018 train_acc: 68.43750 val_loss: 1.40994 val_acc: 66.87500\n",
      "[1, 6250] train_loss: 1.37125 train_acc: 65.62500 val_loss: 1.36069 val_acc: 67.50000\n",
      "[1, 6260] train_loss: 1.52340 train_acc: 64.37500 val_loss: 1.80295 val_acc: 55.62500\n",
      "[1, 6270] train_loss: 1.38489 train_acc: 64.68750 val_loss: 1.67699 val_acc: 58.12500\n",
      "[1, 6280] train_loss: 1.45430 train_acc: 63.43750 val_loss: 1.64676 val_acc: 62.50000\n",
      "[1, 6290] train_loss: 1.47781 train_acc: 63.43750 val_loss: 1.50485 val_acc: 63.12500\n",
      "[1, 6300] train_loss: 1.46859 train_acc: 64.37500 val_loss: 1.79484 val_acc: 61.25000\n",
      "[1, 6310] train_loss: 1.40513 train_acc: 66.87500 val_loss: 1.78610 val_acc: 55.00000\n",
      "[1, 6320] train_loss: 1.43015 train_acc: 65.62500 val_loss: 1.60914 val_acc: 65.00000\n",
      "[1, 6330] train_loss: 1.53551 train_acc: 64.68750 val_loss: 1.45348 val_acc: 64.37500\n",
      "[1, 6340] train_loss: 1.45438 train_acc: 60.62500 val_loss: 1.60021 val_acc: 65.00000\n",
      "[1, 6350] train_loss: 1.43468 train_acc: 65.62500 val_loss: 1.71224 val_acc: 58.12500\n",
      "[1, 6360] train_loss: 1.43820 train_acc: 65.00000 val_loss: 1.38074 val_acc: 68.75000\n",
      "[1, 6370] train_loss: 1.54049 train_acc: 61.56250 val_loss: 1.56994 val_acc: 60.62500\n",
      "[1, 6380] train_loss: 1.43455 train_acc: 65.00000 val_loss: 1.77825 val_acc: 57.50000\n",
      "[1, 6390] train_loss: 1.41812 train_acc: 66.25000 val_loss: 1.74871 val_acc: 60.00000\n",
      "[1, 6400] train_loss: 1.48437 train_acc: 63.12500 val_loss: 1.41304 val_acc: 68.75000\n",
      "[1, 6410] train_loss: 1.52327 train_acc: 63.43750 val_loss: 1.61814 val_acc: 63.75000\n",
      "[1, 6420] train_loss: 1.50211 train_acc: 62.81250 val_loss: 1.50628 val_acc: 65.00000\n",
      "[1, 6430] train_loss: 1.41533 train_acc: 68.12500 val_loss: 1.40694 val_acc: 66.25000\n",
      "[1, 6440] train_loss: 1.44265 train_acc: 64.68750 val_loss: 1.52826 val_acc: 66.25000\n",
      "[1, 6450] train_loss: 1.40769 train_acc: 63.43750 val_loss: 1.64935 val_acc: 61.87500\n",
      "[1, 6460] train_loss: 1.26823 train_acc: 68.12500 val_loss: 1.36597 val_acc: 71.87500\n",
      "[1, 6470] train_loss: 1.41671 train_acc: 63.12500 val_loss: 1.53429 val_acc: 63.12500\n",
      "[1, 6480] train_loss: 1.40667 train_acc: 65.62500 val_loss: 1.93524 val_acc: 59.37500\n",
      "[1, 6490] train_loss: 1.56946 train_acc: 61.25000 val_loss: 1.60120 val_acc: 64.37500\n",
      "[1, 6500] train_loss: 1.45452 train_acc: 59.37500 val_loss: 1.58818 val_acc: 58.12500\n",
      "[1, 6510] train_loss: 1.28029 train_acc: 66.25000 val_loss: 1.86321 val_acc: 58.75000\n",
      "[1, 6520] train_loss: 1.32377 train_acc: 65.00000 val_loss: 1.84072 val_acc: 53.12500\n",
      "[1, 6530] train_loss: 1.34038 train_acc: 66.56250 val_loss: 1.54323 val_acc: 60.00000\n",
      "[1, 6540] train_loss: 1.42399 train_acc: 62.81250 val_loss: 1.68022 val_acc: 58.12500\n",
      "[1, 6550] train_loss: 1.46916 train_acc: 64.37500 val_loss: 1.49078 val_acc: 63.12500\n",
      "[1, 6560] train_loss: 1.42092 train_acc: 65.31250 val_loss: 1.54678 val_acc: 65.00000\n",
      "[1, 6570] train_loss: 1.41650 train_acc: 64.37500 val_loss: 1.80905 val_acc: 60.00000\n",
      "[1, 6580] train_loss: 1.41520 train_acc: 65.00000 val_loss: 1.80547 val_acc: 59.37500\n",
      "[1, 6590] train_loss: 1.40116 train_acc: 64.37500 val_loss: 1.61779 val_acc: 65.00000\n",
      "[1, 6600] train_loss: 1.40750 train_acc: 64.06250 val_loss: 1.45315 val_acc: 61.25000\n",
      "[1, 6610] train_loss: 1.49613 train_acc: 62.81250 val_loss: 1.70090 val_acc: 59.37500\n",
      "[1, 6620] train_loss: 1.53126 train_acc: 61.87500 val_loss: 1.82005 val_acc: 63.12500\n",
      "[1, 6630] train_loss: 1.25280 train_acc: 68.43750 val_loss: 1.56690 val_acc: 63.75000\n",
      "[1, 6640] train_loss: 1.50545 train_acc: 64.06250 val_loss: 1.77996 val_acc: 55.00000\n",
      "[1, 6650] train_loss: 1.50303 train_acc: 62.50000 val_loss: 1.55364 val_acc: 62.50000\n",
      "[1, 6660] train_loss: 1.41546 train_acc: 65.62500 val_loss: 1.49480 val_acc: 61.25000\n",
      "[1, 6670] train_loss: 1.58077 train_acc: 60.62500 val_loss: 1.45087 val_acc: 65.62500\n",
      "[1, 6680] train_loss: 1.21221 train_acc: 68.43750 val_loss: 1.86864 val_acc: 58.75000\n",
      "[1, 6690] train_loss: 1.36157 train_acc: 66.25000 val_loss: 1.52073 val_acc: 63.12500\n",
      "[1, 6700] train_loss: 1.20292 train_acc: 70.93750 val_loss: 1.52825 val_acc: 64.37500\n",
      "[1, 6710] train_loss: 1.47816 train_acc: 60.93750 val_loss: 1.65083 val_acc: 62.50000\n",
      "[1, 6720] train_loss: 1.45354 train_acc: 64.06250 val_loss: 1.62089 val_acc: 61.87500\n",
      "[1, 6730] train_loss: 1.33284 train_acc: 66.25000 val_loss: 1.77347 val_acc: 58.12500\n",
      "[1, 6740] train_loss: 1.35840 train_acc: 64.06250 val_loss: 1.61108 val_acc: 64.37500\n",
      "[1, 6750] train_loss: 1.29882 train_acc: 68.75000 val_loss: 1.77377 val_acc: 57.50000\n",
      "[1, 6760] train_loss: 1.39047 train_acc: 62.50000 val_loss: 1.59638 val_acc: 62.50000\n",
      "[1, 6770] train_loss: 1.49740 train_acc: 63.43750 val_loss: 1.54596 val_acc: 62.50000\n",
      "[1, 6780] train_loss: 1.49640 train_acc: 63.12500 val_loss: 1.49329 val_acc: 62.50000\n",
      "[1, 6790] train_loss: 1.43035 train_acc: 65.31250 val_loss: 1.58173 val_acc: 62.50000\n",
      "[1, 6800] train_loss: 1.44354 train_acc: 63.75000 val_loss: 1.43224 val_acc: 64.37500\n",
      "[1, 6810] train_loss: 1.31409 train_acc: 64.68750 val_loss: 1.65983 val_acc: 61.87500\n",
      "[1, 6820] train_loss: 1.50515 train_acc: 61.87500 val_loss: 1.60793 val_acc: 60.62500\n",
      "[1, 6830] train_loss: 1.54357 train_acc: 60.00000 val_loss: 1.79014 val_acc: 60.00000\n",
      "[1, 6840] train_loss: 1.35752 train_acc: 68.12500 val_loss: 1.65874 val_acc: 58.75000\n",
      "[1, 6850] train_loss: 1.33274 train_acc: 65.00000 val_loss: 1.41770 val_acc: 63.75000\n",
      "[1, 6860] train_loss: 1.19531 train_acc: 69.37500 val_loss: 1.51217 val_acc: 63.12500\n",
      "[1, 6870] train_loss: 1.27034 train_acc: 69.06250 val_loss: 1.69298 val_acc: 61.25000\n",
      "[1, 6880] train_loss: 1.49433 train_acc: 64.68750 val_loss: 1.46175 val_acc: 65.62500\n",
      "[1, 6890] train_loss: 1.30297 train_acc: 64.06250 val_loss: 1.62760 val_acc: 58.12500\n",
      "[1, 6900] train_loss: 1.38700 train_acc: 65.31250 val_loss: 1.52889 val_acc: 62.50000\n",
      "[1, 6910] train_loss: 1.44571 train_acc: 63.12500 val_loss: 1.42520 val_acc: 66.87500\n",
      "[1, 6920] train_loss: 1.38493 train_acc: 67.81250 val_loss: 1.41978 val_acc: 71.25000\n",
      "[1, 6930] train_loss: 1.48479 train_acc: 64.37500 val_loss: 1.69346 val_acc: 61.25000\n",
      "[1, 6940] train_loss: 1.28329 train_acc: 67.18750 val_loss: 1.33391 val_acc: 69.37500\n",
      "[1, 6950] train_loss: 1.29382 train_acc: 69.37500 val_loss: 1.50467 val_acc: 67.50000\n",
      "[1, 6960] train_loss: 1.21342 train_acc: 66.56250 val_loss: 1.56947 val_acc: 63.12500\n",
      "[1, 6970] train_loss: 1.38627 train_acc: 67.50000 val_loss: 1.52989 val_acc: 68.75000\n",
      "[1, 6980] train_loss: 1.39551 train_acc: 65.31250 val_loss: 1.47453 val_acc: 65.00000\n",
      "[1, 6990] train_loss: 1.51484 train_acc: 60.62500 val_loss: 1.51356 val_acc: 61.87500\n",
      "[1, 7000] train_loss: 1.39108 train_acc: 65.93750 val_loss: 1.36564 val_acc: 67.50000\n",
      "[1, 7010] train_loss: 1.46405 train_acc: 62.18750 val_loss: 1.49913 val_acc: 63.12500\n",
      "[1, 7020] train_loss: 1.30734 train_acc: 67.18750 val_loss: 1.72208 val_acc: 59.37500\n",
      "[1, 7030] train_loss: 1.27229 train_acc: 70.93750 val_loss: 1.54867 val_acc: 65.00000\n",
      "[1, 7040] train_loss: 1.21668 train_acc: 67.18750 val_loss: 1.46881 val_acc: 63.75000\n",
      "[1, 7050] train_loss: 1.35700 train_acc: 67.18750 val_loss: 1.62243 val_acc: 61.87500\n",
      "[1, 7060] train_loss: 1.38611 train_acc: 61.87500 val_loss: 1.70717 val_acc: 60.00000\n",
      "[1, 7070] train_loss: 1.21814 train_acc: 69.06250 val_loss: 1.50686 val_acc: 62.50000\n",
      "[1, 7080] train_loss: 1.26883 train_acc: 69.68750 val_loss: 1.68381 val_acc: 57.50000\n",
      "[1, 7090] train_loss: 1.26235 train_acc: 67.81250 val_loss: 1.12415 val_acc: 71.25000\n",
      "[1, 7100] train_loss: 1.28799 train_acc: 70.31250 val_loss: 1.71418 val_acc: 56.87500\n",
      "[1, 7110] train_loss: 1.39133 train_acc: 64.37500 val_loss: 1.37670 val_acc: 65.62500\n",
      "[1, 7120] train_loss: 1.27430 train_acc: 68.12500 val_loss: 1.51486 val_acc: 65.00000\n",
      "[1, 7130] train_loss: 1.24294 train_acc: 69.37500 val_loss: 1.41174 val_acc: 67.50000\n",
      "[1, 7140] train_loss: 1.32025 train_acc: 68.12500 val_loss: 1.36747 val_acc: 70.00000\n",
      "[1, 7150] train_loss: 1.22259 train_acc: 70.00000 val_loss: 1.51322 val_acc: 61.87500\n",
      "[1, 7160] train_loss: 1.35351 train_acc: 64.06250 val_loss: 1.55824 val_acc: 63.12500\n",
      "[1, 7170] train_loss: 1.32618 train_acc: 65.31250 val_loss: 1.45485 val_acc: 61.87500\n",
      "[1, 7180] train_loss: 1.33316 train_acc: 64.68750 val_loss: 1.53486 val_acc: 61.25000\n",
      "[1, 7190] train_loss: 1.32125 train_acc: 68.75000 val_loss: 1.58013 val_acc: 57.50000\n",
      "[1, 7200] train_loss: 1.30264 train_acc: 66.25000 val_loss: 1.41949 val_acc: 64.37500\n",
      "[1, 7210] train_loss: 1.37959 train_acc: 64.06250 val_loss: 1.54908 val_acc: 65.00000\n",
      "[1, 7220] train_loss: 1.29183 train_acc: 64.37500 val_loss: 1.40818 val_acc: 66.87500\n",
      "[1, 7230] train_loss: 1.27165 train_acc: 70.00000 val_loss: 1.48342 val_acc: 60.62500\n",
      "[1, 7240] train_loss: 1.35519 train_acc: 66.25000 val_loss: 1.64171 val_acc: 62.50000\n",
      "[1, 7250] train_loss: 1.28488 train_acc: 66.25000 val_loss: 1.37526 val_acc: 69.37500\n",
      "[1, 7260] train_loss: 1.18577 train_acc: 67.50000 val_loss: 1.31894 val_acc: 70.62500\n",
      "[1, 7270] train_loss: 1.27049 train_acc: 68.12500 val_loss: 1.38989 val_acc: 66.87500\n",
      "[1, 7280] train_loss: 1.33815 train_acc: 65.00000 val_loss: 1.41375 val_acc: 67.50000\n",
      "[1, 7290] train_loss: 1.45506 train_acc: 64.06250 val_loss: 1.40312 val_acc: 69.37500\n",
      "[1, 7300] train_loss: 1.23246 train_acc: 65.93750 val_loss: 1.52425 val_acc: 62.50000\n",
      "[1, 7310] train_loss: 1.30160 train_acc: 68.12500 val_loss: 1.61664 val_acc: 58.12500\n",
      "[1, 7320] train_loss: 1.36487 train_acc: 66.25000 val_loss: 1.31258 val_acc: 70.00000\n",
      "[1, 7330] train_loss: 1.22471 train_acc: 65.93750 val_loss: 1.67759 val_acc: 66.25000\n",
      "[1, 7340] train_loss: 1.39518 train_acc: 65.00000 val_loss: 1.76571 val_acc: 57.50000\n",
      "[1, 7350] train_loss: 1.20264 train_acc: 70.93750 val_loss: 1.43501 val_acc: 63.75000\n",
      "[1, 7360] train_loss: 1.14410 train_acc: 68.75000 val_loss: 1.65722 val_acc: 58.75000\n",
      "[1, 7370] train_loss: 1.31878 train_acc: 65.31250 val_loss: 1.71689 val_acc: 60.00000\n",
      "[1, 7380] train_loss: 1.30571 train_acc: 67.18750 val_loss: 1.62380 val_acc: 61.87500\n",
      "[1, 7390] train_loss: 1.29452 train_acc: 68.43750 val_loss: 1.53328 val_acc: 63.75000\n",
      "[1, 7400] train_loss: 1.21257 train_acc: 67.81250 val_loss: 1.62828 val_acc: 60.00000\n",
      "[1, 7410] train_loss: 1.48109 train_acc: 60.62500 val_loss: 1.36650 val_acc: 68.12500\n",
      "[1, 7420] train_loss: 1.27935 train_acc: 65.93750 val_loss: 1.26788 val_acc: 71.25000\n",
      "[1, 7430] train_loss: 1.17670 train_acc: 72.81250 val_loss: 1.85417 val_acc: 56.25000\n",
      "[1, 7440] train_loss: 1.44038 train_acc: 65.93750 val_loss: 1.48713 val_acc: 60.62500\n",
      "[1, 7450] train_loss: 1.25377 train_acc: 70.93750 val_loss: 1.61790 val_acc: 62.50000\n",
      "[1, 7460] train_loss: 1.53971 train_acc: 62.81250 val_loss: 1.45449 val_acc: 61.25000\n",
      "[1, 7470] train_loss: 1.15248 train_acc: 70.00000 val_loss: 1.49084 val_acc: 63.75000\n",
      "[1, 7480] train_loss: 1.20600 train_acc: 69.06250 val_loss: 1.54272 val_acc: 63.75000\n",
      "[1, 7490] train_loss: 1.16707 train_acc: 71.87500 val_loss: 1.65519 val_acc: 60.62500\n",
      "[1, 7500] train_loss: 1.44573 train_acc: 65.62500 val_loss: 1.29158 val_acc: 66.87500\n",
      "[1, 7510] train_loss: 1.34038 train_acc: 70.00000 val_loss: 1.55447 val_acc: 65.62500\n",
      "[1, 7520] train_loss: 1.38241 train_acc: 65.93750 val_loss: 1.46054 val_acc: 67.50000\n",
      "[1, 7530] train_loss: 1.51608 train_acc: 63.12500 val_loss: 1.65817 val_acc: 61.25000\n",
      "[1, 7540] train_loss: 1.18851 train_acc: 70.31250 val_loss: 1.78549 val_acc: 59.37500\n",
      "[1, 7550] train_loss: 1.31711 train_acc: 66.25000 val_loss: 1.52979 val_acc: 64.37500\n",
      "[1, 7560] train_loss: 1.14942 train_acc: 70.93750 val_loss: 1.64481 val_acc: 59.37500\n",
      "[1, 7570] train_loss: 1.35224 train_acc: 66.87500 val_loss: 1.46525 val_acc: 60.62500\n",
      "[1, 7580] train_loss: 1.33889 train_acc: 66.25000 val_loss: 1.45605 val_acc: 64.37500\n",
      "[1, 7590] train_loss: 1.28598 train_acc: 65.31250 val_loss: 1.54680 val_acc: 61.25000\n",
      "[1, 7600] train_loss: 1.39378 train_acc: 66.25000 val_loss: 1.44600 val_acc: 64.37500\n",
      "[1, 7610] train_loss: 1.38869 train_acc: 64.06250 val_loss: 1.14965 val_acc: 65.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 7620] train_loss: 1.18675 train_acc: 71.87500 val_loss: 1.51057 val_acc: 63.75000\n",
      "[1, 7630] train_loss: 1.08736 train_acc: 72.81250 val_loss: 1.68518 val_acc: 58.12500\n",
      "[1, 7640] train_loss: 1.28113 train_acc: 69.06250 val_loss: 1.77148 val_acc: 53.75000\n",
      "[1, 7650] train_loss: 1.35868 train_acc: 67.18750 val_loss: 1.39597 val_acc: 67.50000\n",
      "[1, 7660] train_loss: 1.41746 train_acc: 60.93750 val_loss: 1.30566 val_acc: 68.12500\n",
      "[1, 7670] train_loss: 1.19202 train_acc: 70.93750 val_loss: 1.27682 val_acc: 66.87500\n",
      "[1, 7680] train_loss: 1.31383 train_acc: 67.81250 val_loss: 1.61142 val_acc: 60.62500\n",
      "[1, 7690] train_loss: 1.35841 train_acc: 63.12500 val_loss: 1.60458 val_acc: 64.37500\n",
      "[1, 7700] train_loss: 1.26259 train_acc: 66.25000 val_loss: 1.50511 val_acc: 60.00000\n",
      "[1, 7710] train_loss: 1.29933 train_acc: 66.87500 val_loss: 1.58722 val_acc: 65.00000\n",
      "[1, 7720] train_loss: 1.30118 train_acc: 65.93750 val_loss: 1.56497 val_acc: 65.62500\n",
      "[1, 7730] train_loss: 1.30308 train_acc: 65.62500 val_loss: 1.41242 val_acc: 68.12500\n",
      "[1, 7740] train_loss: 1.26350 train_acc: 64.37500 val_loss: 1.41874 val_acc: 67.50000\n",
      "[1, 7750] train_loss: 1.19640 train_acc: 66.56250 val_loss: 1.44072 val_acc: 65.00000\n",
      "[1, 7760] train_loss: 1.24383 train_acc: 69.37500 val_loss: 1.50892 val_acc: 64.37500\n",
      "[1, 7770] train_loss: 1.30560 train_acc: 68.75000 val_loss: 1.48591 val_acc: 64.37500\n",
      "[1, 7780] train_loss: 1.31492 train_acc: 68.43750 val_loss: 1.31495 val_acc: 63.12500\n",
      "[1, 7790] train_loss: 1.35282 train_acc: 66.25000 val_loss: 1.54766 val_acc: 61.87500\n",
      "[1, 7800] train_loss: 1.25728 train_acc: 70.31250 val_loss: 1.28322 val_acc: 70.00000\n",
      "[1, 7810] train_loss: 1.28933 train_acc: 67.18750 val_loss: 1.52105 val_acc: 61.87500\n",
      "[1, 7820] train_loss: 1.31988 train_acc: 66.25000 val_loss: 1.54747 val_acc: 65.00000\n",
      "[1, 7830] train_loss: 1.27902 train_acc: 65.62500 val_loss: 1.61010 val_acc: 59.37500\n",
      "[1, 7840] train_loss: 1.28072 train_acc: 66.56250 val_loss: 1.42416 val_acc: 66.25000\n",
      "[1, 7850] train_loss: 1.25024 train_acc: 69.68750 val_loss: 1.59676 val_acc: 64.37500\n",
      "[1, 7860] train_loss: 1.22384 train_acc: 67.18750 val_loss: 1.36291 val_acc: 67.50000\n",
      "[1, 7870] train_loss: 1.24855 train_acc: 69.37500 val_loss: 1.40653 val_acc: 65.62500\n",
      "[1, 7880] train_loss: 1.27902 train_acc: 68.43750 val_loss: 1.22022 val_acc: 73.12500\n",
      "[1, 7890] train_loss: 1.38662 train_acc: 65.62500 val_loss: 1.55874 val_acc: 60.00000\n",
      "[1, 7900] train_loss: 1.06424 train_acc: 73.43750 val_loss: 1.20356 val_acc: 70.62500\n",
      "[1, 7910] train_loss: 1.04536 train_acc: 73.75000 val_loss: 1.55946 val_acc: 63.75000\n",
      "[1, 7920] train_loss: 1.37406 train_acc: 65.00000 val_loss: 1.69904 val_acc: 61.87500\n",
      "[1, 7930] train_loss: 1.09000 train_acc: 71.25000 val_loss: 1.68723 val_acc: 55.00000\n",
      "[1, 7940] train_loss: 1.30942 train_acc: 68.12500 val_loss: 1.46717 val_acc: 65.62500\n",
      "[1, 7950] train_loss: 1.39950 train_acc: 62.18750 val_loss: 1.40850 val_acc: 66.87500\n",
      "[1, 7960] train_loss: 1.28303 train_acc: 68.12500 val_loss: 1.34171 val_acc: 70.00000\n",
      "[1, 7970] train_loss: 1.32008 train_acc: 66.87500 val_loss: 1.46478 val_acc: 61.87500\n",
      "[1, 7980] train_loss: 1.13079 train_acc: 71.25000 val_loss: 1.31868 val_acc: 65.62500\n",
      "[1, 7990] train_loss: 1.17155 train_acc: 72.50000 val_loss: 1.39736 val_acc: 68.12500\n",
      "[1, 8000] train_loss: 1.27214 train_acc: 67.81250 val_loss: 1.19432 val_acc: 68.75000\n",
      "[1, 8010] train_loss: 1.16333 train_acc: 70.62500 val_loss: 1.59740 val_acc: 66.87500\n",
      "[1, 8020] train_loss: 1.22529 train_acc: 69.68750 val_loss: 1.52129 val_acc: 62.50000\n",
      "[1, 8030] train_loss: 1.21907 train_acc: 68.75000 val_loss: 1.31811 val_acc: 66.87500\n",
      "[1, 8040] train_loss: 1.18424 train_acc: 72.50000 val_loss: 1.41321 val_acc: 65.00000\n",
      "[1, 8050] train_loss: 1.29565 train_acc: 68.43750 val_loss: 1.34131 val_acc: 67.50000\n",
      "[1, 8060] train_loss: 1.29936 train_acc: 65.31250 val_loss: 1.39883 val_acc: 66.25000\n",
      "[1, 8070] train_loss: 1.11076 train_acc: 70.62500 val_loss: 1.38683 val_acc: 63.75000\n",
      "[1, 8080] train_loss: 1.09236 train_acc: 74.68750 val_loss: 1.55072 val_acc: 59.37500\n",
      "[1, 8090] train_loss: 1.33700 train_acc: 68.75000 val_loss: 1.44103 val_acc: 68.12500\n",
      "[1, 8100] train_loss: 1.29058 train_acc: 68.12500 val_loss: 1.53470 val_acc: 65.62500\n",
      "[1, 8110] train_loss: 1.32639 train_acc: 67.50000 val_loss: 1.39794 val_acc: 65.62500\n",
      "[1, 8120] train_loss: 1.37887 train_acc: 62.81250 val_loss: 1.69316 val_acc: 60.62500\n",
      "[1, 8130] train_loss: 1.22296 train_acc: 69.06250 val_loss: 1.14393 val_acc: 76.87500\n",
      "[1, 8140] train_loss: 1.27665 train_acc: 68.75000 val_loss: 1.41789 val_acc: 66.87500\n",
      "[1, 8150] train_loss: 1.34337 train_acc: 66.87500 val_loss: 1.47365 val_acc: 65.62500\n",
      "[1, 8160] train_loss: 1.30597 train_acc: 66.87500 val_loss: 1.50107 val_acc: 68.12500\n",
      "[1, 8170] train_loss: 1.20184 train_acc: 68.12500 val_loss: 1.61856 val_acc: 61.87500\n",
      "[1, 8180] train_loss: 1.28759 train_acc: 70.93750 val_loss: 1.15651 val_acc: 71.87500\n",
      "[1, 8190] train_loss: 1.27911 train_acc: 68.43750 val_loss: 1.32451 val_acc: 68.75000\n",
      "[1, 8200] train_loss: 1.37309 train_acc: 65.00000 val_loss: 1.31621 val_acc: 72.50000\n",
      "[1, 8210] train_loss: 1.25435 train_acc: 69.37500 val_loss: 1.42114 val_acc: 65.00000\n",
      "[1, 8220] train_loss: 1.23732 train_acc: 71.56250 val_loss: 1.56668 val_acc: 65.00000\n",
      "[1, 8230] train_loss: 1.14945 train_acc: 72.18750 val_loss: 1.44482 val_acc: 65.00000\n",
      "[1, 8240] train_loss: 1.13780 train_acc: 67.50000 val_loss: 1.21478 val_acc: 70.62500\n",
      "[1, 8250] train_loss: 1.26109 train_acc: 67.18750 val_loss: 1.36754 val_acc: 68.12500\n",
      "[1, 8260] train_loss: 1.24023 train_acc: 66.25000 val_loss: 1.30502 val_acc: 68.75000\n",
      "[1, 8270] train_loss: 1.15271 train_acc: 68.43750 val_loss: 1.73858 val_acc: 60.00000\n",
      "[1, 8280] train_loss: 1.11177 train_acc: 71.87500 val_loss: 1.45506 val_acc: 64.37500\n",
      "[1, 8290] train_loss: 1.17002 train_acc: 69.68750 val_loss: 0.95041 val_acc: 74.37500\n",
      "[1, 8300] train_loss: 1.08517 train_acc: 73.75000 val_loss: 1.31967 val_acc: 68.75000\n",
      "[1, 8310] train_loss: 1.29892 train_acc: 68.43750 val_loss: 1.31339 val_acc: 68.12500\n",
      "[1, 8320] train_loss: 1.19264 train_acc: 72.18750 val_loss: 1.39520 val_acc: 66.87500\n",
      "[1, 8330] train_loss: 1.09961 train_acc: 72.81250 val_loss: 1.38882 val_acc: 69.37500\n",
      "[1, 8340] train_loss: 1.31956 train_acc: 68.12500 val_loss: 1.60188 val_acc: 60.00000\n",
      "[1, 8350] train_loss: 1.25530 train_acc: 68.43750 val_loss: 1.44159 val_acc: 66.87500\n",
      "[1, 8360] train_loss: 1.22696 train_acc: 70.31250 val_loss: 1.29778 val_acc: 71.87500\n",
      "[1, 8370] train_loss: 1.17001 train_acc: 70.62500 val_loss: 1.60022 val_acc: 63.12500\n",
      "[1, 8380] train_loss: 1.23709 train_acc: 67.81250 val_loss: 1.38505 val_acc: 65.00000\n",
      "[1, 8390] train_loss: 1.16864 train_acc: 68.12500 val_loss: 1.15168 val_acc: 76.25000\n",
      "[1, 8400] train_loss: 1.34438 train_acc: 67.18750 val_loss: 1.40238 val_acc: 69.37500\n",
      "[1, 8410] train_loss: 1.20536 train_acc: 70.00000 val_loss: 1.41290 val_acc: 63.75000\n",
      "[1, 8420] train_loss: 1.14838 train_acc: 72.81250 val_loss: 1.64859 val_acc: 61.25000\n",
      "[1, 8430] train_loss: 1.12932 train_acc: 69.68750 val_loss: 1.43601 val_acc: 68.12500\n",
      "[1, 8440] train_loss: 1.25966 train_acc: 68.43750 val_loss: 1.62347 val_acc: 58.12500\n",
      "[1, 8450] train_loss: 1.22883 train_acc: 68.43750 val_loss: 1.26277 val_acc: 66.87500\n",
      "[1, 8460] train_loss: 1.16493 train_acc: 72.50000 val_loss: 1.32827 val_acc: 67.50000\n",
      "[1, 8470] train_loss: 1.41628 train_acc: 69.37500 val_loss: 1.15639 val_acc: 71.87500\n",
      "[1, 8480] train_loss: 1.26885 train_acc: 64.68750 val_loss: 1.35122 val_acc: 68.12500\n",
      "[1, 8490] train_loss: 1.13581 train_acc: 74.06250 val_loss: 1.55550 val_acc: 65.00000\n",
      "[1, 8500] train_loss: 1.21625 train_acc: 70.31250 val_loss: 1.63904 val_acc: 63.75000\n",
      "[1, 8510] train_loss: 1.41218 train_acc: 66.87500 val_loss: 1.41806 val_acc: 70.00000\n",
      "[1, 8520] train_loss: 1.16400 train_acc: 70.93750 val_loss: 1.27694 val_acc: 68.12500\n",
      "[1, 8530] train_loss: 1.25833 train_acc: 70.31250 val_loss: 1.32423 val_acc: 69.37500\n",
      "[1, 8540] train_loss: 1.07148 train_acc: 71.25000 val_loss: 1.38445 val_acc: 68.12500\n",
      "[1, 8550] train_loss: 1.25903 train_acc: 65.31250 val_loss: 1.51170 val_acc: 68.75000\n",
      "[1, 8560] train_loss: 1.02563 train_acc: 72.81250 val_loss: 1.23516 val_acc: 70.00000\n",
      "[1, 8570] train_loss: 1.31717 train_acc: 66.87500 val_loss: 1.36809 val_acc: 68.75000\n",
      "[1, 8580] train_loss: 1.19150 train_acc: 70.31250 val_loss: 1.50122 val_acc: 67.50000\n",
      "[1, 8590] train_loss: 1.22411 train_acc: 70.00000 val_loss: 1.34102 val_acc: 70.62500\n",
      "[1, 8600] train_loss: 1.11871 train_acc: 70.00000 val_loss: 1.39726 val_acc: 65.00000\n",
      "[1, 8610] train_loss: 1.11202 train_acc: 70.62500 val_loss: 1.15844 val_acc: 73.12500\n",
      "[1, 8620] train_loss: 1.13219 train_acc: 69.68750 val_loss: 1.22001 val_acc: 73.12500\n",
      "[1, 8630] train_loss: 1.18940 train_acc: 67.81250 val_loss: 1.32747 val_acc: 66.87500\n",
      "[1, 8640] train_loss: 1.01875 train_acc: 72.81250 val_loss: 1.48152 val_acc: 66.25000\n",
      "[1, 8650] train_loss: 1.11766 train_acc: 70.93750 val_loss: 1.12173 val_acc: 72.50000\n",
      "[1, 8660] train_loss: 1.26484 train_acc: 69.37500 val_loss: 1.29793 val_acc: 69.37500\n",
      "[1, 8670] train_loss: 1.20518 train_acc: 69.06250 val_loss: 1.44373 val_acc: 65.62500\n",
      "[1, 8680] train_loss: 1.18225 train_acc: 68.12500 val_loss: 1.22942 val_acc: 70.62500\n",
      "[1, 8690] train_loss: 1.14592 train_acc: 71.25000 val_loss: 1.38695 val_acc: 66.87500\n",
      "[1, 8700] train_loss: 1.34592 train_acc: 65.93750 val_loss: 1.50468 val_acc: 65.62500\n",
      "[1, 8710] train_loss: 1.32321 train_acc: 67.18750 val_loss: 1.52529 val_acc: 62.50000\n",
      "[1, 8720] train_loss: 1.18846 train_acc: 70.31250 val_loss: 1.28023 val_acc: 68.75000\n",
      "[1, 8730] train_loss: 1.22128 train_acc: 66.56250 val_loss: 1.33471 val_acc: 67.50000\n",
      "[1, 8740] train_loss: 1.14534 train_acc: 73.75000 val_loss: 1.15559 val_acc: 73.75000\n",
      "[1, 8750] train_loss: 1.25171 train_acc: 68.75000 val_loss: 1.48983 val_acc: 61.25000\n",
      "[1, 8760] train_loss: 1.16023 train_acc: 67.18750 val_loss: 1.45900 val_acc: 66.25000\n",
      "[1, 8770] train_loss: 1.14081 train_acc: 69.06250 val_loss: 1.09659 val_acc: 71.25000\n",
      "[1, 8780] train_loss: 1.18838 train_acc: 69.37500 val_loss: 1.24520 val_acc: 71.25000\n",
      "[1, 8790] train_loss: 1.04966 train_acc: 70.31250 val_loss: 1.13213 val_acc: 70.62500\n",
      "[1, 8800] train_loss: 1.18567 train_acc: 73.43750 val_loss: 1.29470 val_acc: 66.87500\n",
      "[1, 8810] train_loss: 1.37156 train_acc: 66.87500 val_loss: 1.34254 val_acc: 65.62500\n",
      "[1, 8820] train_loss: 1.00902 train_acc: 73.75000 val_loss: 1.19226 val_acc: 72.50000\n",
      "[1, 8830] train_loss: 1.22288 train_acc: 68.75000 val_loss: 1.46464 val_acc: 66.25000\n",
      "[1, 8840] train_loss: 1.15567 train_acc: 73.75000 val_loss: 1.32783 val_acc: 64.37500\n",
      "[1, 8850] train_loss: 1.20770 train_acc: 70.62500 val_loss: 1.45822 val_acc: 65.62500\n",
      "[1, 8860] train_loss: 1.22831 train_acc: 69.37500 val_loss: 1.56588 val_acc: 64.37500\n",
      "[1, 8870] train_loss: 1.23528 train_acc: 66.56250 val_loss: 1.49367 val_acc: 62.50000\n",
      "[1, 8880] train_loss: 1.10364 train_acc: 71.87500 val_loss: 1.42055 val_acc: 65.00000\n",
      "[1, 8890] train_loss: 1.16803 train_acc: 69.06250 val_loss: 1.63382 val_acc: 61.25000\n",
      "[1, 8900] train_loss: 1.17364 train_acc: 71.56250 val_loss: 1.61173 val_acc: 64.37500\n",
      "[1, 8910] train_loss: 1.21876 train_acc: 70.31250 val_loss: 1.32399 val_acc: 68.75000\n",
      "[1, 8920] train_loss: 1.13567 train_acc: 70.00000 val_loss: 1.32197 val_acc: 68.12500\n",
      "[1, 8930] train_loss: 1.27745 train_acc: 69.37500 val_loss: 1.59987 val_acc: 61.87500\n",
      "[1, 8940] train_loss: 1.08444 train_acc: 73.75000 val_loss: 1.53092 val_acc: 65.00000\n",
      "[1, 8950] train_loss: 1.12099 train_acc: 73.43750 val_loss: 1.19439 val_acc: 69.37500\n",
      "[1, 8960] train_loss: 1.21368 train_acc: 68.75000 val_loss: 1.45800 val_acc: 61.87500\n",
      "[1, 8970] train_loss: 1.25868 train_acc: 70.31250 val_loss: 1.17345 val_acc: 71.25000\n",
      "[1, 8980] train_loss: 1.14011 train_acc: 70.93750 val_loss: 1.39628 val_acc: 64.37500\n",
      "[1, 8990] train_loss: 0.92789 train_acc: 77.18750 val_loss: 1.58502 val_acc: 64.37500\n",
      "[1, 9000] train_loss: 1.15107 train_acc: 75.00000 val_loss: 1.46411 val_acc: 65.62500\n",
      "[1, 9010] train_loss: 1.09332 train_acc: 73.75000 val_loss: 1.15547 val_acc: 71.87500\n",
      "[1, 9020] train_loss: 1.14087 train_acc: 72.81250 val_loss: 1.19594 val_acc: 73.75000\n",
      "[1, 9030] train_loss: 1.10707 train_acc: 72.18750 val_loss: 1.39437 val_acc: 65.00000\n",
      "[1, 9040] train_loss: 1.23468 train_acc: 69.68750 val_loss: 1.35095 val_acc: 66.25000\n",
      "[1, 9050] train_loss: 1.00817 train_acc: 75.93750 val_loss: 1.32478 val_acc: 70.00000\n",
      "[1, 9060] train_loss: 1.18092 train_acc: 70.00000 val_loss: 1.40262 val_acc: 62.50000\n",
      "[1, 9070] train_loss: 1.10677 train_acc: 71.25000 val_loss: 1.51845 val_acc: 67.50000\n",
      "[1, 9080] train_loss: 0.95973 train_acc: 73.75000 val_loss: 1.42241 val_acc: 66.25000\n",
      "[1, 9090] train_loss: 1.11818 train_acc: 71.87500 val_loss: 1.61551 val_acc: 63.12500\n",
      "[1, 9100] train_loss: 1.10996 train_acc: 70.00000 val_loss: 1.16256 val_acc: 73.12500\n",
      "[1, 9110] train_loss: 1.29834 train_acc: 65.62500 val_loss: 1.41587 val_acc: 66.87500\n",
      "[1, 9120] train_loss: 1.06316 train_acc: 71.87500 val_loss: 1.10531 val_acc: 71.25000\n",
      "[1, 9130] train_loss: 1.17045 train_acc: 71.56250 val_loss: 1.49304 val_acc: 65.62500\n",
      "[1, 9140] train_loss: 1.11324 train_acc: 70.62500 val_loss: 1.27235 val_acc: 66.25000\n",
      "[1, 9150] train_loss: 1.21306 train_acc: 66.25000 val_loss: 1.36275 val_acc: 68.75000\n",
      "[1, 9160] train_loss: 1.25049 train_acc: 67.81250 val_loss: 1.34572 val_acc: 71.87500\n",
      "[1, 9170] train_loss: 1.16825 train_acc: 67.81250 val_loss: 1.53275 val_acc: 63.12500\n",
      "[1, 9180] train_loss: 1.14250 train_acc: 72.50000 val_loss: 1.53951 val_acc: 61.87500\n",
      "[1, 9190] train_loss: 1.13667 train_acc: 72.18750 val_loss: 1.34527 val_acc: 70.00000\n",
      "[1, 9200] train_loss: 1.04378 train_acc: 74.68750 val_loss: 1.08799 val_acc: 74.37500\n",
      "[1, 9210] train_loss: 1.09803 train_acc: 72.50000 val_loss: 1.23400 val_acc: 66.87500\n",
      "[1, 9220] train_loss: 1.14209 train_acc: 70.00000 val_loss: 1.30654 val_acc: 68.12500\n",
      "[1, 9230] train_loss: 1.25416 train_acc: 71.56250 val_loss: 1.25870 val_acc: 70.62500\n",
      "[1, 9240] train_loss: 1.05163 train_acc: 70.93750 val_loss: 1.57836 val_acc: 66.87500\n",
      "[1, 9250] train_loss: 1.05923 train_acc: 72.18750 val_loss: 1.49030 val_acc: 69.37500\n",
      "[1, 9260] train_loss: 1.13326 train_acc: 70.00000 val_loss: 1.28929 val_acc: 69.37500\n",
      "[1, 9270] train_loss: 1.17173 train_acc: 72.18750 val_loss: 1.34049 val_acc: 72.50000\n",
      "[1, 9280] train_loss: 1.17711 train_acc: 70.31250 val_loss: 1.34328 val_acc: 69.37500\n",
      "[1, 9290] train_loss: 1.23021 train_acc: 70.62500 val_loss: 1.38537 val_acc: 62.50000\n",
      "[1, 9300] train_loss: 1.13162 train_acc: 72.81250 val_loss: 1.17058 val_acc: 72.50000\n",
      "[1, 9310] train_loss: 1.11068 train_acc: 70.31250 val_loss: 1.33714 val_acc: 67.50000\n",
      "[1, 9320] train_loss: 1.07480 train_acc: 74.37500 val_loss: 1.50357 val_acc: 63.12500\n",
      "[1, 9330] train_loss: 1.10266 train_acc: 71.87500 val_loss: 1.59106 val_acc: 61.87500\n",
      "[1, 9340] train_loss: 1.15625 train_acc: 70.62500 val_loss: 1.54991 val_acc: 64.37500\n",
      "[1, 9350] train_loss: 1.08201 train_acc: 73.43750 val_loss: 1.15497 val_acc: 73.12500\n",
      "[1, 9360] train_loss: 1.01052 train_acc: 74.37500 val_loss: 1.28384 val_acc: 68.12500\n",
      "[1, 9370] train_loss: 1.00737 train_acc: 75.93750 val_loss: 1.56582 val_acc: 59.37500\n",
      "[1, 9380] train_loss: 1.07905 train_acc: 74.06250 val_loss: 1.53998 val_acc: 65.00000\n",
      "[1, 9390] train_loss: 1.04169 train_acc: 71.56250 val_loss: 1.37795 val_acc: 68.75000\n",
      "[1, 9400] train_loss: 1.12139 train_acc: 71.25000 val_loss: 1.31601 val_acc: 68.12500\n",
      "[1, 9410] train_loss: 1.22035 train_acc: 72.81250 val_loss: 1.30383 val_acc: 70.62500\n",
      "[1, 9420] train_loss: 1.24764 train_acc: 67.81250 val_loss: 1.28181 val_acc: 71.87500\n",
      "[1, 9430] train_loss: 1.09367 train_acc: 72.18750 val_loss: 1.25454 val_acc: 76.87500\n",
      "[1, 9440] train_loss: 1.19350 train_acc: 70.62500 val_loss: 1.33214 val_acc: 66.87500\n",
      "[1, 9450] train_loss: 1.14501 train_acc: 69.68750 val_loss: 1.30459 val_acc: 69.37500\n",
      "[1, 9460] train_loss: 1.08117 train_acc: 74.68750 val_loss: 1.47982 val_acc: 64.37500\n",
      "[1, 9470] train_loss: 1.20778 train_acc: 69.06250 val_loss: 1.43283 val_acc: 68.12500\n",
      "[1, 9480] train_loss: 1.01476 train_acc: 74.68750 val_loss: 1.52076 val_acc: 63.75000\n",
      "[1, 9490] train_loss: 1.13655 train_acc: 71.87500 val_loss: 1.18169 val_acc: 66.87500\n",
      "[1, 9500] train_loss: 1.27460 train_acc: 66.87500 val_loss: 1.72888 val_acc: 60.00000\n",
      "[1, 9510] train_loss: 1.11052 train_acc: 72.81250 val_loss: 1.51134 val_acc: 64.37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 9520] train_loss: 0.98880 train_acc: 76.25000 val_loss: 1.27664 val_acc: 71.87500\n",
      "[1, 9530] train_loss: 1.07998 train_acc: 74.37500 val_loss: 1.25212 val_acc: 74.37500\n",
      "[1, 9540] train_loss: 1.09841 train_acc: 73.43750 val_loss: 1.54596 val_acc: 65.00000\n",
      "[1, 9550] train_loss: 1.20107 train_acc: 72.50000 val_loss: 1.19999 val_acc: 70.62500\n",
      "[1, 9560] train_loss: 1.06917 train_acc: 72.50000 val_loss: 1.25879 val_acc: 72.50000\n",
      "[1, 9570] train_loss: 1.00781 train_acc: 77.50000 val_loss: 1.25182 val_acc: 73.12500\n",
      "[1, 9580] train_loss: 0.88082 train_acc: 77.18750 val_loss: 1.35831 val_acc: 66.25000\n",
      "[1, 9590] train_loss: 1.10999 train_acc: 70.62500 val_loss: 1.34497 val_acc: 65.62500\n",
      "[1, 9600] train_loss: 1.08855 train_acc: 71.56250 val_loss: 1.19047 val_acc: 70.00000\n",
      "[1, 9610] train_loss: 1.11389 train_acc: 70.62500 val_loss: 1.34863 val_acc: 70.00000\n",
      "[1, 9620] train_loss: 1.12527 train_acc: 70.00000 val_loss: 1.59563 val_acc: 67.50000\n",
      "[1, 9630] train_loss: 1.07195 train_acc: 74.06250 val_loss: 1.20577 val_acc: 70.00000\n",
      "[1, 9640] train_loss: 1.24698 train_acc: 69.06250 val_loss: 1.45651 val_acc: 65.62500\n",
      "[1, 9650] train_loss: 1.22286 train_acc: 67.81250 val_loss: 1.26570 val_acc: 71.25000\n",
      "[1, 9660] train_loss: 1.34157 train_acc: 65.31250 val_loss: 1.14797 val_acc: 73.75000\n",
      "[1, 9670] train_loss: 0.97843 train_acc: 77.18750 val_loss: 1.36814 val_acc: 68.12500\n",
      "[1, 9680] train_loss: 1.19217 train_acc: 67.50000 val_loss: 1.65099 val_acc: 61.87500\n",
      "[1, 9690] train_loss: 0.99344 train_acc: 75.62500 val_loss: 1.14214 val_acc: 70.62500\n",
      "[1, 9700] train_loss: 1.03309 train_acc: 72.18750 val_loss: 1.25910 val_acc: 67.50000\n",
      "[1, 9710] train_loss: 1.30472 train_acc: 66.87500 val_loss: 1.27172 val_acc: 67.50000\n",
      "[1, 9720] train_loss: 1.14043 train_acc: 67.81250 val_loss: 1.18173 val_acc: 71.87500\n",
      "[1, 9730] train_loss: 1.01675 train_acc: 75.93750 val_loss: 1.43260 val_acc: 68.12500\n",
      "[1, 9740] train_loss: 1.06169 train_acc: 72.18750 val_loss: 1.54803 val_acc: 61.25000\n",
      "[1, 9750] train_loss: 0.98749 train_acc: 72.81250 val_loss: 1.30081 val_acc: 71.25000\n",
      "[1, 9760] train_loss: 1.29356 train_acc: 65.00000 val_loss: 1.18042 val_acc: 69.37500\n",
      "[1, 9770] train_loss: 1.17528 train_acc: 68.12500 val_loss: 1.30272 val_acc: 70.00000\n",
      "[1, 9780] train_loss: 0.99603 train_acc: 74.68750 val_loss: 1.17619 val_acc: 70.62500\n",
      "[1, 9790] train_loss: 1.08020 train_acc: 72.50000 val_loss: 1.06150 val_acc: 71.87500\n",
      "[1, 9800] train_loss: 1.09982 train_acc: 71.56250 val_loss: 1.30564 val_acc: 65.00000\n",
      "[1, 9810] train_loss: 1.07398 train_acc: 72.50000 val_loss: 1.38736 val_acc: 66.25000\n",
      "[1, 9820] train_loss: 1.04219 train_acc: 69.68750 val_loss: 1.27475 val_acc: 71.25000\n",
      "[1, 9830] train_loss: 0.98609 train_acc: 72.18750 val_loss: 1.37865 val_acc: 68.75000\n",
      "[1, 9840] train_loss: 0.97359 train_acc: 74.68750 val_loss: 1.30417 val_acc: 72.50000\n",
      "[1, 9850] train_loss: 1.14725 train_acc: 69.06250 val_loss: 1.18672 val_acc: 73.12500\n",
      "[1, 9860] train_loss: 1.10661 train_acc: 73.12500 val_loss: 1.48605 val_acc: 63.12500\n",
      "[1, 9870] train_loss: 1.12809 train_acc: 72.50000 val_loss: 1.10086 val_acc: 72.50000\n",
      "[1, 9880] train_loss: 0.94202 train_acc: 76.56250 val_loss: 1.23036 val_acc: 70.62500\n",
      "[1, 9890] train_loss: 1.01164 train_acc: 75.31250 val_loss: 1.36903 val_acc: 73.12500\n",
      "[1, 9900] train_loss: 0.98261 train_acc: 74.37500 val_loss: 1.20405 val_acc: 71.87500\n",
      "[1, 9910] train_loss: 1.12054 train_acc: 70.62500 val_loss: 1.10067 val_acc: 73.75000\n",
      "[1, 9920] train_loss: 1.17609 train_acc: 72.18750 val_loss: 1.33479 val_acc: 68.12500\n",
      "[1, 9930] train_loss: 1.03262 train_acc: 70.31250 val_loss: 1.27370 val_acc: 68.75000\n",
      "[1, 9940] train_loss: 0.94859 train_acc: 76.25000 val_loss: 1.26511 val_acc: 70.62500\n",
      "[2, 1] train_loss: 0.97263 train_acc: 84.37500 val_loss: 1.54288 val_acc: 62.50000\n",
      "[2, 10] train_loss: 0.97460 train_acc: 77.50000 val_loss: 1.25893 val_acc: 66.87500\n",
      "[2, 20] train_loss: 1.05042 train_acc: 70.31250 val_loss: 1.24687 val_acc: 69.37500\n",
      "[2, 30] train_loss: 0.98333 train_acc: 76.25000 val_loss: 1.38758 val_acc: 67.50000\n",
      "[2, 40] train_loss: 0.91357 train_acc: 73.12500 val_loss: 1.11070 val_acc: 75.00000\n",
      "[2, 50] train_loss: 1.12682 train_acc: 71.87500 val_loss: 1.48991 val_acc: 60.62500\n",
      "[2, 60] train_loss: 0.95578 train_acc: 78.12500 val_loss: 1.41835 val_acc: 68.75000\n",
      "[2, 70] train_loss: 1.07419 train_acc: 71.56250 val_loss: 1.29871 val_acc: 70.00000\n",
      "[2, 80] train_loss: 1.10245 train_acc: 72.81250 val_loss: 1.07671 val_acc: 75.00000\n",
      "[2, 90] train_loss: 1.15106 train_acc: 71.56250 val_loss: 1.43809 val_acc: 69.37500\n",
      "[2, 100] train_loss: 0.97956 train_acc: 76.25000 val_loss: 1.22832 val_acc: 70.62500\n",
      "[2, 110] train_loss: 1.15538 train_acc: 72.18750 val_loss: 1.01506 val_acc: 75.00000\n",
      "[2, 120] train_loss: 1.03321 train_acc: 72.18750 val_loss: 1.38018 val_acc: 66.25000\n",
      "[2, 130] train_loss: 1.03615 train_acc: 72.50000 val_loss: 1.47373 val_acc: 65.62500\n",
      "[2, 140] train_loss: 1.05275 train_acc: 74.06250 val_loss: 1.30635 val_acc: 73.75000\n",
      "[2, 150] train_loss: 0.85771 train_acc: 79.06250 val_loss: 1.27806 val_acc: 66.87500\n",
      "[2, 160] train_loss: 1.16828 train_acc: 73.43750 val_loss: 1.22509 val_acc: 73.12500\n",
      "[2, 170] train_loss: 0.93130 train_acc: 74.68750 val_loss: 1.16950 val_acc: 69.37500\n",
      "[2, 180] train_loss: 1.03678 train_acc: 74.06250 val_loss: 1.39191 val_acc: 65.00000\n",
      "[2, 190] train_loss: 1.10221 train_acc: 74.06250 val_loss: 1.08740 val_acc: 74.37500\n",
      "[2, 200] train_loss: 0.99380 train_acc: 73.43750 val_loss: 1.16022 val_acc: 73.12500\n",
      "[2, 210] train_loss: 0.91351 train_acc: 76.56250 val_loss: 1.26575 val_acc: 70.62500\n",
      "[2, 220] train_loss: 1.07697 train_acc: 72.81250 val_loss: 1.11744 val_acc: 75.00000\n",
      "[2, 230] train_loss: 1.21518 train_acc: 68.75000 val_loss: 1.29403 val_acc: 68.75000\n",
      "[2, 240] train_loss: 1.03046 train_acc: 76.87500 val_loss: 1.10780 val_acc: 70.62500\n",
      "[2, 250] train_loss: 1.17379 train_acc: 69.37500 val_loss: 1.22674 val_acc: 71.25000\n",
      "[2, 260] train_loss: 0.98082 train_acc: 75.00000 val_loss: 1.19053 val_acc: 70.62500\n",
      "[2, 270] train_loss: 0.98087 train_acc: 75.62500 val_loss: 1.14874 val_acc: 72.50000\n",
      "[2, 280] train_loss: 0.97958 train_acc: 72.81250 val_loss: 1.15220 val_acc: 72.50000\n",
      "[2, 290] train_loss: 1.14003 train_acc: 70.00000 val_loss: 1.25893 val_acc: 62.50000\n",
      "[2, 300] train_loss: 1.01216 train_acc: 72.81250 val_loss: 1.16524 val_acc: 71.87500\n",
      "[2, 310] train_loss: 0.99236 train_acc: 75.00000 val_loss: 1.27796 val_acc: 71.87500\n",
      "[2, 320] train_loss: 1.09303 train_acc: 72.18750 val_loss: 1.26998 val_acc: 67.50000\n",
      "[2, 330] train_loss: 1.08322 train_acc: 73.43750 val_loss: 1.46143 val_acc: 66.87500\n",
      "[2, 340] train_loss: 1.03540 train_acc: 73.43750 val_loss: 1.39829 val_acc: 64.37500\n",
      "[2, 350] train_loss: 0.97345 train_acc: 73.12500 val_loss: 1.61335 val_acc: 61.87500\n",
      "[2, 360] train_loss: 1.09291 train_acc: 71.56250 val_loss: 1.07640 val_acc: 67.50000\n",
      "[2, 370] train_loss: 0.93804 train_acc: 73.75000 val_loss: 1.38700 val_acc: 68.12500\n",
      "[2, 380] train_loss: 1.03678 train_acc: 73.12500 val_loss: 1.46449 val_acc: 66.87500\n",
      "[2, 390] train_loss: 0.96801 train_acc: 73.43750 val_loss: 1.26658 val_acc: 68.12500\n",
      "[2, 400] train_loss: 0.98356 train_acc: 75.31250 val_loss: 1.39629 val_acc: 69.37500\n",
      "[2, 410] train_loss: 1.10074 train_acc: 71.56250 val_loss: 1.32287 val_acc: 66.87500\n",
      "[2, 420] train_loss: 0.80605 train_acc: 79.06250 val_loss: 1.58308 val_acc: 65.62500\n",
      "[2, 430] train_loss: 1.06359 train_acc: 72.50000 val_loss: 1.13598 val_acc: 72.50000\n",
      "[2, 440] train_loss: 0.92996 train_acc: 76.56250 val_loss: 1.39554 val_acc: 62.50000\n",
      "[2, 450] train_loss: 0.98231 train_acc: 71.56250 val_loss: 1.03676 val_acc: 76.87500\n",
      "[2, 460] train_loss: 1.06769 train_acc: 74.37500 val_loss: 1.14648 val_acc: 75.00000\n",
      "[2, 470] train_loss: 1.03092 train_acc: 74.06250 val_loss: 1.27778 val_acc: 66.25000\n",
      "[2, 480] train_loss: 1.02213 train_acc: 72.18750 val_loss: 1.29244 val_acc: 67.50000\n",
      "[2, 490] train_loss: 0.97442 train_acc: 73.43750 val_loss: 1.32474 val_acc: 70.00000\n",
      "[2, 500] train_loss: 1.07403 train_acc: 71.56250 val_loss: 1.35572 val_acc: 66.87500\n",
      "[2, 510] train_loss: 1.13764 train_acc: 72.18750 val_loss: 1.24248 val_acc: 72.50000\n",
      "[2, 520] train_loss: 1.10779 train_acc: 71.87500 val_loss: 1.39411 val_acc: 71.25000\n",
      "[2, 530] train_loss: 0.94701 train_acc: 76.25000 val_loss: 1.23797 val_acc: 71.25000\n",
      "[2, 540] train_loss: 1.02527 train_acc: 75.93750 val_loss: 1.17804 val_acc: 70.62500\n",
      "[2, 550] train_loss: 0.92124 train_acc: 75.00000 val_loss: 1.16765 val_acc: 71.25000\n",
      "[2, 560] train_loss: 0.92630 train_acc: 74.37500 val_loss: 1.29473 val_acc: 66.87500\n",
      "[2, 570] train_loss: 0.99535 train_acc: 74.68750 val_loss: 1.11092 val_acc: 72.50000\n",
      "[2, 580] train_loss: 1.00660 train_acc: 75.62500 val_loss: 1.37477 val_acc: 68.75000\n",
      "[2, 590] train_loss: 1.01115 train_acc: 75.31250 val_loss: 1.22219 val_acc: 68.12500\n",
      "[2, 600] train_loss: 1.06599 train_acc: 72.81250 val_loss: 1.25052 val_acc: 71.87500\n",
      "[2, 610] train_loss: 0.95967 train_acc: 74.68750 val_loss: 1.07248 val_acc: 65.00000\n",
      "[2, 620] train_loss: 0.78481 train_acc: 80.31250 val_loss: 1.16421 val_acc: 67.50000\n",
      "[2, 630] train_loss: 1.03210 train_acc: 74.68750 val_loss: 1.30310 val_acc: 70.00000\n",
      "[2, 640] train_loss: 1.05571 train_acc: 74.06250 val_loss: 1.39147 val_acc: 62.50000\n",
      "[2, 650] train_loss: 0.95463 train_acc: 75.00000 val_loss: 1.19102 val_acc: 74.37500\n",
      "[2, 660] train_loss: 1.02188 train_acc: 74.06250 val_loss: 1.12713 val_acc: 73.75000\n",
      "[2, 670] train_loss: 0.90744 train_acc: 79.37500 val_loss: 1.50339 val_acc: 66.25000\n",
      "[2, 680] train_loss: 1.10174 train_acc: 73.75000 val_loss: 1.20104 val_acc: 72.50000\n",
      "[2, 690] train_loss: 1.04314 train_acc: 75.62500 val_loss: 0.99773 val_acc: 75.00000\n",
      "[2, 700] train_loss: 1.11845 train_acc: 70.62500 val_loss: 1.34050 val_acc: 68.75000\n",
      "[2, 710] train_loss: 1.12698 train_acc: 72.50000 val_loss: 1.26890 val_acc: 69.37500\n",
      "[2, 720] train_loss: 0.96144 train_acc: 76.56250 val_loss: 1.24730 val_acc: 70.00000\n",
      "[2, 730] train_loss: 0.99779 train_acc: 73.12500 val_loss: 1.20312 val_acc: 76.87500\n",
      "[2, 740] train_loss: 1.02148 train_acc: 76.25000 val_loss: 1.52021 val_acc: 67.50000\n",
      "[2, 750] train_loss: 1.03150 train_acc: 75.00000 val_loss: 1.56947 val_acc: 64.37500\n",
      "[2, 760] train_loss: 1.12763 train_acc: 70.93750 val_loss: 1.45203 val_acc: 67.50000\n",
      "[2, 770] train_loss: 1.09796 train_acc: 72.50000 val_loss: 1.40094 val_acc: 65.00000\n",
      "[2, 780] train_loss: 1.05879 train_acc: 73.43750 val_loss: 1.59199 val_acc: 64.37500\n",
      "[2, 790] train_loss: 1.03317 train_acc: 72.81250 val_loss: 1.06634 val_acc: 75.00000\n",
      "[2, 800] train_loss: 1.05072 train_acc: 70.93750 val_loss: 1.19783 val_acc: 69.37500\n",
      "[2, 810] train_loss: 1.09200 train_acc: 72.81250 val_loss: 1.51341 val_acc: 65.62500\n",
      "[2, 820] train_loss: 1.05732 train_acc: 71.25000 val_loss: 1.21571 val_acc: 72.50000\n",
      "[2, 830] train_loss: 1.11630 train_acc: 71.25000 val_loss: 1.27051 val_acc: 68.12500\n",
      "[2, 840] train_loss: 0.90833 train_acc: 77.50000 val_loss: 1.21122 val_acc: 70.00000\n",
      "[2, 850] train_loss: 0.98423 train_acc: 71.87500 val_loss: 1.24498 val_acc: 72.50000\n",
      "[2, 860] train_loss: 0.77619 train_acc: 81.25000 val_loss: 1.32737 val_acc: 64.37500\n",
      "[2, 870] train_loss: 0.92852 train_acc: 77.18750 val_loss: 1.27058 val_acc: 73.12500\n",
      "[2, 880] train_loss: 0.96347 train_acc: 74.37500 val_loss: 1.15874 val_acc: 70.62500\n",
      "[2, 890] train_loss: 1.06400 train_acc: 74.37500 val_loss: 1.31349 val_acc: 70.62500\n",
      "[2, 900] train_loss: 0.95384 train_acc: 77.18750 val_loss: 1.08065 val_acc: 76.87500\n",
      "[2, 910] train_loss: 0.87785 train_acc: 78.75000 val_loss: 1.35997 val_acc: 68.12500\n",
      "[2, 920] train_loss: 0.96283 train_acc: 75.00000 val_loss: 1.01070 val_acc: 75.00000\n",
      "[2, 930] train_loss: 1.06718 train_acc: 73.75000 val_loss: 1.39713 val_acc: 61.87500\n",
      "[2, 940] train_loss: 0.92841 train_acc: 73.75000 val_loss: 1.14469 val_acc: 73.75000\n",
      "[2, 950] train_loss: 0.83174 train_acc: 77.18750 val_loss: 1.28421 val_acc: 65.62500\n",
      "[2, 960] train_loss: 0.95166 train_acc: 72.81250 val_loss: 1.22303 val_acc: 67.50000\n",
      "[2, 970] train_loss: 1.00524 train_acc: 71.87500 val_loss: 1.30517 val_acc: 71.25000\n",
      "[2, 980] train_loss: 0.88951 train_acc: 77.81250 val_loss: 1.48236 val_acc: 61.87500\n",
      "[2, 990] train_loss: 1.00690 train_acc: 74.37500 val_loss: 1.60136 val_acc: 63.12500\n",
      "[2, 1000] train_loss: 1.25010 train_acc: 69.68750 val_loss: 1.27767 val_acc: 69.37500\n",
      "[2, 1010] train_loss: 0.96143 train_acc: 75.93750 val_loss: 1.15335 val_acc: 73.75000\n",
      "[2, 1020] train_loss: 0.94462 train_acc: 76.25000 val_loss: 1.32152 val_acc: 71.87500\n",
      "[2, 1030] train_loss: 1.14284 train_acc: 70.93750 val_loss: 1.31404 val_acc: 68.12500\n",
      "[2, 1040] train_loss: 0.99352 train_acc: 70.62500 val_loss: 1.23074 val_acc: 70.62500\n",
      "[2, 1050] train_loss: 1.10181 train_acc: 72.81250 val_loss: 1.18326 val_acc: 67.50000\n",
      "[2, 1060] train_loss: 0.94260 train_acc: 74.37500 val_loss: 1.29388 val_acc: 73.75000\n",
      "[2, 1070] train_loss: 1.10078 train_acc: 72.50000 val_loss: 1.30465 val_acc: 65.00000\n",
      "[2, 1080] train_loss: 1.01606 train_acc: 74.37500 val_loss: 1.31380 val_acc: 68.75000\n",
      "[2, 1090] train_loss: 0.98097 train_acc: 75.93750 val_loss: 1.18970 val_acc: 73.75000\n",
      "[2, 1100] train_loss: 1.02548 train_acc: 74.06250 val_loss: 1.24965 val_acc: 70.62500\n",
      "[2, 1110] train_loss: 1.16602 train_acc: 70.31250 val_loss: 1.12970 val_acc: 72.50000\n",
      "[2, 1120] train_loss: 1.05618 train_acc: 72.50000 val_loss: 1.40512 val_acc: 68.75000\n",
      "[2, 1130] train_loss: 1.02713 train_acc: 74.68750 val_loss: 1.22475 val_acc: 69.37500\n",
      "[2, 1140] train_loss: 1.08588 train_acc: 73.12500 val_loss: 1.14635 val_acc: 70.62500\n",
      "[2, 1150] train_loss: 1.07739 train_acc: 73.43750 val_loss: 1.27923 val_acc: 71.87500\n",
      "[2, 1160] train_loss: 0.99013 train_acc: 73.43750 val_loss: 1.33018 val_acc: 68.75000\n",
      "[2, 1170] train_loss: 1.02303 train_acc: 75.00000 val_loss: 1.00012 val_acc: 76.25000\n",
      "[2, 1180] train_loss: 0.92910 train_acc: 74.68750 val_loss: 1.18804 val_acc: 70.62500\n",
      "[2, 1190] train_loss: 0.96800 train_acc: 75.62500 val_loss: 0.97561 val_acc: 73.75000\n",
      "[2, 1200] train_loss: 1.02341 train_acc: 74.06250 val_loss: 1.19181 val_acc: 72.50000\n",
      "[2, 1210] train_loss: 0.96455 train_acc: 74.68750 val_loss: 1.08691 val_acc: 76.87500\n",
      "[2, 1220] train_loss: 0.89788 train_acc: 75.62500 val_loss: 1.17528 val_acc: 71.87500\n",
      "[2, 1230] train_loss: 0.94609 train_acc: 72.81250 val_loss: 1.41799 val_acc: 70.00000\n",
      "[2, 1240] train_loss: 0.78687 train_acc: 78.75000 val_loss: 1.37348 val_acc: 71.87500\n",
      "[2, 1250] train_loss: 0.86237 train_acc: 78.43750 val_loss: 1.18024 val_acc: 71.87500\n",
      "[2, 1260] train_loss: 0.94572 train_acc: 76.87500 val_loss: 1.33443 val_acc: 70.62500\n",
      "[2, 1270] train_loss: 1.05606 train_acc: 72.18750 val_loss: 1.13930 val_acc: 73.75000\n",
      "[2, 1280] train_loss: 0.90031 train_acc: 76.87500 val_loss: 1.21308 val_acc: 70.62500\n",
      "[2, 1290] train_loss: 1.03030 train_acc: 74.68750 val_loss: 1.37718 val_acc: 70.00000\n",
      "[2, 1300] train_loss: 0.93143 train_acc: 74.68750 val_loss: 1.09747 val_acc: 73.75000\n",
      "[2, 1310] train_loss: 1.00677 train_acc: 74.06250 val_loss: 0.98526 val_acc: 75.62500\n",
      "[2, 1320] train_loss: 0.88211 train_acc: 75.62500 val_loss: 1.15245 val_acc: 75.00000\n",
      "[2, 1330] train_loss: 0.86716 train_acc: 77.18750 val_loss: 1.09897 val_acc: 73.12500\n",
      "[2, 1340] train_loss: 0.96502 train_acc: 76.87500 val_loss: 1.28614 val_acc: 72.50000\n",
      "[2, 1350] train_loss: 0.91865 train_acc: 77.18750 val_loss: 1.23990 val_acc: 71.87500\n",
      "[2, 1360] train_loss: 0.98221 train_acc: 75.62500 val_loss: 1.19734 val_acc: 69.37500\n",
      "[2, 1370] train_loss: 1.03070 train_acc: 72.81250 val_loss: 1.16362 val_acc: 73.75000\n",
      "[2, 1380] train_loss: 0.98911 train_acc: 72.50000 val_loss: 1.08814 val_acc: 76.25000\n",
      "[2, 1390] train_loss: 0.85271 train_acc: 78.43750 val_loss: 1.42695 val_acc: 66.25000\n",
      "[2, 1400] train_loss: 0.93591 train_acc: 75.31250 val_loss: 1.04658 val_acc: 77.50000\n",
      "[2, 1410] train_loss: 1.02615 train_acc: 73.43750 val_loss: 1.43677 val_acc: 69.37500\n",
      "[2, 1420] train_loss: 0.99270 train_acc: 71.56250 val_loss: 1.16525 val_acc: 70.00000\n",
      "[2, 1430] train_loss: 0.83023 train_acc: 76.56250 val_loss: 1.42122 val_acc: 66.87500\n",
      "[2, 1440] train_loss: 0.82345 train_acc: 79.68750 val_loss: 1.25776 val_acc: 70.00000\n",
      "[2, 1450] train_loss: 0.93262 train_acc: 75.31250 val_loss: 1.13379 val_acc: 70.62500\n",
      "[2, 1460] train_loss: 0.84156 train_acc: 76.87500 val_loss: 1.53111 val_acc: 65.62500\n",
      "[2, 1470] train_loss: 1.00330 train_acc: 75.62500 val_loss: 1.01473 val_acc: 73.75000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1480] train_loss: 0.87508 train_acc: 77.18750 val_loss: 1.38005 val_acc: 69.37500\n",
      "[2, 1490] train_loss: 1.00754 train_acc: 74.68750 val_loss: 1.12034 val_acc: 74.37500\n",
      "[2, 1500] train_loss: 0.93060 train_acc: 75.00000 val_loss: 1.37730 val_acc: 73.75000\n",
      "[2, 1510] train_loss: 0.90002 train_acc: 76.56250 val_loss: 1.28345 val_acc: 70.62500\n",
      "[2, 1520] train_loss: 0.99560 train_acc: 75.00000 val_loss: 0.95862 val_acc: 75.62500\n",
      "[2, 1530] train_loss: 0.99104 train_acc: 75.93750 val_loss: 1.10221 val_acc: 71.25000\n",
      "[2, 1540] train_loss: 0.88181 train_acc: 75.62500 val_loss: 1.30129 val_acc: 69.37500\n",
      "[2, 1550] train_loss: 0.95819 train_acc: 72.81250 val_loss: 1.22927 val_acc: 71.25000\n",
      "[2, 1560] train_loss: 1.02545 train_acc: 76.87500 val_loss: 1.09895 val_acc: 75.00000\n",
      "[2, 1570] train_loss: 1.12032 train_acc: 71.56250 val_loss: 1.05462 val_acc: 76.87500\n",
      "[2, 1580] train_loss: 0.91682 train_acc: 77.18750 val_loss: 1.33766 val_acc: 68.75000\n",
      "[2, 1590] train_loss: 0.98189 train_acc: 74.06250 val_loss: 1.37734 val_acc: 68.12500\n",
      "[2, 1600] train_loss: 1.00472 train_acc: 76.87500 val_loss: 1.21355 val_acc: 68.12500\n",
      "[2, 1610] train_loss: 0.96382 train_acc: 76.56250 val_loss: 0.96613 val_acc: 76.25000\n",
      "[2, 1620] train_loss: 0.98391 train_acc: 76.56250 val_loss: 1.42288 val_acc: 66.25000\n",
      "[2, 1630] train_loss: 0.94884 train_acc: 75.93750 val_loss: 1.38064 val_acc: 66.25000\n",
      "[2, 1640] train_loss: 0.92580 train_acc: 75.62500 val_loss: 1.34773 val_acc: 68.75000\n",
      "[2, 1650] train_loss: 0.84920 train_acc: 78.75000 val_loss: 1.01279 val_acc: 74.37500\n",
      "[2, 1660] train_loss: 1.07897 train_acc: 72.81250 val_loss: 1.22769 val_acc: 68.12500\n",
      "[2, 1670] train_loss: 0.84842 train_acc: 78.75000 val_loss: 1.18024 val_acc: 75.00000\n",
      "[2, 1680] train_loss: 1.02426 train_acc: 70.62500 val_loss: 1.43629 val_acc: 68.12500\n",
      "[2, 1690] train_loss: 0.93455 train_acc: 75.00000 val_loss: 1.33447 val_acc: 72.50000\n",
      "[2, 1700] train_loss: 0.89931 train_acc: 77.50000 val_loss: 1.46990 val_acc: 63.12500\n",
      "[2, 1710] train_loss: 0.95551 train_acc: 74.68750 val_loss: 1.31038 val_acc: 68.75000\n",
      "[2, 1720] train_loss: 0.89235 train_acc: 75.62500 val_loss: 1.21501 val_acc: 69.37500\n",
      "[2, 1730] train_loss: 1.00925 train_acc: 76.25000 val_loss: 1.23789 val_acc: 71.25000\n",
      "[2, 1740] train_loss: 0.82013 train_acc: 77.81250 val_loss: 1.04932 val_acc: 74.37500\n",
      "[2, 1750] train_loss: 0.86278 train_acc: 76.87500 val_loss: 1.13512 val_acc: 68.12500\n",
      "[2, 1760] train_loss: 0.92736 train_acc: 75.62500 val_loss: 1.09014 val_acc: 76.25000\n",
      "[2, 1770] train_loss: 0.91229 train_acc: 75.93750 val_loss: 1.11048 val_acc: 73.12500\n",
      "[2, 1780] train_loss: 0.90064 train_acc: 76.87500 val_loss: 1.09788 val_acc: 69.37500\n",
      "[2, 1790] train_loss: 0.96434 train_acc: 76.87500 val_loss: 1.34713 val_acc: 65.00000\n",
      "[2, 1800] train_loss: 0.97416 train_acc: 75.62500 val_loss: 1.13412 val_acc: 75.00000\n",
      "[2, 1810] train_loss: 0.88674 train_acc: 78.12500 val_loss: 0.95830 val_acc: 75.00000\n",
      "[2, 1820] train_loss: 1.07937 train_acc: 73.43750 val_loss: 1.10810 val_acc: 75.00000\n",
      "[2, 1830] train_loss: 0.92680 train_acc: 74.37500 val_loss: 1.38700 val_acc: 65.00000\n",
      "[2, 1840] train_loss: 0.96042 train_acc: 75.62500 val_loss: 1.33070 val_acc: 70.00000\n",
      "[2, 1850] train_loss: 0.86585 train_acc: 75.62500 val_loss: 1.25734 val_acc: 71.87500\n",
      "[2, 1860] train_loss: 1.05327 train_acc: 75.00000 val_loss: 1.18262 val_acc: 69.37500\n",
      "[2, 1870] train_loss: 0.91400 train_acc: 77.50000 val_loss: 1.23273 val_acc: 69.37500\n",
      "[2, 1880] train_loss: 1.03600 train_acc: 73.75000 val_loss: 1.21295 val_acc: 69.37500\n",
      "[2, 1890] train_loss: 1.02426 train_acc: 75.62500 val_loss: 1.20271 val_acc: 71.25000\n",
      "[2, 1900] train_loss: 0.93039 train_acc: 77.18750 val_loss: 1.29333 val_acc: 68.75000\n",
      "[2, 1910] train_loss: 0.78274 train_acc: 80.93750 val_loss: 1.10231 val_acc: 70.62500\n",
      "[2, 1920] train_loss: 0.98527 train_acc: 73.43750 val_loss: 1.18869 val_acc: 70.62500\n",
      "[2, 1930] train_loss: 0.96985 train_acc: 75.00000 val_loss: 1.12886 val_acc: 70.62500\n",
      "[2, 1940] train_loss: 1.03381 train_acc: 75.93750 val_loss: 1.14096 val_acc: 73.12500\n",
      "[2, 1950] train_loss: 0.94733 train_acc: 73.75000 val_loss: 1.20528 val_acc: 69.37500\n",
      "[2, 1960] train_loss: 1.03130 train_acc: 73.43750 val_loss: 1.36861 val_acc: 71.87500\n",
      "[2, 1970] train_loss: 0.90069 train_acc: 76.56250 val_loss: 1.21209 val_acc: 70.62500\n",
      "[2, 1980] train_loss: 0.93111 train_acc: 76.56250 val_loss: 1.45959 val_acc: 69.37500\n",
      "[2, 1990] train_loss: 0.85147 train_acc: 76.56250 val_loss: 1.15884 val_acc: 70.00000\n",
      "[2, 2000] train_loss: 0.84053 train_acc: 75.31250 val_loss: 1.28331 val_acc: 71.87500\n",
      "[2, 2010] train_loss: 0.79339 train_acc: 79.37500 val_loss: 1.33567 val_acc: 70.00000\n",
      "[2, 2020] train_loss: 0.83181 train_acc: 77.81250 val_loss: 1.02475 val_acc: 75.00000\n",
      "[2, 2030] train_loss: 1.08589 train_acc: 71.87500 val_loss: 1.30626 val_acc: 68.75000\n",
      "[2, 2040] train_loss: 0.85143 train_acc: 78.75000 val_loss: 1.38999 val_acc: 68.12500\n",
      "[2, 2050] train_loss: 1.01380 train_acc: 74.06250 val_loss: 1.19262 val_acc: 72.50000\n",
      "[2, 2060] train_loss: 0.86664 train_acc: 77.18750 val_loss: 0.95938 val_acc: 77.50000\n",
      "[2, 2070] train_loss: 0.93890 train_acc: 75.62500 val_loss: 0.98655 val_acc: 77.50000\n",
      "[2, 2080] train_loss: 1.00640 train_acc: 74.06250 val_loss: 1.27003 val_acc: 69.37500\n",
      "[2, 2090] train_loss: 0.87912 train_acc: 77.18750 val_loss: 1.00751 val_acc: 74.37500\n",
      "[2, 2100] train_loss: 0.90653 train_acc: 75.00000 val_loss: 1.22393 val_acc: 68.75000\n",
      "[2, 2110] train_loss: 1.01743 train_acc: 74.06250 val_loss: 1.25756 val_acc: 68.75000\n",
      "[2, 2120] train_loss: 1.06095 train_acc: 72.50000 val_loss: 1.11226 val_acc: 74.37500\n",
      "[2, 2130] train_loss: 1.00551 train_acc: 76.87500 val_loss: 1.17387 val_acc: 71.87500\n",
      "[2, 2140] train_loss: 0.96927 train_acc: 76.87500 val_loss: 1.16948 val_acc: 73.12500\n",
      "[2, 2150] train_loss: 0.81789 train_acc: 78.12500 val_loss: 1.24744 val_acc: 68.12500\n",
      "[2, 2160] train_loss: 1.00920 train_acc: 72.50000 val_loss: 0.92442 val_acc: 75.00000\n",
      "[2, 2170] train_loss: 0.92006 train_acc: 76.87500 val_loss: 1.09784 val_acc: 73.75000\n",
      "[2, 2180] train_loss: 0.95398 train_acc: 76.25000 val_loss: 1.33201 val_acc: 69.37500\n",
      "[2, 2190] train_loss: 1.03300 train_acc: 72.18750 val_loss: 1.28411 val_acc: 67.50000\n",
      "[2, 2200] train_loss: 1.14662 train_acc: 69.37500 val_loss: 1.41337 val_acc: 70.62500\n",
      "[2, 2210] train_loss: 0.83784 train_acc: 76.25000 val_loss: 0.98188 val_acc: 79.37500\n",
      "[2, 2220] train_loss: 0.86078 train_acc: 77.50000 val_loss: 1.20080 val_acc: 68.75000\n",
      "[2, 2230] train_loss: 1.03979 train_acc: 73.75000 val_loss: 1.15878 val_acc: 71.87500\n",
      "[2, 2240] train_loss: 0.80623 train_acc: 76.56250 val_loss: 1.39494 val_acc: 71.87500\n",
      "[2, 2250] train_loss: 0.97179 train_acc: 73.43750 val_loss: 1.23991 val_acc: 71.25000\n",
      "[2, 2260] train_loss: 1.01840 train_acc: 71.87500 val_loss: 1.03367 val_acc: 75.00000\n",
      "[2, 2270] train_loss: 0.96503 train_acc: 75.00000 val_loss: 1.17955 val_acc: 73.75000\n",
      "[2, 2280] train_loss: 0.81330 train_acc: 80.00000 val_loss: 1.03474 val_acc: 75.62500\n",
      "[2, 2290] train_loss: 0.88800 train_acc: 77.50000 val_loss: 1.45076 val_acc: 65.00000\n",
      "[2, 2300] train_loss: 0.92921 train_acc: 75.93750 val_loss: 1.09854 val_acc: 72.50000\n",
      "[2, 2310] train_loss: 0.83649 train_acc: 77.81250 val_loss: 1.22944 val_acc: 68.75000\n",
      "[2, 2320] train_loss: 0.94447 train_acc: 76.87500 val_loss: 1.40113 val_acc: 65.62500\n",
      "[2, 2330] train_loss: 0.89219 train_acc: 77.81250 val_loss: 1.22273 val_acc: 75.62500\n",
      "[2, 2340] train_loss: 0.79984 train_acc: 80.62500 val_loss: 1.13368 val_acc: 70.62500\n",
      "[2, 2350] train_loss: 0.76357 train_acc: 80.00000 val_loss: 1.20473 val_acc: 70.00000\n",
      "[2, 2360] train_loss: 0.87338 train_acc: 74.68750 val_loss: 1.08725 val_acc: 77.50000\n",
      "[2, 2370] train_loss: 0.70263 train_acc: 81.25000 val_loss: 1.23553 val_acc: 72.50000\n",
      "[2, 2380] train_loss: 0.90524 train_acc: 76.56250 val_loss: 1.16839 val_acc: 72.50000\n",
      "[2, 2390] train_loss: 1.02528 train_acc: 74.68750 val_loss: 1.05871 val_acc: 73.75000\n",
      "[2, 2400] train_loss: 0.90157 train_acc: 76.25000 val_loss: 1.05285 val_acc: 74.37500\n",
      "[2, 2410] train_loss: 0.98623 train_acc: 72.18750 val_loss: 1.21630 val_acc: 71.87500\n",
      "[2, 2420] train_loss: 0.86830 train_acc: 77.50000 val_loss: 0.99768 val_acc: 74.37500\n",
      "[2, 2430] train_loss: 0.90408 train_acc: 80.00000 val_loss: 1.19035 val_acc: 72.50000\n",
      "[2, 2440] train_loss: 0.94219 train_acc: 75.93750 val_loss: 1.14470 val_acc: 69.37500\n",
      "[2, 2450] train_loss: 1.06722 train_acc: 74.37500 val_loss: 1.17995 val_acc: 70.62500\n",
      "[2, 2460] train_loss: 0.85885 train_acc: 79.37500 val_loss: 0.98831 val_acc: 75.62500\n",
      "[2, 2470] train_loss: 0.91544 train_acc: 77.50000 val_loss: 1.09075 val_acc: 76.25000\n",
      "[2, 2480] train_loss: 0.89238 train_acc: 76.87500 val_loss: 1.16293 val_acc: 75.62500\n",
      "[2, 2490] train_loss: 0.94294 train_acc: 75.62500 val_loss: 1.21050 val_acc: 70.62500\n",
      "[2, 2500] train_loss: 0.88898 train_acc: 76.25000 val_loss: 1.58062 val_acc: 70.00000\n",
      "[2, 2510] train_loss: 1.06523 train_acc: 69.68750 val_loss: 1.25124 val_acc: 70.00000\n",
      "[2, 2520] train_loss: 0.92997 train_acc: 75.62500 val_loss: 1.07993 val_acc: 73.75000\n",
      "[2, 2530] train_loss: 0.87616 train_acc: 78.75000 val_loss: 1.36863 val_acc: 70.62500\n",
      "[2, 2540] train_loss: 0.82338 train_acc: 79.68750 val_loss: 1.43749 val_acc: 69.37500\n",
      "[2, 2550] train_loss: 0.82508 train_acc: 76.25000 val_loss: 1.10999 val_acc: 71.25000\n",
      "[2, 2560] train_loss: 0.92217 train_acc: 76.87500 val_loss: 1.26863 val_acc: 70.62500\n",
      "[2, 2570] train_loss: 0.85347 train_acc: 77.81250 val_loss: 1.24117 val_acc: 68.12500\n",
      "[2, 2580] train_loss: 0.87116 train_acc: 77.50000 val_loss: 1.27017 val_acc: 70.00000\n",
      "[2, 2590] train_loss: 0.92624 train_acc: 75.93750 val_loss: 1.21403 val_acc: 73.75000\n",
      "[2, 2600] train_loss: 0.83915 train_acc: 78.12500 val_loss: 1.29429 val_acc: 71.87500\n",
      "[2, 2610] train_loss: 0.87990 train_acc: 78.12500 val_loss: 1.43456 val_acc: 70.00000\n",
      "[2, 2620] train_loss: 0.90073 train_acc: 78.75000 val_loss: 1.06176 val_acc: 72.50000\n",
      "[2, 2630] train_loss: 0.88663 train_acc: 76.87500 val_loss: 0.98288 val_acc: 75.00000\n",
      "[2, 2640] train_loss: 0.92051 train_acc: 76.25000 val_loss: 1.17113 val_acc: 71.25000\n",
      "[2, 2650] train_loss: 1.07346 train_acc: 71.56250 val_loss: 1.21540 val_acc: 75.62500\n",
      "[2, 2660] train_loss: 1.02407 train_acc: 72.81250 val_loss: 0.94123 val_acc: 78.12500\n",
      "[2, 2670] train_loss: 0.82113 train_acc: 79.68750 val_loss: 1.20488 val_acc: 68.12500\n",
      "[2, 2680] train_loss: 0.98293 train_acc: 75.00000 val_loss: 1.19911 val_acc: 72.50000\n",
      "[2, 2690] train_loss: 0.83750 train_acc: 77.50000 val_loss: 1.21474 val_acc: 74.37500\n",
      "[2, 2700] train_loss: 0.81728 train_acc: 80.00000 val_loss: 1.25344 val_acc: 67.50000\n",
      "[2, 2710] train_loss: 0.82181 train_acc: 77.81250 val_loss: 1.25743 val_acc: 70.00000\n",
      "[2, 2720] train_loss: 0.93168 train_acc: 75.00000 val_loss: 1.00556 val_acc: 75.00000\n",
      "[2, 2730] train_loss: 0.84868 train_acc: 77.50000 val_loss: 1.19739 val_acc: 74.37500\n",
      "[2, 2740] train_loss: 0.87374 train_acc: 78.12500 val_loss: 1.31929 val_acc: 70.62500\n",
      "[2, 2750] train_loss: 0.89068 train_acc: 78.12500 val_loss: 1.39742 val_acc: 68.12500\n",
      "[2, 2760] train_loss: 0.88069 train_acc: 75.31250 val_loss: 1.17093 val_acc: 70.00000\n",
      "[2, 2770] train_loss: 0.87777 train_acc: 77.50000 val_loss: 1.29253 val_acc: 69.37500\n",
      "[2, 2780] train_loss: 0.93284 train_acc: 75.62500 val_loss: 1.20140 val_acc: 74.37500\n",
      "[2, 2790] train_loss: 0.92817 train_acc: 76.56250 val_loss: 1.21204 val_acc: 73.75000\n",
      "[2, 2800] train_loss: 0.95278 train_acc: 75.93750 val_loss: 1.14698 val_acc: 72.50000\n",
      "[2, 2810] train_loss: 0.95557 train_acc: 74.37500 val_loss: 1.24423 val_acc: 73.75000\n",
      "[2, 2820] train_loss: 0.87992 train_acc: 79.37500 val_loss: 1.18154 val_acc: 70.62500\n",
      "[2, 2830] train_loss: 1.05689 train_acc: 73.75000 val_loss: 1.45042 val_acc: 64.37500\n",
      "[2, 2840] train_loss: 0.81697 train_acc: 79.37500 val_loss: 0.95278 val_acc: 75.62500\n",
      "[2, 2850] train_loss: 0.90425 train_acc: 78.43750 val_loss: 1.24150 val_acc: 70.62500\n",
      "[2, 2860] train_loss: 0.76698 train_acc: 77.50000 val_loss: 1.06745 val_acc: 76.25000\n",
      "[2, 2870] train_loss: 0.99570 train_acc: 75.31250 val_loss: 1.17200 val_acc: 75.00000\n",
      "[2, 2880] train_loss: 0.86406 train_acc: 78.12500 val_loss: 1.01946 val_acc: 72.50000\n",
      "[2, 2890] train_loss: 0.76362 train_acc: 81.56250 val_loss: 1.13641 val_acc: 74.37500\n",
      "[2, 2900] train_loss: 0.89438 train_acc: 77.18750 val_loss: 1.28279 val_acc: 71.25000\n",
      "[2, 2910] train_loss: 0.97876 train_acc: 73.12500 val_loss: 1.14900 val_acc: 75.00000\n",
      "[2, 2920] train_loss: 0.83779 train_acc: 77.81250 val_loss: 1.14834 val_acc: 71.87500\n",
      "[2, 2930] train_loss: 0.99828 train_acc: 74.37500 val_loss: 0.85664 val_acc: 78.75000\n",
      "[2, 2940] train_loss: 1.03097 train_acc: 72.50000 val_loss: 1.11615 val_acc: 73.75000\n",
      "[2, 2950] train_loss: 0.99151 train_acc: 72.50000 val_loss: 1.40772 val_acc: 66.87500\n",
      "[2, 2960] train_loss: 0.84935 train_acc: 78.43750 val_loss: 1.30823 val_acc: 68.12500\n",
      "[2, 2970] train_loss: 0.87223 train_acc: 76.87500 val_loss: 1.13938 val_acc: 72.50000\n",
      "[2, 2980] train_loss: 0.85241 train_acc: 79.37500 val_loss: 1.11026 val_acc: 71.25000\n",
      "[2, 2990] train_loss: 0.73646 train_acc: 79.37500 val_loss: 1.15393 val_acc: 72.50000\n",
      "[2, 3000] train_loss: 0.96440 train_acc: 75.00000 val_loss: 1.13094 val_acc: 75.62500\n",
      "[2, 3010] train_loss: 0.92639 train_acc: 76.56250 val_loss: 1.05794 val_acc: 76.25000\n",
      "[2, 3020] train_loss: 0.80756 train_acc: 80.00000 val_loss: 1.31403 val_acc: 71.87500\n",
      "[2, 3030] train_loss: 0.88545 train_acc: 75.62500 val_loss: 1.08673 val_acc: 73.12500\n",
      "[2, 3040] train_loss: 0.75793 train_acc: 80.00000 val_loss: 1.11697 val_acc: 76.87500\n",
      "[2, 3050] train_loss: 0.79197 train_acc: 78.75000 val_loss: 1.01085 val_acc: 76.87500\n",
      "[2, 3060] train_loss: 0.79278 train_acc: 77.81250 val_loss: 1.27844 val_acc: 71.25000\n",
      "[2, 3070] train_loss: 0.86039 train_acc: 79.68750 val_loss: 1.00352 val_acc: 78.12500\n",
      "[2, 3080] train_loss: 0.75667 train_acc: 80.93750 val_loss: 1.19125 val_acc: 71.25000\n",
      "[2, 3090] train_loss: 0.93326 train_acc: 76.56250 val_loss: 1.41232 val_acc: 67.50000\n",
      "[2, 3100] train_loss: 0.99742 train_acc: 73.43750 val_loss: 1.31416 val_acc: 75.00000\n",
      "[2, 3110] train_loss: 0.84133 train_acc: 78.75000 val_loss: 1.08333 val_acc: 76.25000\n",
      "[2, 3120] train_loss: 0.82240 train_acc: 80.31250 val_loss: 0.97938 val_acc: 76.25000\n",
      "[2, 3130] train_loss: 0.77837 train_acc: 80.93750 val_loss: 1.17906 val_acc: 76.25000\n",
      "[2, 3140] train_loss: 0.93989 train_acc: 75.00000 val_loss: 1.03620 val_acc: 75.62500\n",
      "[2, 3150] train_loss: 0.85754 train_acc: 78.12500 val_loss: 1.31484 val_acc: 69.37500\n",
      "[2, 3160] train_loss: 0.93297 train_acc: 75.31250 val_loss: 1.30056 val_acc: 69.37500\n",
      "[2, 3170] train_loss: 0.90238 train_acc: 74.06250 val_loss: 1.27670 val_acc: 67.50000\n",
      "[2, 3180] train_loss: 0.80625 train_acc: 78.75000 val_loss: 1.25366 val_acc: 69.37500\n",
      "[2, 3190] train_loss: 0.82818 train_acc: 79.68750 val_loss: 1.26634 val_acc: 70.62500\n",
      "[2, 3200] train_loss: 0.82945 train_acc: 79.37500 val_loss: 1.12261 val_acc: 74.37500\n",
      "[2, 3210] train_loss: 0.85130 train_acc: 75.62500 val_loss: 1.11470 val_acc: 74.37500\n",
      "[2, 3220] train_loss: 0.96871 train_acc: 75.31250 val_loss: 1.35288 val_acc: 70.00000\n",
      "[2, 3230] train_loss: 0.93564 train_acc: 77.18750 val_loss: 1.26247 val_acc: 70.62500\n",
      "[2, 3240] train_loss: 1.06549 train_acc: 72.18750 val_loss: 0.97996 val_acc: 75.00000\n",
      "[2, 3250] train_loss: 0.86458 train_acc: 76.25000 val_loss: 1.15816 val_acc: 73.12500\n",
      "[2, 3260] train_loss: 0.79085 train_acc: 79.06250 val_loss: 0.93590 val_acc: 73.75000\n",
      "[2, 3270] train_loss: 0.86485 train_acc: 80.31250 val_loss: 1.29044 val_acc: 71.25000\n",
      "[2, 3280] train_loss: 0.88252 train_acc: 74.37500 val_loss: 1.11601 val_acc: 71.87500\n",
      "[2, 3290] train_loss: 0.98431 train_acc: 74.37500 val_loss: 1.02311 val_acc: 76.25000\n",
      "[2, 3300] train_loss: 0.93821 train_acc: 75.93750 val_loss: 1.40956 val_acc: 65.62500\n",
      "[2, 3310] train_loss: 0.88327 train_acc: 75.62500 val_loss: 1.20469 val_acc: 74.37500\n",
      "[2, 3320] train_loss: 0.83236 train_acc: 76.87500 val_loss: 1.35616 val_acc: 76.25000\n",
      "[2, 3330] train_loss: 0.84048 train_acc: 79.06250 val_loss: 1.01173 val_acc: 77.50000\n",
      "[2, 3340] train_loss: 1.02643 train_acc: 75.62500 val_loss: 1.27029 val_acc: 72.50000\n",
      "[2, 3350] train_loss: 0.97470 train_acc: 77.18750 val_loss: 1.11342 val_acc: 78.75000\n",
      "[2, 3360] train_loss: 0.74959 train_acc: 80.31250 val_loss: 1.41707 val_acc: 66.25000\n",
      "[2, 3370] train_loss: 0.82103 train_acc: 76.25000 val_loss: 1.14939 val_acc: 76.25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3380] train_loss: 0.74043 train_acc: 79.68750 val_loss: 1.08267 val_acc: 72.50000\n",
      "[2, 3390] train_loss: 0.90229 train_acc: 76.87500 val_loss: 1.29013 val_acc: 71.87500\n",
      "[2, 3400] train_loss: 0.89504 train_acc: 78.12500 val_loss: 1.15935 val_acc: 72.50000\n",
      "[2, 3410] train_loss: 0.90286 train_acc: 79.37500 val_loss: 0.96000 val_acc: 76.87500\n",
      "[2, 3420] train_loss: 0.86211 train_acc: 77.81250 val_loss: 1.06130 val_acc: 73.12500\n",
      "[2, 3430] train_loss: 0.83625 train_acc: 78.43750 val_loss: 0.85657 val_acc: 80.00000\n",
      "[2, 3440] train_loss: 0.77055 train_acc: 78.12500 val_loss: 1.28511 val_acc: 73.12500\n",
      "[2, 3450] train_loss: 0.85072 train_acc: 78.75000 val_loss: 1.42013 val_acc: 67.50000\n",
      "[2, 3460] train_loss: 0.89189 train_acc: 77.81250 val_loss: 1.18166 val_acc: 72.50000\n",
      "[2, 3470] train_loss: 0.84303 train_acc: 79.68750 val_loss: 1.34543 val_acc: 70.00000\n",
      "[2, 3480] train_loss: 0.88704 train_acc: 78.43750 val_loss: 1.07608 val_acc: 76.25000\n",
      "[2, 3490] train_loss: 0.92354 train_acc: 76.56250 val_loss: 1.09173 val_acc: 75.62500\n",
      "[2, 3500] train_loss: 0.86846 train_acc: 74.68750 val_loss: 1.23836 val_acc: 74.37500\n",
      "[2, 3510] train_loss: 0.87563 train_acc: 78.75000 val_loss: 1.00881 val_acc: 78.12500\n",
      "[2, 3520] train_loss: 1.07601 train_acc: 74.37500 val_loss: 0.99311 val_acc: 79.37500\n",
      "[2, 3530] train_loss: 0.74752 train_acc: 81.56250 val_loss: 1.11898 val_acc: 76.87500\n",
      "[2, 3540] train_loss: 0.74981 train_acc: 80.93750 val_loss: 1.35242 val_acc: 70.00000\n",
      "[2, 3550] train_loss: 0.71217 train_acc: 78.75000 val_loss: 1.26047 val_acc: 75.00000\n",
      "[2, 3560] train_loss: 0.94659 train_acc: 75.62500 val_loss: 1.04500 val_acc: 78.12500\n",
      "[2, 3570] train_loss: 0.91150 train_acc: 77.81250 val_loss: 1.12490 val_acc: 73.12500\n",
      "[2, 3580] train_loss: 0.75215 train_acc: 81.87500 val_loss: 1.40935 val_acc: 68.75000\n",
      "[2, 3590] train_loss: 0.95080 train_acc: 75.62500 val_loss: 1.28778 val_acc: 68.75000\n",
      "[2, 3600] train_loss: 0.82040 train_acc: 78.43750 val_loss: 1.20034 val_acc: 66.87500\n",
      "[2, 3610] train_loss: 1.07447 train_acc: 73.12500 val_loss: 1.14092 val_acc: 75.00000\n",
      "[2, 3620] train_loss: 0.97275 train_acc: 72.81250 val_loss: 1.15408 val_acc: 73.12500\n",
      "[2, 3630] train_loss: 0.78239 train_acc: 80.00000 val_loss: 0.97144 val_acc: 78.12500\n",
      "[2, 3640] train_loss: 0.92162 train_acc: 76.56250 val_loss: 1.16477 val_acc: 75.62500\n",
      "[2, 3650] train_loss: 0.85747 train_acc: 79.06250 val_loss: 1.16871 val_acc: 70.62500\n",
      "[2, 3660] train_loss: 1.10361 train_acc: 72.18750 val_loss: 1.17416 val_acc: 74.37500\n",
      "[2, 3670] train_loss: 0.88728 train_acc: 80.31250 val_loss: 1.15943 val_acc: 74.37500\n",
      "[2, 3680] train_loss: 0.84824 train_acc: 75.62500 val_loss: 1.26822 val_acc: 68.12500\n",
      "[2, 3690] train_loss: 1.03151 train_acc: 73.43750 val_loss: 1.11641 val_acc: 73.75000\n",
      "[2, 3700] train_loss: 0.98421 train_acc: 71.56250 val_loss: 1.30175 val_acc: 68.75000\n",
      "[2, 3710] train_loss: 0.95755 train_acc: 73.12500 val_loss: 1.31119 val_acc: 68.75000\n",
      "[2, 3720] train_loss: 1.03284 train_acc: 75.93750 val_loss: 1.25378 val_acc: 70.62500\n",
      "[2, 3730] train_loss: 0.97938 train_acc: 75.93750 val_loss: 1.15198 val_acc: 71.87500\n",
      "[2, 3740] train_loss: 0.95174 train_acc: 74.37500 val_loss: 1.54678 val_acc: 68.75000\n",
      "[2, 3750] train_loss: 0.79934 train_acc: 79.68750 val_loss: 1.17811 val_acc: 75.62500\n",
      "[2, 3760] train_loss: 1.03742 train_acc: 72.81250 val_loss: 1.14864 val_acc: 73.75000\n",
      "[2, 3770] train_loss: 0.78803 train_acc: 79.06250 val_loss: 1.39596 val_acc: 66.87500\n",
      "[2, 3780] train_loss: 0.79361 train_acc: 79.37500 val_loss: 0.96776 val_acc: 78.75000\n",
      "[2, 3790] train_loss: 0.97766 train_acc: 76.25000 val_loss: 0.97350 val_acc: 75.00000\n",
      "[2, 3800] train_loss: 0.86901 train_acc: 76.87500 val_loss: 1.23323 val_acc: 71.87500\n",
      "[2, 3810] train_loss: 0.88392 train_acc: 77.18750 val_loss: 0.99726 val_acc: 77.50000\n",
      "[2, 3820] train_loss: 0.88963 train_acc: 75.62500 val_loss: 1.03827 val_acc: 75.00000\n",
      "[2, 3830] train_loss: 0.76763 train_acc: 78.75000 val_loss: 0.64022 val_acc: 84.37500\n",
      "[2, 3840] train_loss: 0.79897 train_acc: 79.68750 val_loss: 1.24181 val_acc: 71.87500\n",
      "[2, 3850] train_loss: 0.91756 train_acc: 76.56250 val_loss: 1.14540 val_acc: 70.00000\n",
      "[2, 3860] train_loss: 0.71718 train_acc: 81.56250 val_loss: 1.33885 val_acc: 73.12500\n",
      "[2, 3870] train_loss: 0.91838 train_acc: 76.56250 val_loss: 0.94322 val_acc: 76.87500\n",
      "[2, 3880] train_loss: 0.90861 train_acc: 75.31250 val_loss: 1.41401 val_acc: 64.37500\n",
      "[2, 3890] train_loss: 0.80471 train_acc: 78.43750 val_loss: 1.10510 val_acc: 73.75000\n",
      "[2, 3900] train_loss: 0.74593 train_acc: 79.06250 val_loss: 0.95976 val_acc: 78.12500\n",
      "[2, 3910] train_loss: 0.82808 train_acc: 79.06250 val_loss: 1.21646 val_acc: 71.87500\n",
      "[2, 3920] train_loss: 0.92371 train_acc: 75.62500 val_loss: 1.38267 val_acc: 71.87500\n",
      "[2, 3930] train_loss: 0.89802 train_acc: 78.75000 val_loss: 1.05326 val_acc: 76.25000\n",
      "[2, 3940] train_loss: 0.82771 train_acc: 77.50000 val_loss: 1.13436 val_acc: 76.25000\n",
      "[2, 3950] train_loss: 0.87134 train_acc: 77.50000 val_loss: 1.10731 val_acc: 76.87500\n",
      "[2, 3960] train_loss: 1.01506 train_acc: 70.62500 val_loss: 0.93914 val_acc: 76.25000\n",
      "[2, 3970] train_loss: 0.77243 train_acc: 80.31250 val_loss: 0.96998 val_acc: 76.25000\n",
      "[2, 3980] train_loss: 0.85577 train_acc: 80.62500 val_loss: 1.29184 val_acc: 67.50000\n",
      "[2, 3990] train_loss: 0.76740 train_acc: 81.56250 val_loss: 0.92263 val_acc: 80.00000\n",
      "[2, 4000] train_loss: 0.78283 train_acc: 78.75000 val_loss: 1.01023 val_acc: 75.00000\n",
      "[2, 4010] train_loss: 0.90744 train_acc: 76.25000 val_loss: 1.18171 val_acc: 73.12500\n",
      "[2, 4020] train_loss: 0.79796 train_acc: 80.31250 val_loss: 1.15425 val_acc: 74.37500\n",
      "[2, 4030] train_loss: 0.80904 train_acc: 78.43750 val_loss: 1.61148 val_acc: 63.75000\n",
      "[2, 4040] train_loss: 0.70881 train_acc: 83.43750 val_loss: 1.13835 val_acc: 73.75000\n",
      "[2, 4050] train_loss: 0.79181 train_acc: 80.93750 val_loss: 1.45223 val_acc: 66.87500\n",
      "[2, 4060] train_loss: 0.76531 train_acc: 79.37500 val_loss: 1.07074 val_acc: 72.50000\n",
      "[2, 4070] train_loss: 0.76330 train_acc: 80.62500 val_loss: 1.23184 val_acc: 73.12500\n",
      "[2, 4080] train_loss: 0.69539 train_acc: 80.31250 val_loss: 1.13766 val_acc: 76.87500\n",
      "[2, 4090] train_loss: 0.73942 train_acc: 81.25000 val_loss: 1.18050 val_acc: 74.37500\n",
      "[2, 4100] train_loss: 0.98582 train_acc: 73.43750 val_loss: 0.96654 val_acc: 74.37500\n",
      "[2, 4110] train_loss: 0.89378 train_acc: 78.75000 val_loss: 1.29014 val_acc: 71.87500\n",
      "[2, 4120] train_loss: 0.84296 train_acc: 77.81250 val_loss: 1.15936 val_acc: 71.87500\n",
      "[2, 4130] train_loss: 0.86718 train_acc: 76.56250 val_loss: 1.14003 val_acc: 75.00000\n",
      "[2, 4140] train_loss: 0.83782 train_acc: 78.43750 val_loss: 1.24777 val_acc: 70.62500\n",
      "[2, 4150] train_loss: 0.86512 train_acc: 76.25000 val_loss: 1.00185 val_acc: 78.12500\n",
      "[2, 4160] train_loss: 0.75603 train_acc: 78.43750 val_loss: 1.00082 val_acc: 71.87500\n",
      "[2, 4170] train_loss: 0.89931 train_acc: 77.81250 val_loss: 1.22771 val_acc: 69.37500\n",
      "[2, 4180] train_loss: 0.93137 train_acc: 77.50000 val_loss: 1.28943 val_acc: 67.50000\n",
      "[2, 4190] train_loss: 0.88473 train_acc: 78.43750 val_loss: 1.03002 val_acc: 77.50000\n",
      "[2, 4200] train_loss: 0.95258 train_acc: 74.68750 val_loss: 1.14190 val_acc: 71.25000\n",
      "[2, 4210] train_loss: 0.95310 train_acc: 77.50000 val_loss: 1.23165 val_acc: 72.50000\n",
      "[2, 4220] train_loss: 0.92486 train_acc: 75.31250 val_loss: 1.06822 val_acc: 75.62500\n",
      "[2, 4230] train_loss: 0.76852 train_acc: 79.06250 val_loss: 1.28765 val_acc: 70.62500\n",
      "[2, 4240] train_loss: 0.97347 train_acc: 73.43750 val_loss: 1.17520 val_acc: 73.12500\n",
      "[2, 4250] train_loss: 0.81085 train_acc: 78.43750 val_loss: 0.99045 val_acc: 74.37500\n",
      "[2, 4260] train_loss: 0.89074 train_acc: 76.25000 val_loss: 1.75043 val_acc: 65.00000\n",
      "[2, 4270] train_loss: 0.83983 train_acc: 77.18750 val_loss: 1.15749 val_acc: 74.37500\n",
      "[2, 4280] train_loss: 0.92602 train_acc: 75.93750 val_loss: 1.26290 val_acc: 72.50000\n",
      "[2, 4290] train_loss: 0.87338 train_acc: 77.50000 val_loss: 1.06535 val_acc: 75.00000\n",
      "[2, 4300] train_loss: 0.77497 train_acc: 82.18750 val_loss: 0.80428 val_acc: 81.25000\n",
      "[2, 4310] train_loss: 0.77554 train_acc: 80.00000 val_loss: 1.03116 val_acc: 75.62500\n",
      "[2, 4320] train_loss: 0.91410 train_acc: 76.87500 val_loss: 1.12950 val_acc: 74.37500\n",
      "[2, 4330] train_loss: 0.78776 train_acc: 80.93750 val_loss: 0.98851 val_acc: 75.62500\n",
      "[2, 4340] train_loss: 0.65190 train_acc: 81.87500 val_loss: 1.05461 val_acc: 73.75000\n",
      "[2, 4350] train_loss: 0.76867 train_acc: 77.50000 val_loss: 1.19301 val_acc: 73.75000\n",
      "[2, 4360] train_loss: 0.78978 train_acc: 81.56250 val_loss: 1.13257 val_acc: 75.00000\n",
      "[2, 4370] train_loss: 0.77275 train_acc: 81.25000 val_loss: 1.25903 val_acc: 68.12500\n",
      "[2, 4380] train_loss: 0.84531 train_acc: 77.81250 val_loss: 1.11429 val_acc: 80.62500\n",
      "[2, 4390] train_loss: 0.84787 train_acc: 77.18750 val_loss: 1.17137 val_acc: 76.25000\n",
      "[2, 4400] train_loss: 0.81360 train_acc: 79.06250 val_loss: 0.92883 val_acc: 80.62500\n",
      "[2, 4410] train_loss: 0.78032 train_acc: 82.50000 val_loss: 1.25458 val_acc: 69.37500\n",
      "[2, 4420] train_loss: 0.84170 train_acc: 78.12500 val_loss: 1.27716 val_acc: 70.00000\n",
      "[2, 4430] train_loss: 0.86130 train_acc: 77.50000 val_loss: 1.01025 val_acc: 76.25000\n",
      "[2, 4440] train_loss: 0.73027 train_acc: 81.25000 val_loss: 1.23267 val_acc: 72.50000\n",
      "[2, 4450] train_loss: 0.99554 train_acc: 76.56250 val_loss: 1.10486 val_acc: 75.62500\n",
      "[2, 4460] train_loss: 0.77440 train_acc: 77.81250 val_loss: 0.99294 val_acc: 78.75000\n",
      "[2, 4470] train_loss: 0.81729 train_acc: 77.50000 val_loss: 1.02565 val_acc: 75.00000\n",
      "[2, 4480] train_loss: 0.85501 train_acc: 77.18750 val_loss: 1.21960 val_acc: 70.62500\n",
      "[2, 4490] train_loss: 0.75300 train_acc: 80.62500 val_loss: 0.96539 val_acc: 78.75000\n",
      "[2, 4500] train_loss: 0.73779 train_acc: 83.43750 val_loss: 1.09956 val_acc: 70.00000\n",
      "[2, 4510] train_loss: 0.82821 train_acc: 77.81250 val_loss: 0.92925 val_acc: 80.62500\n",
      "[2, 4520] train_loss: 0.73255 train_acc: 82.50000 val_loss: 0.98598 val_acc: 75.62500\n",
      "[2, 4530] train_loss: 0.75045 train_acc: 81.56250 val_loss: 1.18532 val_acc: 73.75000\n",
      "[2, 4540] train_loss: 0.85428 train_acc: 76.87500 val_loss: 1.16955 val_acc: 72.50000\n",
      "[2, 4550] train_loss: 0.75300 train_acc: 80.62500 val_loss: 1.20691 val_acc: 72.50000\n",
      "[2, 4560] train_loss: 0.73202 train_acc: 80.00000 val_loss: 1.28146 val_acc: 71.25000\n",
      "[2, 4570] train_loss: 0.85961 train_acc: 76.87500 val_loss: 1.16183 val_acc: 71.87500\n",
      "[2, 4580] train_loss: 0.80421 train_acc: 78.75000 val_loss: 1.00238 val_acc: 75.00000\n",
      "[2, 4590] train_loss: 0.85908 train_acc: 78.43750 val_loss: 1.06277 val_acc: 75.00000\n",
      "[2, 4600] train_loss: 0.96931 train_acc: 73.75000 val_loss: 1.01390 val_acc: 75.62500\n",
      "[2, 4610] train_loss: 0.90433 train_acc: 77.81250 val_loss: 1.07622 val_acc: 71.25000\n",
      "[2, 4620] train_loss: 0.87752 train_acc: 78.75000 val_loss: 1.22455 val_acc: 73.75000\n",
      "[2, 4630] train_loss: 0.75529 train_acc: 79.37500 val_loss: 1.31812 val_acc: 71.87500\n",
      "[2, 4640] train_loss: 0.77107 train_acc: 79.37500 val_loss: 1.09467 val_acc: 73.75000\n",
      "[2, 4650] train_loss: 0.87172 train_acc: 77.81250 val_loss: 1.00658 val_acc: 75.62500\n",
      "[2, 4660] train_loss: 0.79854 train_acc: 77.50000 val_loss: 1.27417 val_acc: 74.37500\n",
      "[2, 4670] train_loss: 0.68419 train_acc: 82.81250 val_loss: 1.07020 val_acc: 73.12500\n",
      "[2, 4680] train_loss: 0.77706 train_acc: 82.50000 val_loss: 0.96838 val_acc: 74.37500\n",
      "[2, 4690] train_loss: 0.89443 train_acc: 78.75000 val_loss: 0.86361 val_acc: 77.50000\n",
      "[2, 4700] train_loss: 0.85163 train_acc: 76.87500 val_loss: 1.09879 val_acc: 75.62500\n",
      "[2, 4710] train_loss: 0.86298 train_acc: 75.93750 val_loss: 1.04707 val_acc: 75.00000\n",
      "[2, 4720] train_loss: 0.79822 train_acc: 79.06250 val_loss: 1.15469 val_acc: 71.87500\n",
      "[2, 4730] train_loss: 0.83567 train_acc: 77.18750 val_loss: 1.02852 val_acc: 77.50000\n",
      "[2, 4740] train_loss: 0.93925 train_acc: 76.87500 val_loss: 1.06926 val_acc: 71.87500\n",
      "[2, 4750] train_loss: 0.76077 train_acc: 79.68750 val_loss: 1.07824 val_acc: 77.50000\n",
      "[2, 4760] train_loss: 0.81744 train_acc: 79.06250 val_loss: 1.23116 val_acc: 69.37500\n",
      "[2, 4770] train_loss: 0.72117 train_acc: 81.87500 val_loss: 1.05831 val_acc: 73.75000\n",
      "[2, 4780] train_loss: 0.92640 train_acc: 76.25000 val_loss: 1.26684 val_acc: 67.50000\n",
      "[2, 4790] train_loss: 0.77845 train_acc: 80.31250 val_loss: 1.04312 val_acc: 72.50000\n",
      "[2, 4800] train_loss: 0.89283 train_acc: 75.00000 val_loss: 1.05528 val_acc: 74.37500\n",
      "[2, 4810] train_loss: 0.67656 train_acc: 82.50000 val_loss: 1.24170 val_acc: 71.87500\n",
      "[2, 4820] train_loss: 0.82613 train_acc: 76.87500 val_loss: 0.94845 val_acc: 74.37500\n",
      "[2, 4830] train_loss: 0.97569 train_acc: 75.31250 val_loss: 1.01878 val_acc: 75.62500\n",
      "[2, 4840] train_loss: 0.83079 train_acc: 78.12500 val_loss: 1.07003 val_acc: 76.87500\n",
      "[2, 4850] train_loss: 0.65913 train_acc: 80.00000 val_loss: 1.19423 val_acc: 73.75000\n",
      "[2, 4860] train_loss: 0.80997 train_acc: 80.31250 val_loss: 0.93048 val_acc: 78.75000\n",
      "[2, 4870] train_loss: 0.79140 train_acc: 78.75000 val_loss: 0.97563 val_acc: 78.12500\n",
      "[2, 4880] train_loss: 0.67410 train_acc: 81.56250 val_loss: 1.17041 val_acc: 75.00000\n",
      "[2, 4890] train_loss: 0.84109 train_acc: 78.43750 val_loss: 1.07304 val_acc: 75.62500\n",
      "[2, 4900] train_loss: 0.95025 train_acc: 75.31250 val_loss: 1.09175 val_acc: 75.62500\n",
      "[2, 4910] train_loss: 0.81702 train_acc: 78.43750 val_loss: 0.87781 val_acc: 82.50000\n",
      "[2, 4920] train_loss: 0.72264 train_acc: 82.50000 val_loss: 1.11059 val_acc: 72.50000\n",
      "[2, 4930] train_loss: 0.72212 train_acc: 81.56250 val_loss: 0.93073 val_acc: 74.37500\n",
      "[2, 4940] train_loss: 0.82745 train_acc: 79.06250 val_loss: 0.85392 val_acc: 77.50000\n",
      "[2, 4950] train_loss: 0.85461 train_acc: 77.50000 val_loss: 1.12328 val_acc: 71.25000\n",
      "[2, 4960] train_loss: 0.62109 train_acc: 84.06250 val_loss: 1.07457 val_acc: 75.00000\n",
      "[2, 4970] train_loss: 0.64344 train_acc: 84.37500 val_loss: 1.00897 val_acc: 78.75000\n",
      "[2, 4980] train_loss: 0.69178 train_acc: 80.62500 val_loss: 1.26828 val_acc: 75.00000\n",
      "[2, 4990] train_loss: 0.85001 train_acc: 76.56250 val_loss: 0.89977 val_acc: 79.37500\n",
      "[2, 5000] train_loss: 0.81630 train_acc: 82.81250 val_loss: 1.09542 val_acc: 74.37500\n",
      "[2, 5010] train_loss: 0.79904 train_acc: 79.68750 val_loss: 0.93565 val_acc: 81.25000\n",
      "[2, 5020] train_loss: 0.73562 train_acc: 81.56250 val_loss: 0.96194 val_acc: 74.37500\n",
      "[2, 5030] train_loss: 0.77127 train_acc: 80.93750 val_loss: 0.89443 val_acc: 77.50000\n",
      "[2, 5040] train_loss: 0.76802 train_acc: 80.62500 val_loss: 0.95863 val_acc: 77.50000\n",
      "[2, 5050] train_loss: 0.77926 train_acc: 78.75000 val_loss: 0.84945 val_acc: 80.62500\n",
      "[2, 5060] train_loss: 0.79916 train_acc: 77.18750 val_loss: 0.83554 val_acc: 78.12500\n",
      "[2, 5070] train_loss: 0.85965 train_acc: 76.87500 val_loss: 1.11113 val_acc: 71.87500\n",
      "[2, 5080] train_loss: 0.69405 train_acc: 82.18750 val_loss: 1.11503 val_acc: 73.75000\n",
      "[2, 5090] train_loss: 0.91082 train_acc: 75.62500 val_loss: 1.07259 val_acc: 78.75000\n",
      "[2, 5100] train_loss: 0.86051 train_acc: 79.37500 val_loss: 1.36643 val_acc: 68.12500\n",
      "[2, 5110] train_loss: 0.81854 train_acc: 79.06250 val_loss: 1.12025 val_acc: 72.50000\n",
      "[2, 5120] train_loss: 0.78936 train_acc: 80.00000 val_loss: 1.08742 val_acc: 73.75000\n",
      "[2, 5130] train_loss: 0.65500 train_acc: 81.87500 val_loss: 1.04053 val_acc: 77.50000\n",
      "[2, 5140] train_loss: 0.86234 train_acc: 78.75000 val_loss: 1.05277 val_acc: 72.50000\n",
      "[2, 5150] train_loss: 0.76202 train_acc: 79.68750 val_loss: 0.76553 val_acc: 76.25000\n",
      "[2, 5160] train_loss: 0.81959 train_acc: 80.62500 val_loss: 1.23338 val_acc: 70.62500\n",
      "[2, 5170] train_loss: 0.64030 train_acc: 83.75000 val_loss: 1.13582 val_acc: 75.62500\n",
      "[2, 5180] train_loss: 0.72766 train_acc: 78.12500 val_loss: 1.08052 val_acc: 73.12500\n",
      "[2, 5190] train_loss: 0.90842 train_acc: 79.68750 val_loss: 1.05882 val_acc: 72.50000\n",
      "[2, 5200] train_loss: 0.74425 train_acc: 79.06250 val_loss: 0.97996 val_acc: 78.75000\n",
      "[2, 5210] train_loss: 0.71774 train_acc: 80.62500 val_loss: 0.94890 val_acc: 78.75000\n",
      "[2, 5220] train_loss: 0.78658 train_acc: 78.12500 val_loss: 1.02932 val_acc: 75.62500\n",
      "[2, 5230] train_loss: 0.80901 train_acc: 76.87500 val_loss: 1.34471 val_acc: 71.87500\n",
      "[2, 5240] train_loss: 0.86621 train_acc: 74.37500 val_loss: 0.91463 val_acc: 80.00000\n",
      "[2, 5250] train_loss: 0.74244 train_acc: 77.81250 val_loss: 1.00112 val_acc: 78.75000\n",
      "[2, 5260] train_loss: 0.84088 train_acc: 77.18750 val_loss: 1.17533 val_acc: 71.25000\n",
      "[2, 5270] train_loss: 0.81580 train_acc: 79.68750 val_loss: 1.04215 val_acc: 76.87500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5280] train_loss: 0.78333 train_acc: 79.06250 val_loss: 1.28953 val_acc: 68.12500\n",
      "[2, 5290] train_loss: 0.77245 train_acc: 80.31250 val_loss: 0.90451 val_acc: 78.75000\n",
      "[2, 5300] train_loss: 0.77873 train_acc: 80.00000 val_loss: 0.98656 val_acc: 76.25000\n",
      "[2, 5310] train_loss: 0.92653 train_acc: 75.00000 val_loss: 1.36393 val_acc: 68.75000\n",
      "[2, 5320] train_loss: 0.74420 train_acc: 78.43750 val_loss: 1.03929 val_acc: 77.50000\n",
      "[2, 5330] train_loss: 0.77373 train_acc: 80.31250 val_loss: 1.04601 val_acc: 79.37500\n",
      "[2, 5340] train_loss: 0.80275 train_acc: 77.18750 val_loss: 1.15460 val_acc: 70.62500\n",
      "[2, 5350] train_loss: 0.73327 train_acc: 80.93750 val_loss: 1.34543 val_acc: 69.37500\n",
      "[2, 5360] train_loss: 0.83455 train_acc: 78.75000 val_loss: 1.30758 val_acc: 68.12500\n",
      "[2, 5370] train_loss: 0.82951 train_acc: 79.06250 val_loss: 0.88638 val_acc: 74.37500\n",
      "[2, 5380] train_loss: 0.72328 train_acc: 80.93750 val_loss: 0.88603 val_acc: 78.12500\n",
      "[2, 5390] train_loss: 0.82085 train_acc: 78.12500 val_loss: 1.10840 val_acc: 74.37500\n",
      "[2, 5400] train_loss: 0.79820 train_acc: 80.31250 val_loss: 0.84510 val_acc: 77.50000\n",
      "[2, 5410] train_loss: 0.71848 train_acc: 82.18750 val_loss: 0.84920 val_acc: 76.25000\n",
      "[2, 5420] train_loss: 0.77912 train_acc: 81.25000 val_loss: 1.31601 val_acc: 74.37500\n",
      "[2, 5430] train_loss: 0.84810 train_acc: 77.50000 val_loss: 1.17506 val_acc: 70.62500\n",
      "[2, 5440] train_loss: 0.72869 train_acc: 80.62500 val_loss: 0.89381 val_acc: 77.50000\n",
      "[2, 5450] train_loss: 0.88185 train_acc: 77.50000 val_loss: 1.03831 val_acc: 75.00000\n",
      "[2, 5460] train_loss: 0.65742 train_acc: 82.50000 val_loss: 1.02481 val_acc: 77.50000\n",
      "[2, 5470] train_loss: 0.82091 train_acc: 75.93750 val_loss: 0.92057 val_acc: 79.37500\n",
      "[2, 5480] train_loss: 0.73889 train_acc: 81.56250 val_loss: 1.04891 val_acc: 73.75000\n",
      "[2, 5490] train_loss: 0.73520 train_acc: 81.87500 val_loss: 1.14281 val_acc: 74.37500\n",
      "[2, 5500] train_loss: 0.78962 train_acc: 79.06250 val_loss: 1.15604 val_acc: 75.62500\n",
      "[2, 5510] train_loss: 0.82805 train_acc: 79.06250 val_loss: 0.90103 val_acc: 80.00000\n",
      "[2, 5520] train_loss: 0.88998 train_acc: 79.37500 val_loss: 1.02726 val_acc: 73.75000\n",
      "[2, 5530] train_loss: 0.86120 train_acc: 78.75000 val_loss: 1.23405 val_acc: 71.87500\n",
      "[2, 5540] train_loss: 0.69818 train_acc: 79.37500 val_loss: 1.13425 val_acc: 75.62500\n",
      "[2, 5550] train_loss: 0.76052 train_acc: 82.18750 val_loss: 0.86670 val_acc: 78.75000\n",
      "[2, 5560] train_loss: 0.79333 train_acc: 78.12500 val_loss: 0.99166 val_acc: 75.62500\n",
      "[2, 5570] train_loss: 0.79412 train_acc: 80.00000 val_loss: 1.06234 val_acc: 80.00000\n",
      "[2, 5580] train_loss: 0.83790 train_acc: 79.06250 val_loss: 1.14345 val_acc: 71.87500\n",
      "[2, 5590] train_loss: 0.72492 train_acc: 80.93750 val_loss: 1.30734 val_acc: 69.37500\n",
      "[2, 5600] train_loss: 0.81977 train_acc: 77.50000 val_loss: 1.15799 val_acc: 71.25000\n",
      "[2, 5610] train_loss: 0.83469 train_acc: 80.93750 val_loss: 1.07245 val_acc: 70.62500\n",
      "[2, 5620] train_loss: 0.64360 train_acc: 82.50000 val_loss: 1.01093 val_acc: 76.25000\n",
      "[2, 5630] train_loss: 0.77197 train_acc: 79.06250 val_loss: 1.21875 val_acc: 73.12500\n",
      "[2, 5640] train_loss: 0.76257 train_acc: 77.81250 val_loss: 1.39585 val_acc: 68.75000\n",
      "[2, 5650] train_loss: 0.83762 train_acc: 79.37500 val_loss: 1.22484 val_acc: 68.12500\n",
      "[2, 5660] train_loss: 0.81395 train_acc: 78.75000 val_loss: 1.35217 val_acc: 68.75000\n",
      "[2, 5670] train_loss: 0.82259 train_acc: 78.75000 val_loss: 1.13766 val_acc: 71.87500\n",
      "[2, 5680] train_loss: 0.73787 train_acc: 79.06250 val_loss: 1.24145 val_acc: 72.50000\n",
      "[2, 5690] train_loss: 0.76013 train_acc: 78.12500 val_loss: 1.08567 val_acc: 75.00000\n",
      "[2, 5700] train_loss: 0.88254 train_acc: 77.18750 val_loss: 0.92795 val_acc: 78.75000\n",
      "[2, 5710] train_loss: 0.74829 train_acc: 80.62500 val_loss: 1.19500 val_acc: 75.62500\n",
      "[2, 5720] train_loss: 0.99657 train_acc: 75.00000 val_loss: 0.98515 val_acc: 78.75000\n",
      "[2, 5730] train_loss: 0.74849 train_acc: 80.93750 val_loss: 1.29541 val_acc: 72.50000\n",
      "[2, 5740] train_loss: 0.74928 train_acc: 80.93750 val_loss: 1.27128 val_acc: 72.50000\n",
      "[2, 5750] train_loss: 0.72527 train_acc: 82.50000 val_loss: 1.07847 val_acc: 75.62500\n",
      "[2, 5760] train_loss: 0.77938 train_acc: 75.62500 val_loss: 1.05625 val_acc: 74.37500\n",
      "[2, 5770] train_loss: 0.83188 train_acc: 77.81250 val_loss: 1.32764 val_acc: 71.25000\n",
      "[2, 5780] train_loss: 0.63551 train_acc: 81.87500 val_loss: 1.16434 val_acc: 73.12500\n",
      "[2, 5790] train_loss: 0.94898 train_acc: 76.25000 val_loss: 1.16219 val_acc: 68.75000\n",
      "[2, 5800] train_loss: 0.73055 train_acc: 80.62500 val_loss: 1.19101 val_acc: 72.50000\n",
      "[2, 5810] train_loss: 0.80942 train_acc: 79.68750 val_loss: 1.20732 val_acc: 71.87500\n",
      "[2, 5820] train_loss: 0.69019 train_acc: 79.68750 val_loss: 1.10062 val_acc: 74.37500\n",
      "[2, 5830] train_loss: 0.75944 train_acc: 80.31250 val_loss: 1.17887 val_acc: 71.25000\n",
      "[2, 5840] train_loss: 0.75410 train_acc: 81.25000 val_loss: 0.80987 val_acc: 76.87500\n",
      "[2, 5850] train_loss: 0.81765 train_acc: 77.50000 val_loss: 0.93312 val_acc: 78.12500\n",
      "[2, 5860] train_loss: 0.85418 train_acc: 78.43750 val_loss: 1.18814 val_acc: 72.50000\n",
      "[2, 5870] train_loss: 0.75973 train_acc: 81.56250 val_loss: 1.15234 val_acc: 73.12500\n",
      "[2, 5880] train_loss: 0.74044 train_acc: 80.00000 val_loss: 0.98314 val_acc: 77.50000\n",
      "[2, 5890] train_loss: 0.69220 train_acc: 80.62500 val_loss: 1.21249 val_acc: 76.87500\n",
      "[2, 5900] train_loss: 0.77562 train_acc: 81.87500 val_loss: 0.86695 val_acc: 77.50000\n",
      "[2, 5910] train_loss: 0.87878 train_acc: 76.87500 val_loss: 1.10783 val_acc: 75.62500\n",
      "[2, 5920] train_loss: 0.76855 train_acc: 82.18750 val_loss: 1.28925 val_acc: 73.75000\n",
      "[2, 5930] train_loss: 0.74604 train_acc: 82.18750 val_loss: 1.09573 val_acc: 75.62500\n",
      "[2, 5940] train_loss: 0.74249 train_acc: 79.68750 val_loss: 0.82058 val_acc: 78.75000\n",
      "[2, 5950] train_loss: 0.77212 train_acc: 79.06250 val_loss: 0.93228 val_acc: 79.37500\n",
      "[2, 5960] train_loss: 0.76942 train_acc: 81.87500 val_loss: 0.90363 val_acc: 78.12500\n",
      "[2, 5970] train_loss: 0.75532 train_acc: 80.93750 val_loss: 0.96435 val_acc: 76.25000\n",
      "[2, 5980] train_loss: 0.87395 train_acc: 77.50000 val_loss: 1.15317 val_acc: 71.87500\n",
      "[2, 5990] train_loss: 0.87394 train_acc: 78.43750 val_loss: 1.07893 val_acc: 73.12500\n",
      "[2, 6000] train_loss: 0.81444 train_acc: 80.00000 val_loss: 0.92826 val_acc: 78.75000\n",
      "[2, 6010] train_loss: 0.83741 train_acc: 77.18750 val_loss: 0.85903 val_acc: 82.50000\n",
      "[2, 6020] train_loss: 0.75852 train_acc: 81.87500 val_loss: 1.10483 val_acc: 73.75000\n",
      "[2, 6030] train_loss: 0.83339 train_acc: 76.56250 val_loss: 0.89433 val_acc: 77.50000\n",
      "[2, 6040] train_loss: 0.79055 train_acc: 79.06250 val_loss: 0.92507 val_acc: 76.25000\n",
      "[2, 6050] train_loss: 0.80311 train_acc: 79.37500 val_loss: 1.12843 val_acc: 74.37500\n",
      "[2, 6060] train_loss: 0.64140 train_acc: 82.18750 val_loss: 1.22100 val_acc: 73.12500\n",
      "[2, 6070] train_loss: 0.78463 train_acc: 79.06250 val_loss: 1.07030 val_acc: 75.00000\n",
      "[2, 6080] train_loss: 0.70494 train_acc: 80.00000 val_loss: 1.25712 val_acc: 70.00000\n",
      "[2, 6090] train_loss: 0.77432 train_acc: 80.00000 val_loss: 1.29588 val_acc: 67.50000\n",
      "[2, 6100] train_loss: 0.72081 train_acc: 80.31250 val_loss: 1.08490 val_acc: 76.87500\n",
      "[2, 6110] train_loss: 0.83625 train_acc: 76.87500 val_loss: 1.27252 val_acc: 68.75000\n",
      "[2, 6120] train_loss: 0.78444 train_acc: 78.12500 val_loss: 0.90018 val_acc: 78.75000\n",
      "[2, 6130] train_loss: 0.71780 train_acc: 79.06250 val_loss: 1.27794 val_acc: 70.00000\n",
      "[2, 6140] train_loss: 0.81652 train_acc: 77.81250 val_loss: 0.93495 val_acc: 78.12500\n",
      "[2, 6150] train_loss: 0.86498 train_acc: 77.18750 val_loss: 1.30347 val_acc: 69.37500\n",
      "[2, 6160] train_loss: 0.69384 train_acc: 81.56250 val_loss: 1.11543 val_acc: 70.62500\n",
      "[2, 6170] train_loss: 0.86235 train_acc: 76.25000 val_loss: 1.16339 val_acc: 72.50000\n",
      "[2, 6180] train_loss: 0.88521 train_acc: 77.50000 val_loss: 1.06481 val_acc: 71.87500\n",
      "[2, 6190] train_loss: 0.78775 train_acc: 80.00000 val_loss: 1.20196 val_acc: 71.87500\n",
      "[2, 6200] train_loss: 0.74628 train_acc: 80.00000 val_loss: 1.34310 val_acc: 66.87500\n",
      "[2, 6210] train_loss: 0.87616 train_acc: 76.25000 val_loss: 0.92507 val_acc: 73.12500\n",
      "[2, 6220] train_loss: 0.80648 train_acc: 80.31250 val_loss: 0.78208 val_acc: 83.12500\n",
      "[2, 6230] train_loss: 0.81084 train_acc: 77.81250 val_loss: 1.05822 val_acc: 78.12500\n",
      "[2, 6240] train_loss: 0.73461 train_acc: 79.06250 val_loss: 1.02782 val_acc: 76.87500\n",
      "[2, 6250] train_loss: 0.82080 train_acc: 79.06250 val_loss: 1.06401 val_acc: 75.00000\n",
      "[2, 6260] train_loss: 0.65177 train_acc: 83.75000 val_loss: 0.89990 val_acc: 77.50000\n",
      "[2, 6270] train_loss: 0.77367 train_acc: 80.31250 val_loss: 1.16764 val_acc: 73.12500\n",
      "[2, 6280] train_loss: 0.84259 train_acc: 79.06250 val_loss: 1.18726 val_acc: 70.00000\n",
      "[2, 6290] train_loss: 0.74452 train_acc: 81.25000 val_loss: 1.04670 val_acc: 79.37500\n",
      "[2, 6300] train_loss: 0.76792 train_acc: 79.37500 val_loss: 1.03892 val_acc: 76.87500\n",
      "[2, 6310] train_loss: 0.77660 train_acc: 80.00000 val_loss: 0.85484 val_acc: 79.37500\n",
      "[2, 6320] train_loss: 0.75327 train_acc: 81.25000 val_loss: 0.92078 val_acc: 76.87500\n",
      "[2, 6330] train_loss: 0.73237 train_acc: 80.00000 val_loss: 1.07638 val_acc: 76.25000\n",
      "[2, 6340] train_loss: 0.80123 train_acc: 78.43750 val_loss: 1.35008 val_acc: 68.75000\n",
      "[2, 6350] train_loss: 0.65419 train_acc: 80.62500 val_loss: 0.99917 val_acc: 76.87500\n",
      "[2, 6360] train_loss: 0.71933 train_acc: 79.37500 val_loss: 1.10214 val_acc: 73.12500\n",
      "[2, 6370] train_loss: 0.59011 train_acc: 83.12500 val_loss: 1.17302 val_acc: 74.37500\n",
      "[2, 6380] train_loss: 0.62506 train_acc: 83.43750 val_loss: 1.09343 val_acc: 74.37500\n",
      "[2, 6390] train_loss: 0.70040 train_acc: 78.75000 val_loss: 1.15632 val_acc: 68.75000\n",
      "[2, 6400] train_loss: 0.66829 train_acc: 82.50000 val_loss: 0.85429 val_acc: 81.25000\n",
      "[2, 6410] train_loss: 0.82191 train_acc: 78.43750 val_loss: 1.00966 val_acc: 73.75000\n",
      "[2, 6420] train_loss: 0.79385 train_acc: 79.06250 val_loss: 1.10410 val_acc: 73.12500\n",
      "[2, 6430] train_loss: 0.65883 train_acc: 83.75000 val_loss: 1.18319 val_acc: 71.87500\n",
      "[2, 6440] train_loss: 0.73352 train_acc: 81.25000 val_loss: 0.96497 val_acc: 78.12500\n",
      "[2, 6450] train_loss: 0.71483 train_acc: 80.00000 val_loss: 1.16857 val_acc: 72.50000\n",
      "[2, 6460] train_loss: 0.75342 train_acc: 80.31250 val_loss: 1.20367 val_acc: 71.87500\n",
      "[2, 6470] train_loss: 0.75216 train_acc: 80.62500 val_loss: 0.80792 val_acc: 79.37500\n",
      "[2, 6480] train_loss: 0.64178 train_acc: 84.06250 val_loss: 1.14152 val_acc: 71.25000\n",
      "[2, 6490] train_loss: 0.87865 train_acc: 76.25000 val_loss: 0.87249 val_acc: 79.37500\n",
      "[2, 6500] train_loss: 0.67341 train_acc: 79.06250 val_loss: 1.11274 val_acc: 75.62500\n",
      "[2, 6510] train_loss: 0.82702 train_acc: 79.37500 val_loss: 1.12059 val_acc: 73.75000\n",
      "[2, 6520] train_loss: 0.78848 train_acc: 80.62500 val_loss: 0.93731 val_acc: 76.25000\n",
      "[2, 6530] train_loss: 0.82880 train_acc: 77.50000 val_loss: 1.30220 val_acc: 70.62500\n",
      "[2, 6540] train_loss: 0.72083 train_acc: 81.87500 val_loss: 1.10322 val_acc: 73.12500\n",
      "[2, 6550] train_loss: 0.85670 train_acc: 74.68750 val_loss: 1.01823 val_acc: 75.00000\n",
      "[2, 6560] train_loss: 0.84262 train_acc: 79.68750 val_loss: 1.30159 val_acc: 71.25000\n",
      "[2, 6570] train_loss: 0.82022 train_acc: 78.43750 val_loss: 1.03899 val_acc: 71.87500\n",
      "[2, 6580] train_loss: 0.72603 train_acc: 81.56250 val_loss: 0.88049 val_acc: 78.75000\n",
      "[2, 6590] train_loss: 0.66304 train_acc: 81.56250 val_loss: 1.07197 val_acc: 73.75000\n",
      "[2, 6600] train_loss: 0.78873 train_acc: 80.62500 val_loss: 1.20301 val_acc: 71.25000\n",
      "[2, 6610] train_loss: 0.76797 train_acc: 80.93750 val_loss: 1.05499 val_acc: 73.75000\n",
      "[2, 6620] train_loss: 0.68922 train_acc: 82.18750 val_loss: 0.83141 val_acc: 81.25000\n",
      "[2, 6630] train_loss: 0.70896 train_acc: 80.93750 val_loss: 0.98630 val_acc: 76.25000\n",
      "[2, 6640] train_loss: 0.60161 train_acc: 82.50000 val_loss: 1.09213 val_acc: 75.00000\n",
      "[2, 6650] train_loss: 0.70599 train_acc: 80.00000 val_loss: 0.98109 val_acc: 75.62500\n",
      "[2, 6660] train_loss: 0.78826 train_acc: 79.06250 val_loss: 1.06667 val_acc: 73.12500\n",
      "[2, 6670] train_loss: 0.71770 train_acc: 81.56250 val_loss: 1.34313 val_acc: 70.62500\n",
      "[2, 6680] train_loss: 0.76228 train_acc: 81.25000 val_loss: 1.05359 val_acc: 76.25000\n",
      "[2, 6690] train_loss: 0.65910 train_acc: 82.50000 val_loss: 0.86337 val_acc: 80.62500\n",
      "[2, 6700] train_loss: 0.79513 train_acc: 78.75000 val_loss: 0.99698 val_acc: 78.12500\n",
      "[2, 6710] train_loss: 0.82610 train_acc: 76.25000 val_loss: 1.01868 val_acc: 76.25000\n",
      "[2, 6720] train_loss: 0.84413 train_acc: 79.37500 val_loss: 1.04736 val_acc: 80.00000\n",
      "[2, 6730] train_loss: 0.76645 train_acc: 79.06250 val_loss: 1.00375 val_acc: 76.87500\n",
      "[2, 6740] train_loss: 0.82001 train_acc: 75.62500 val_loss: 1.12786 val_acc: 73.12500\n",
      "[2, 6750] train_loss: 0.77512 train_acc: 83.12500 val_loss: 1.12876 val_acc: 73.12500\n",
      "[2, 6760] train_loss: 0.80596 train_acc: 78.43750 val_loss: 1.33064 val_acc: 70.00000\n",
      "[2, 6770] train_loss: 0.75356 train_acc: 79.68750 val_loss: 0.95155 val_acc: 76.25000\n",
      "[2, 6780] train_loss: 0.85465 train_acc: 78.43750 val_loss: 1.33313 val_acc: 68.12500\n",
      "[2, 6790] train_loss: 0.65421 train_acc: 80.93750 val_loss: 0.84725 val_acc: 76.87500\n",
      "[2, 6800] train_loss: 0.82455 train_acc: 77.81250 val_loss: 1.24202 val_acc: 72.50000\n",
      "[2, 6810] train_loss: 0.67265 train_acc: 80.62500 val_loss: 0.87915 val_acc: 78.12500\n",
      "[2, 6820] train_loss: 0.86606 train_acc: 75.62500 val_loss: 0.90495 val_acc: 75.62500\n",
      "[2, 6830] train_loss: 0.64887 train_acc: 81.87500 val_loss: 0.87064 val_acc: 80.00000\n",
      "[2, 6840] train_loss: 0.71130 train_acc: 82.50000 val_loss: 1.26727 val_acc: 70.62500\n",
      "[2, 6850] train_loss: 0.79053 train_acc: 78.43750 val_loss: 1.53189 val_acc: 70.00000\n",
      "[2, 6860] train_loss: 0.74310 train_acc: 79.68750 val_loss: 1.07682 val_acc: 76.87500\n",
      "[2, 6870] train_loss: 0.77577 train_acc: 79.68750 val_loss: 0.96842 val_acc: 78.75000\n",
      "[2, 6880] train_loss: 0.81563 train_acc: 78.75000 val_loss: 1.07882 val_acc: 76.25000\n",
      "[2, 6890] train_loss: 0.71132 train_acc: 80.62500 val_loss: 1.23429 val_acc: 68.75000\n",
      "[2, 6900] train_loss: 0.61666 train_acc: 82.81250 val_loss: 0.95760 val_acc: 80.00000\n",
      "[2, 6910] train_loss: 0.72555 train_acc: 80.00000 val_loss: 1.07530 val_acc: 78.12500\n",
      "[2, 6920] train_loss: 0.83432 train_acc: 77.50000 val_loss: 0.92415 val_acc: 79.37500\n",
      "[2, 6930] train_loss: 0.74791 train_acc: 79.68750 val_loss: 1.04575 val_acc: 72.50000\n",
      "[2, 6940] train_loss: 0.89581 train_acc: 75.00000 val_loss: 0.95559 val_acc: 75.62500\n",
      "[2, 6950] train_loss: 0.93821 train_acc: 75.93750 val_loss: 1.07833 val_acc: 77.50000\n",
      "[2, 6960] train_loss: 0.68844 train_acc: 80.00000 val_loss: 1.36889 val_acc: 70.00000\n",
      "[2, 6970] train_loss: 0.74578 train_acc: 78.12500 val_loss: 1.16545 val_acc: 75.62500\n",
      "[2, 6980] train_loss: 0.83546 train_acc: 78.12500 val_loss: 1.18981 val_acc: 71.87500\n",
      "[2, 6990] train_loss: 0.69592 train_acc: 82.81250 val_loss: 0.88412 val_acc: 78.12500\n",
      "[2, 7000] train_loss: 0.78859 train_acc: 77.18750 val_loss: 1.29712 val_acc: 70.00000\n",
      "[2, 7010] train_loss: 0.69262 train_acc: 82.81250 val_loss: 1.02943 val_acc: 76.87500\n",
      "[2, 7020] train_loss: 0.74346 train_acc: 81.87500 val_loss: 1.11100 val_acc: 73.12500\n",
      "[2, 7030] train_loss: 0.69189 train_acc: 81.87500 val_loss: 1.00263 val_acc: 78.75000\n",
      "[2, 7040] train_loss: 0.75452 train_acc: 79.68750 val_loss: 1.03164 val_acc: 74.37500\n",
      "[2, 7050] train_loss: 0.76433 train_acc: 80.31250 val_loss: 0.95169 val_acc: 78.12500\n",
      "[2, 7060] train_loss: 0.65966 train_acc: 80.93750 val_loss: 1.16539 val_acc: 75.00000\n",
      "[2, 7070] train_loss: 0.72914 train_acc: 80.00000 val_loss: 0.95848 val_acc: 78.12500\n",
      "[2, 7080] train_loss: 0.61568 train_acc: 83.12500 val_loss: 1.08714 val_acc: 73.75000\n",
      "[2, 7090] train_loss: 0.74504 train_acc: 80.93750 val_loss: 0.82718 val_acc: 82.50000\n",
      "[2, 7100] train_loss: 0.83973 train_acc: 76.87500 val_loss: 1.13831 val_acc: 71.87500\n",
      "[2, 7110] train_loss: 0.71423 train_acc: 81.25000 val_loss: 1.23596 val_acc: 72.50000\n",
      "[2, 7120] train_loss: 0.77592 train_acc: 78.12500 val_loss: 1.03858 val_acc: 75.62500\n",
      "[2, 7130] train_loss: 0.63638 train_acc: 85.31250 val_loss: 1.10331 val_acc: 75.00000\n",
      "[2, 7140] train_loss: 0.58073 train_acc: 84.68750 val_loss: 0.96028 val_acc: 81.87500\n",
      "[2, 7150] train_loss: 0.72075 train_acc: 80.93750 val_loss: 1.09510 val_acc: 76.87500\n",
      "[2, 7160] train_loss: 0.67791 train_acc: 80.31250 val_loss: 1.07833 val_acc: 77.50000\n",
      "[2, 7170] train_loss: 0.95746 train_acc: 77.18750 val_loss: 1.26030 val_acc: 70.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7180] train_loss: 0.65152 train_acc: 81.87500 val_loss: 1.03383 val_acc: 81.25000\n",
      "[2, 7190] train_loss: 0.81078 train_acc: 80.31250 val_loss: 0.80455 val_acc: 79.37500\n",
      "[2, 7200] train_loss: 0.70943 train_acc: 83.12500 val_loss: 0.78305 val_acc: 80.62500\n",
      "[2, 7210] train_loss: 0.90485 train_acc: 77.18750 val_loss: 1.02532 val_acc: 76.87500\n",
      "[2, 7220] train_loss: 0.72137 train_acc: 82.18750 val_loss: 1.10570 val_acc: 74.37500\n",
      "[2, 7230] train_loss: 0.64639 train_acc: 80.93750 val_loss: 1.09889 val_acc: 76.25000\n",
      "[2, 7240] train_loss: 0.78865 train_acc: 78.12500 val_loss: 0.93142 val_acc: 77.50000\n",
      "[2, 7250] train_loss: 0.73602 train_acc: 80.62500 val_loss: 1.19491 val_acc: 72.50000\n",
      "[2, 7260] train_loss: 0.72102 train_acc: 79.06250 val_loss: 1.05485 val_acc: 75.62500\n",
      "[2, 7270] train_loss: 0.84562 train_acc: 77.50000 val_loss: 0.71759 val_acc: 81.25000\n",
      "[2, 7280] train_loss: 0.77362 train_acc: 80.62500 val_loss: 0.65472 val_acc: 83.75000\n",
      "[2, 7290] train_loss: 0.75508 train_acc: 79.68750 val_loss: 0.99754 val_acc: 78.12500\n",
      "[2, 7300] train_loss: 0.81106 train_acc: 79.68750 val_loss: 1.07190 val_acc: 76.25000\n",
      "[2, 7310] train_loss: 0.79415 train_acc: 80.93750 val_loss: 0.99002 val_acc: 77.50000\n",
      "[2, 7320] train_loss: 0.79887 train_acc: 77.81250 val_loss: 1.02784 val_acc: 76.25000\n",
      "[2, 7330] train_loss: 0.65869 train_acc: 82.18750 val_loss: 1.01939 val_acc: 78.75000\n",
      "[2, 7340] train_loss: 0.67197 train_acc: 81.87500 val_loss: 1.00842 val_acc: 74.37500\n",
      "[2, 7350] train_loss: 0.67491 train_acc: 81.87500 val_loss: 0.76165 val_acc: 79.37500\n",
      "[2, 7360] train_loss: 0.75998 train_acc: 81.25000 val_loss: 1.01644 val_acc: 74.37500\n",
      "[2, 7370] train_loss: 0.73491 train_acc: 80.00000 val_loss: 0.93977 val_acc: 75.62500\n",
      "[2, 7380] train_loss: 0.74799 train_acc: 79.37500 val_loss: 0.98099 val_acc: 76.87500\n",
      "[2, 7390] train_loss: 0.70821 train_acc: 82.18750 val_loss: 1.12937 val_acc: 75.62500\n",
      "[2, 7400] train_loss: 0.72233 train_acc: 81.25000 val_loss: 0.99386 val_acc: 76.25000\n",
      "[2, 7410] train_loss: 0.68197 train_acc: 81.25000 val_loss: 1.22810 val_acc: 76.25000\n",
      "[2, 7420] train_loss: 0.74014 train_acc: 81.25000 val_loss: 0.95998 val_acc: 75.62500\n",
      "[2, 7430] train_loss: 0.68656 train_acc: 81.56250 val_loss: 0.96931 val_acc: 79.37500\n",
      "[2, 7440] train_loss: 0.67920 train_acc: 79.68750 val_loss: 1.08051 val_acc: 75.62500\n",
      "[2, 7450] train_loss: 0.76229 train_acc: 78.43750 val_loss: 0.95276 val_acc: 76.25000\n",
      "[2, 7460] train_loss: 0.92820 train_acc: 74.37500 val_loss: 1.05543 val_acc: 75.00000\n",
      "[2, 7470] train_loss: 0.82301 train_acc: 79.37500 val_loss: 0.99420 val_acc: 74.37500\n",
      "[2, 7480] train_loss: 0.83182 train_acc: 78.43750 val_loss: 1.29782 val_acc: 73.75000\n",
      "[2, 7490] train_loss: 0.68407 train_acc: 81.87500 val_loss: 0.90071 val_acc: 79.37500\n",
      "[2, 7500] train_loss: 0.72717 train_acc: 81.25000 val_loss: 1.19495 val_acc: 71.25000\n",
      "[2, 7510] train_loss: 0.61368 train_acc: 84.68750 val_loss: 1.19577 val_acc: 72.50000\n",
      "[2, 7520] train_loss: 0.62928 train_acc: 82.81250 val_loss: 1.21297 val_acc: 73.12500\n",
      "[2, 7530] train_loss: 0.72011 train_acc: 79.68750 val_loss: 1.13753 val_acc: 75.62500\n",
      "[2, 7540] train_loss: 0.67356 train_acc: 80.93750 val_loss: 1.00240 val_acc: 76.25000\n",
      "[2, 7550] train_loss: 0.69414 train_acc: 82.50000 val_loss: 1.01240 val_acc: 80.00000\n",
      "[2, 7560] train_loss: 0.81329 train_acc: 78.12500 val_loss: 1.03639 val_acc: 78.75000\n",
      "[2, 7570] train_loss: 0.67451 train_acc: 81.56250 val_loss: 1.39468 val_acc: 69.37500\n",
      "[2, 7580] train_loss: 0.76286 train_acc: 81.56250 val_loss: 1.01565 val_acc: 72.50000\n",
      "[2, 7590] train_loss: 0.71569 train_acc: 82.18750 val_loss: 1.11315 val_acc: 78.12500\n",
      "[2, 7600] train_loss: 0.62089 train_acc: 83.12500 val_loss: 1.08128 val_acc: 75.00000\n",
      "[2, 7610] train_loss: 0.62257 train_acc: 83.12500 val_loss: 1.26174 val_acc: 77.50000\n",
      "[2, 7620] train_loss: 0.71179 train_acc: 80.00000 val_loss: 1.23113 val_acc: 68.12500\n",
      "[2, 7630] train_loss: 0.78858 train_acc: 78.12500 val_loss: 1.02225 val_acc: 72.50000\n",
      "[2, 7640] train_loss: 0.75014 train_acc: 80.62500 val_loss: 0.91465 val_acc: 77.50000\n",
      "[2, 7650] train_loss: 0.84955 train_acc: 80.31250 val_loss: 1.06711 val_acc: 75.00000\n",
      "[2, 7660] train_loss: 0.67573 train_acc: 83.12500 val_loss: 1.04089 val_acc: 78.12500\n",
      "[2, 7670] train_loss: 0.54813 train_acc: 84.68750 val_loss: 0.75626 val_acc: 80.00000\n",
      "[2, 7680] train_loss: 0.71757 train_acc: 80.00000 val_loss: 0.90863 val_acc: 74.37500\n",
      "[2, 7690] train_loss: 0.60255 train_acc: 84.37500 val_loss: 1.17166 val_acc: 72.50000\n",
      "[2, 7700] train_loss: 0.60526 train_acc: 83.12500 val_loss: 1.37134 val_acc: 66.87500\n",
      "[2, 7710] train_loss: 0.71265 train_acc: 79.37500 val_loss: 1.14855 val_acc: 75.62500\n",
      "[2, 7720] train_loss: 0.71034 train_acc: 83.75000 val_loss: 1.02939 val_acc: 78.12500\n",
      "[2, 7730] train_loss: 0.76861 train_acc: 81.87500 val_loss: 0.89738 val_acc: 76.87500\n",
      "[2, 7740] train_loss: 0.72009 train_acc: 82.18750 val_loss: 1.17529 val_acc: 72.50000\n",
      "[2, 7750] train_loss: 0.70684 train_acc: 79.68750 val_loss: 0.92842 val_acc: 79.37500\n",
      "[2, 7760] train_loss: 0.76684 train_acc: 80.31250 val_loss: 1.04578 val_acc: 78.12500\n",
      "[2, 7770] train_loss: 0.79555 train_acc: 77.81250 val_loss: 1.10717 val_acc: 74.37500\n",
      "[2, 7780] train_loss: 0.80487 train_acc: 79.68750 val_loss: 1.11971 val_acc: 71.87500\n",
      "[2, 7790] train_loss: 0.70054 train_acc: 80.31250 val_loss: 0.96343 val_acc: 79.37500\n",
      "[2, 7800] train_loss: 0.70464 train_acc: 82.50000 val_loss: 1.16361 val_acc: 75.62500\n",
      "[2, 7810] train_loss: 0.83323 train_acc: 72.81250 val_loss: 1.12692 val_acc: 75.62500\n",
      "[2, 7820] train_loss: 0.80471 train_acc: 80.93750 val_loss: 0.87423 val_acc: 83.75000\n",
      "[2, 7830] train_loss: 0.73192 train_acc: 80.31250 val_loss: 0.96044 val_acc: 81.25000\n",
      "[2, 7840] train_loss: 0.63282 train_acc: 83.75000 val_loss: 1.00642 val_acc: 74.37500\n",
      "[2, 7850] train_loss: 0.71475 train_acc: 78.75000 val_loss: 1.06375 val_acc: 71.87500\n",
      "[2, 7860] train_loss: 0.71331 train_acc: 80.62500 val_loss: 1.03207 val_acc: 80.62500\n",
      "[2, 7870] train_loss: 0.73293 train_acc: 80.62500 val_loss: 1.05852 val_acc: 74.37500\n",
      "[2, 7880] train_loss: 0.64942 train_acc: 81.56250 val_loss: 1.22184 val_acc: 74.37500\n",
      "[2, 7890] train_loss: 0.88731 train_acc: 77.18750 val_loss: 1.14258 val_acc: 76.25000\n",
      "[2, 7900] train_loss: 0.80452 train_acc: 80.00000 val_loss: 0.79908 val_acc: 81.87500\n",
      "[2, 7910] train_loss: 0.69660 train_acc: 80.31250 val_loss: 1.04223 val_acc: 78.75000\n",
      "[2, 7920] train_loss: 0.75977 train_acc: 79.37500 val_loss: 1.00954 val_acc: 75.62500\n",
      "[2, 7930] train_loss: 0.72360 train_acc: 82.50000 val_loss: 0.79457 val_acc: 82.50000\n",
      "[2, 7940] train_loss: 0.92373 train_acc: 75.93750 val_loss: 1.02544 val_acc: 76.87500\n",
      "[2, 7950] train_loss: 0.82071 train_acc: 79.37500 val_loss: 0.86421 val_acc: 78.75000\n",
      "[2, 7960] train_loss: 0.70177 train_acc: 79.68750 val_loss: 0.71681 val_acc: 83.12500\n",
      "[2, 7970] train_loss: 0.79117 train_acc: 79.06250 val_loss: 0.99999 val_acc: 75.62500\n",
      "[2, 7980] train_loss: 0.68520 train_acc: 79.37500 val_loss: 1.32686 val_acc: 70.62500\n",
      "[2, 7990] train_loss: 0.74118 train_acc: 82.18750 val_loss: 1.18011 val_acc: 73.12500\n",
      "[2, 8000] train_loss: 0.83083 train_acc: 78.12500 val_loss: 1.14996 val_acc: 80.00000\n",
      "[2, 8010] train_loss: 0.84754 train_acc: 78.75000 val_loss: 0.96622 val_acc: 76.87500\n",
      "[2, 8020] train_loss: 0.59341 train_acc: 86.87500 val_loss: 1.07590 val_acc: 76.87500\n",
      "[2, 8030] train_loss: 0.73679 train_acc: 80.31250 val_loss: 1.09033 val_acc: 75.00000\n",
      "[2, 8040] train_loss: 0.76839 train_acc: 81.56250 val_loss: 1.02363 val_acc: 73.12500\n",
      "[2, 8050] train_loss: 0.71528 train_acc: 83.12500 val_loss: 0.90714 val_acc: 75.62500\n",
      "[2, 8060] train_loss: 0.60233 train_acc: 85.93750 val_loss: 0.86127 val_acc: 80.00000\n",
      "[2, 8070] train_loss: 0.81212 train_acc: 79.68750 val_loss: 0.86919 val_acc: 80.00000\n",
      "[2, 8080] train_loss: 0.57827 train_acc: 83.12500 val_loss: 1.01223 val_acc: 78.12500\n",
      "[2, 8090] train_loss: 0.72392 train_acc: 81.87500 val_loss: 0.88782 val_acc: 77.50000\n",
      "[2, 8100] train_loss: 0.60634 train_acc: 84.06250 val_loss: 0.94136 val_acc: 78.75000\n",
      "[2, 8110] train_loss: 0.70808 train_acc: 81.87500 val_loss: 1.02898 val_acc: 78.75000\n",
      "[2, 8120] train_loss: 0.77978 train_acc: 79.06250 val_loss: 1.03792 val_acc: 78.75000\n",
      "[2, 8130] train_loss: 0.64790 train_acc: 83.12500 val_loss: 0.93274 val_acc: 78.75000\n",
      "[2, 8140] train_loss: 0.81509 train_acc: 78.75000 val_loss: 0.95336 val_acc: 78.75000\n",
      "[2, 8150] train_loss: 0.68072 train_acc: 82.50000 val_loss: 0.96433 val_acc: 79.37500\n",
      "[2, 8160] train_loss: 0.65112 train_acc: 81.56250 val_loss: 1.04609 val_acc: 76.25000\n",
      "[2, 8170] train_loss: 0.67000 train_acc: 82.50000 val_loss: 1.13617 val_acc: 75.62500\n",
      "[2, 8180] train_loss: 0.71273 train_acc: 81.56250 val_loss: 1.04246 val_acc: 76.25000\n",
      "[2, 8190] train_loss: 0.64998 train_acc: 83.12500 val_loss: 0.84899 val_acc: 77.50000\n",
      "[2, 8200] train_loss: 0.75549 train_acc: 79.68750 val_loss: 0.84993 val_acc: 81.25000\n",
      "[2, 8210] train_loss: 0.61078 train_acc: 81.87500 val_loss: 1.10656 val_acc: 74.37500\n",
      "[2, 8220] train_loss: 0.71269 train_acc: 80.00000 val_loss: 1.02818 val_acc: 74.37500\n",
      "[2, 8230] train_loss: 0.68902 train_acc: 81.87500 val_loss: 1.35065 val_acc: 70.00000\n",
      "[2, 8240] train_loss: 0.63444 train_acc: 82.81250 val_loss: 1.33224 val_acc: 73.12500\n",
      "[2, 8250] train_loss: 0.75252 train_acc: 78.75000 val_loss: 1.02119 val_acc: 75.00000\n",
      "[2, 8260] train_loss: 0.84031 train_acc: 77.50000 val_loss: 1.15328 val_acc: 73.75000\n",
      "[2, 8270] train_loss: 0.76925 train_acc: 78.12500 val_loss: 1.11193 val_acc: 75.00000\n",
      "[2, 8280] train_loss: 0.74904 train_acc: 78.12500 val_loss: 1.25297 val_acc: 73.12500\n",
      "[2, 8290] train_loss: 0.65789 train_acc: 81.56250 val_loss: 1.12523 val_acc: 73.12500\n",
      "[2, 8300] train_loss: 0.67972 train_acc: 82.18750 val_loss: 1.14711 val_acc: 71.87500\n",
      "[2, 8310] train_loss: 0.89087 train_acc: 77.50000 val_loss: 0.85437 val_acc: 79.37500\n",
      "[2, 8320] train_loss: 0.70234 train_acc: 79.68750 val_loss: 1.01191 val_acc: 75.62500\n",
      "[2, 8330] train_loss: 0.74097 train_acc: 78.75000 val_loss: 1.10710 val_acc: 76.25000\n",
      "[2, 8340] train_loss: 0.73832 train_acc: 82.18750 val_loss: 1.03805 val_acc: 77.50000\n",
      "[2, 8350] train_loss: 0.63604 train_acc: 79.37500 val_loss: 1.06206 val_acc: 75.00000\n",
      "[2, 8360] train_loss: 0.79980 train_acc: 78.75000 val_loss: 0.94022 val_acc: 78.75000\n",
      "[2, 8370] train_loss: 0.66002 train_acc: 83.75000 val_loss: 0.95793 val_acc: 77.50000\n",
      "[2, 8380] train_loss: 0.71534 train_acc: 81.87500 val_loss: 1.23831 val_acc: 73.75000\n",
      "[2, 8390] train_loss: 0.64772 train_acc: 80.93750 val_loss: 1.11149 val_acc: 73.12500\n",
      "[2, 8400] train_loss: 0.78448 train_acc: 79.37500 val_loss: 1.11679 val_acc: 80.00000\n",
      "[2, 8410] train_loss: 0.65459 train_acc: 83.43750 val_loss: 0.74538 val_acc: 81.87500\n",
      "[2, 8420] train_loss: 0.75454 train_acc: 80.62500 val_loss: 1.04006 val_acc: 73.12500\n",
      "[2, 8430] train_loss: 0.71418 train_acc: 80.93750 val_loss: 1.24038 val_acc: 71.87500\n",
      "[2, 8440] train_loss: 0.79464 train_acc: 78.43750 val_loss: 1.04566 val_acc: 75.62500\n",
      "[2, 8450] train_loss: 0.63341 train_acc: 81.56250 val_loss: 1.32069 val_acc: 69.37500\n",
      "[2, 8460] train_loss: 0.62165 train_acc: 82.18750 val_loss: 1.09264 val_acc: 75.00000\n",
      "[2, 8470] train_loss: 0.64190 train_acc: 82.81250 val_loss: 0.94191 val_acc: 80.62500\n",
      "[2, 8480] train_loss: 0.73275 train_acc: 81.87500 val_loss: 0.98073 val_acc: 77.50000\n",
      "[2, 8490] train_loss: 0.69240 train_acc: 82.18750 val_loss: 0.86717 val_acc: 78.12500\n",
      "[2, 8500] train_loss: 0.75772 train_acc: 78.75000 val_loss: 1.09037 val_acc: 75.62500\n",
      "[2, 8510] train_loss: 0.84842 train_acc: 76.56250 val_loss: 1.12272 val_acc: 73.12500\n",
      "[2, 8520] train_loss: 0.60682 train_acc: 82.81250 val_loss: 1.08272 val_acc: 76.25000\n",
      "[2, 8530] train_loss: 0.68804 train_acc: 82.81250 val_loss: 1.18314 val_acc: 72.50000\n",
      "[2, 8540] train_loss: 0.76585 train_acc: 77.81250 val_loss: 1.27052 val_acc: 75.62500\n",
      "[2, 8550] train_loss: 0.63887 train_acc: 85.00000 val_loss: 1.01431 val_acc: 74.37500\n",
      "[2, 8560] train_loss: 0.63809 train_acc: 82.81250 val_loss: 1.04198 val_acc: 78.12500\n",
      "[2, 8570] train_loss: 0.79869 train_acc: 77.50000 val_loss: 1.10022 val_acc: 75.00000\n",
      "[2, 8580] train_loss: 0.61802 train_acc: 83.12500 val_loss: 1.12982 val_acc: 78.12500\n",
      "[2, 8590] train_loss: 0.71631 train_acc: 80.00000 val_loss: 0.76601 val_acc: 81.87500\n",
      "[2, 8600] train_loss: 0.69779 train_acc: 80.00000 val_loss: 0.82038 val_acc: 79.37500\n",
      "[2, 8610] train_loss: 0.64732 train_acc: 84.68750 val_loss: 0.66930 val_acc: 81.87500\n",
      "[2, 8620] train_loss: 0.77301 train_acc: 77.81250 val_loss: 1.06094 val_acc: 76.25000\n",
      "[2, 8630] train_loss: 0.68132 train_acc: 80.31250 val_loss: 0.93035 val_acc: 80.00000\n",
      "[2, 8640] train_loss: 0.65054 train_acc: 80.62500 val_loss: 0.82352 val_acc: 77.50000\n",
      "[2, 8650] train_loss: 0.74297 train_acc: 80.62500 val_loss: 1.31687 val_acc: 72.50000\n",
      "[2, 8660] train_loss: 0.68077 train_acc: 81.87500 val_loss: 1.02205 val_acc: 76.25000\n",
      "[2, 8670] train_loss: 0.72608 train_acc: 80.62500 val_loss: 0.73281 val_acc: 81.25000\n",
      "[2, 8680] train_loss: 0.63637 train_acc: 81.87500 val_loss: 1.12474 val_acc: 74.37500\n",
      "[2, 8690] train_loss: 0.82897 train_acc: 77.81250 val_loss: 1.09793 val_acc: 73.12500\n",
      "[2, 8700] train_loss: 0.72952 train_acc: 78.12500 val_loss: 0.90948 val_acc: 77.50000\n",
      "[2, 8710] train_loss: 0.81433 train_acc: 79.06250 val_loss: 0.74234 val_acc: 84.37500\n",
      "[2, 8720] train_loss: 0.70143 train_acc: 80.31250 val_loss: 0.91097 val_acc: 76.25000\n",
      "[2, 8730] train_loss: 0.70965 train_acc: 82.18750 val_loss: 1.17681 val_acc: 73.75000\n",
      "[2, 8740] train_loss: 0.71992 train_acc: 80.93750 val_loss: 1.20174 val_acc: 75.00000\n",
      "[2, 8750] train_loss: 0.72176 train_acc: 81.87500 val_loss: 1.00751 val_acc: 73.75000\n",
      "[2, 8760] train_loss: 0.49972 train_acc: 89.37500 val_loss: 1.09122 val_acc: 76.87500\n",
      "[2, 8770] train_loss: 0.68047 train_acc: 81.87500 val_loss: 0.86005 val_acc: 81.87500\n",
      "[2, 8780] train_loss: 0.73797 train_acc: 80.93750 val_loss: 1.33393 val_acc: 72.50000\n",
      "[2, 8790] train_loss: 0.66951 train_acc: 80.93750 val_loss: 1.24791 val_acc: 71.87500\n",
      "[2, 8800] train_loss: 0.66634 train_acc: 83.43750 val_loss: 0.96357 val_acc: 76.87500\n",
      "[2, 8810] train_loss: 0.74877 train_acc: 80.31250 val_loss: 1.02435 val_acc: 80.62500\n",
      "[2, 8820] train_loss: 0.63943 train_acc: 83.75000 val_loss: 1.08825 val_acc: 76.87500\n",
      "[2, 8830] train_loss: 0.67898 train_acc: 80.93750 val_loss: 0.78968 val_acc: 81.25000\n",
      "[2, 8840] train_loss: 0.65601 train_acc: 80.31250 val_loss: 1.25507 val_acc: 74.37500\n",
      "[2, 8850] train_loss: 0.61566 train_acc: 81.87500 val_loss: 0.68644 val_acc: 81.25000\n",
      "[2, 8860] train_loss: 0.65509 train_acc: 81.25000 val_loss: 1.08233 val_acc: 73.75000\n",
      "[2, 8870] train_loss: 0.70239 train_acc: 80.62500 val_loss: 1.01467 val_acc: 78.12500\n",
      "[2, 8880] train_loss: 0.70317 train_acc: 81.25000 val_loss: 0.79101 val_acc: 80.00000\n",
      "[2, 8890] train_loss: 0.70008 train_acc: 81.56250 val_loss: 1.05369 val_acc: 75.00000\n",
      "[2, 8900] train_loss: 0.64332 train_acc: 82.18750 val_loss: 1.10021 val_acc: 75.62500\n",
      "[2, 8910] train_loss: 0.76526 train_acc: 79.68750 val_loss: 1.04107 val_acc: 77.50000\n",
      "[2, 8920] train_loss: 0.77804 train_acc: 81.56250 val_loss: 0.91236 val_acc: 76.25000\n",
      "[2, 8930] train_loss: 0.72454 train_acc: 81.56250 val_loss: 0.99083 val_acc: 76.25000\n",
      "[2, 8940] train_loss: 0.66561 train_acc: 83.12500 val_loss: 0.95448 val_acc: 76.87500\n",
      "[2, 8950] train_loss: 0.80857 train_acc: 80.62500 val_loss: 1.01116 val_acc: 75.62500\n",
      "[2, 8960] train_loss: 0.55632 train_acc: 83.12500 val_loss: 1.05668 val_acc: 76.87500\n",
      "[2, 8970] train_loss: 0.77225 train_acc: 79.06250 val_loss: 1.29595 val_acc: 76.25000\n",
      "[2, 8980] train_loss: 0.77076 train_acc: 78.75000 val_loss: 1.03626 val_acc: 76.87500\n",
      "[2, 8990] train_loss: 0.64490 train_acc: 84.68750 val_loss: 1.00043 val_acc: 75.62500\n",
      "[2, 9000] train_loss: 0.70930 train_acc: 79.37500 val_loss: 1.12162 val_acc: 73.12500\n",
      "[2, 9010] train_loss: 0.67840 train_acc: 80.62500 val_loss: 0.91389 val_acc: 78.75000\n",
      "[2, 9020] train_loss: 0.78987 train_acc: 79.06250 val_loss: 1.06249 val_acc: 75.62500\n",
      "[2, 9030] train_loss: 0.71378 train_acc: 82.18750 val_loss: 1.07815 val_acc: 76.87500\n",
      "[2, 9040] train_loss: 0.74127 train_acc: 80.62500 val_loss: 1.15341 val_acc: 74.37500\n",
      "[2, 9050] train_loss: 0.64088 train_acc: 82.81250 val_loss: 0.96637 val_acc: 75.62500\n",
      "[2, 9060] train_loss: 0.68250 train_acc: 78.75000 val_loss: 0.78610 val_acc: 81.25000\n",
      "[2, 9070] train_loss: 0.70649 train_acc: 80.62500 val_loss: 1.21089 val_acc: 71.87500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 9080] train_loss: 0.65557 train_acc: 81.87500 val_loss: 1.05339 val_acc: 74.37500\n",
      "[2, 9090] train_loss: 0.61470 train_acc: 85.00000 val_loss: 1.07696 val_acc: 75.62500\n",
      "[2, 9100] train_loss: 0.66718 train_acc: 82.50000 val_loss: 0.92007 val_acc: 78.12500\n",
      "[2, 9110] train_loss: 0.75643 train_acc: 80.00000 val_loss: 1.22987 val_acc: 69.37500\n",
      "[2, 9120] train_loss: 0.64419 train_acc: 82.18750 val_loss: 1.16264 val_acc: 74.37500\n",
      "[2, 9130] train_loss: 0.64522 train_acc: 84.06250 val_loss: 0.94930 val_acc: 75.62500\n",
      "[2, 9140] train_loss: 0.58765 train_acc: 85.93750 val_loss: 0.80536 val_acc: 81.87500\n",
      "[2, 9150] train_loss: 0.57107 train_acc: 84.68750 val_loss: 0.93332 val_acc: 77.50000\n",
      "[2, 9160] train_loss: 0.68717 train_acc: 83.12500 val_loss: 0.90706 val_acc: 80.00000\n",
      "[2, 9170] train_loss: 0.68915 train_acc: 81.56250 val_loss: 1.06337 val_acc: 75.00000\n",
      "[2, 9180] train_loss: 0.65484 train_acc: 81.25000 val_loss: 0.82702 val_acc: 83.12500\n",
      "[2, 9190] train_loss: 0.61156 train_acc: 84.37500 val_loss: 1.33413 val_acc: 71.87500\n",
      "[2, 9200] train_loss: 0.72294 train_acc: 78.75000 val_loss: 1.02717 val_acc: 74.37500\n",
      "[2, 9210] train_loss: 0.55215 train_acc: 84.37500 val_loss: 0.91418 val_acc: 81.87500\n",
      "[2, 9220] train_loss: 0.62003 train_acc: 85.31250 val_loss: 0.92551 val_acc: 78.12500\n",
      "[2, 9230] train_loss: 0.62516 train_acc: 81.56250 val_loss: 0.98922 val_acc: 76.87500\n",
      "[2, 9240] train_loss: 0.60227 train_acc: 82.81250 val_loss: 0.81414 val_acc: 78.75000\n",
      "[2, 9250] train_loss: 0.81031 train_acc: 78.43750 val_loss: 0.99655 val_acc: 76.25000\n",
      "[2, 9260] train_loss: 0.63677 train_acc: 83.12500 val_loss: 0.98472 val_acc: 76.87500\n",
      "[2, 9270] train_loss: 0.56666 train_acc: 84.68750 val_loss: 1.00187 val_acc: 81.25000\n",
      "[2, 9280] train_loss: 0.68329 train_acc: 83.75000 val_loss: 1.07975 val_acc: 74.37500\n",
      "[2, 9290] train_loss: 0.67704 train_acc: 81.56250 val_loss: 1.04507 val_acc: 75.00000\n",
      "[2, 9300] train_loss: 0.70114 train_acc: 81.25000 val_loss: 0.88402 val_acc: 80.00000\n",
      "[2, 9310] train_loss: 0.73365 train_acc: 79.37500 val_loss: 0.99287 val_acc: 80.62500\n",
      "[2, 9320] train_loss: 0.62552 train_acc: 85.93750 val_loss: 0.92857 val_acc: 74.37500\n",
      "[2, 9330] train_loss: 0.66610 train_acc: 81.56250 val_loss: 1.00925 val_acc: 76.25000\n",
      "[2, 9340] train_loss: 0.80050 train_acc: 80.62500 val_loss: 0.69856 val_acc: 83.12500\n",
      "[2, 9350] train_loss: 0.72264 train_acc: 82.50000 val_loss: 1.09561 val_acc: 80.00000\n",
      "[2, 9360] train_loss: 0.69877 train_acc: 82.50000 val_loss: 0.80094 val_acc: 80.62500\n",
      "[2, 9370] train_loss: 0.66261 train_acc: 82.50000 val_loss: 0.87884 val_acc: 77.50000\n",
      "[2, 9380] train_loss: 0.62559 train_acc: 85.31250 val_loss: 1.05950 val_acc: 77.50000\n",
      "[2, 9390] train_loss: 0.75029 train_acc: 79.37500 val_loss: 0.86419 val_acc: 78.75000\n",
      "[2, 9400] train_loss: 0.58393 train_acc: 84.68750 val_loss: 1.09989 val_acc: 75.00000\n",
      "[2, 9410] train_loss: 0.56186 train_acc: 84.68750 val_loss: 1.03912 val_acc: 71.87500\n",
      "[2, 9420] train_loss: 0.74303 train_acc: 78.75000 val_loss: 0.81221 val_acc: 80.62500\n",
      "[2, 9430] train_loss: 0.55524 train_acc: 85.62500 val_loss: 0.87809 val_acc: 78.75000\n",
      "[2, 9440] train_loss: 0.59672 train_acc: 86.56250 val_loss: 0.87882 val_acc: 79.37500\n",
      "[2, 9450] train_loss: 0.77560 train_acc: 79.06250 val_loss: 1.13389 val_acc: 75.62500\n",
      "[2, 9460] train_loss: 0.72439 train_acc: 78.43750 val_loss: 1.12452 val_acc: 73.12500\n",
      "[2, 9470] train_loss: 0.64043 train_acc: 83.75000 val_loss: 1.17746 val_acc: 76.87500\n",
      "[2, 9480] train_loss: 0.71195 train_acc: 80.62500 val_loss: 0.91296 val_acc: 78.75000\n",
      "[2, 9490] train_loss: 0.62783 train_acc: 82.18750 val_loss: 1.24496 val_acc: 71.87500\n",
      "[2, 9500] train_loss: 0.80220 train_acc: 78.75000 val_loss: 1.17383 val_acc: 73.75000\n",
      "[2, 9510] train_loss: 0.76571 train_acc: 82.18750 val_loss: 1.04814 val_acc: 72.50000\n",
      "[2, 9520] train_loss: 0.59397 train_acc: 83.43750 val_loss: 0.67046 val_acc: 82.50000\n",
      "[2, 9530] train_loss: 0.63274 train_acc: 84.06250 val_loss: 0.93932 val_acc: 78.12500\n",
      "[2, 9540] train_loss: 0.55401 train_acc: 86.25000 val_loss: 1.14186 val_acc: 78.75000\n",
      "[2, 9550] train_loss: 0.62438 train_acc: 83.43750 val_loss: 0.81574 val_acc: 81.87500\n",
      "[2, 9560] train_loss: 0.76283 train_acc: 81.25000 val_loss: 1.16866 val_acc: 74.37500\n",
      "[2, 9570] train_loss: 0.71362 train_acc: 81.56250 val_loss: 0.98771 val_acc: 77.50000\n",
      "[2, 9580] train_loss: 0.58665 train_acc: 83.12500 val_loss: 1.00818 val_acc: 78.12500\n",
      "[2, 9590] train_loss: 0.62495 train_acc: 84.06250 val_loss: 1.19008 val_acc: 71.25000\n",
      "[2, 9600] train_loss: 0.67640 train_acc: 78.75000 val_loss: 1.09137 val_acc: 75.62500\n",
      "[2, 9610] train_loss: 0.62777 train_acc: 83.43750 val_loss: 0.97809 val_acc: 78.75000\n",
      "[2, 9620] train_loss: 0.76286 train_acc: 80.00000 val_loss: 1.15060 val_acc: 74.37500\n",
      "[2, 9630] train_loss: 0.62011 train_acc: 82.81250 val_loss: 1.21832 val_acc: 69.37500\n",
      "[2, 9640] train_loss: 0.79377 train_acc: 80.62500 val_loss: 0.82959 val_acc: 76.87500\n",
      "[2, 9650] train_loss: 0.60819 train_acc: 84.68750 val_loss: 1.03484 val_acc: 75.00000\n",
      "[2, 9660] train_loss: 0.69611 train_acc: 82.50000 val_loss: 0.89672 val_acc: 80.62500\n",
      "[2, 9670] train_loss: 0.65183 train_acc: 84.06250 val_loss: 1.18368 val_acc: 74.37500\n",
      "[2, 9680] train_loss: 0.66957 train_acc: 82.18750 val_loss: 1.35648 val_acc: 70.62500\n",
      "[2, 9690] train_loss: 0.69958 train_acc: 80.62500 val_loss: 0.91230 val_acc: 78.75000\n",
      "[2, 9700] train_loss: 0.70863 train_acc: 80.93750 val_loss: 0.86049 val_acc: 80.00000\n",
      "[2, 9710] train_loss: 0.68220 train_acc: 83.75000 val_loss: 1.01662 val_acc: 75.62500\n",
      "[2, 9720] train_loss: 0.65915 train_acc: 82.81250 val_loss: 1.00752 val_acc: 78.75000\n",
      "[2, 9730] train_loss: 0.76839 train_acc: 79.37500 val_loss: 0.82558 val_acc: 81.25000\n",
      "[2, 9740] train_loss: 0.54266 train_acc: 85.93750 val_loss: 1.05681 val_acc: 77.50000\n",
      "[2, 9750] train_loss: 0.68714 train_acc: 83.12500 val_loss: 0.79889 val_acc: 82.50000\n",
      "[2, 9760] train_loss: 0.76194 train_acc: 78.43750 val_loss: 1.18813 val_acc: 72.50000\n",
      "[2, 9770] train_loss: 0.61265 train_acc: 84.06250 val_loss: 0.99692 val_acc: 77.50000\n",
      "[2, 9780] train_loss: 0.84429 train_acc: 77.18750 val_loss: 0.94745 val_acc: 76.25000\n",
      "[2, 9790] train_loss: 0.79625 train_acc: 79.37500 val_loss: 0.75156 val_acc: 84.37500\n",
      "[2, 9800] train_loss: 0.71832 train_acc: 81.25000 val_loss: 1.00090 val_acc: 76.25000\n",
      "[2, 9810] train_loss: 0.70039 train_acc: 82.18750 val_loss: 1.05118 val_acc: 75.00000\n",
      "[2, 9820] train_loss: 0.63137 train_acc: 82.81250 val_loss: 1.11311 val_acc: 76.87500\n",
      "[2, 9830] train_loss: 0.58802 train_acc: 82.50000 val_loss: 1.10241 val_acc: 74.37500\n",
      "[2, 9840] train_loss: 0.69690 train_acc: 81.87500 val_loss: 1.10908 val_acc: 77.50000\n",
      "[2, 9850] train_loss: 0.68404 train_acc: 79.37500 val_loss: 0.66442 val_acc: 83.75000\n",
      "[2, 9860] train_loss: 0.55786 train_acc: 85.00000 val_loss: 0.92606 val_acc: 78.12500\n",
      "[2, 9870] train_loss: 0.73417 train_acc: 78.75000 val_loss: 0.89154 val_acc: 78.75000\n",
      "[2, 9880] train_loss: 0.78435 train_acc: 79.06250 val_loss: 1.12806 val_acc: 76.87500\n",
      "[2, 9890] train_loss: 0.70425 train_acc: 80.31250 val_loss: 0.99332 val_acc: 78.12500\n",
      "[2, 9900] train_loss: 0.65874 train_acc: 81.56250 val_loss: 1.00664 val_acc: 76.25000\n",
      "[2, 9910] train_loss: 0.65351 train_acc: 82.50000 val_loss: 1.10274 val_acc: 73.12500\n",
      "[2, 9920] train_loss: 0.63540 train_acc: 82.50000 val_loss: 1.00325 val_acc: 74.37500\n",
      "[2, 9930] train_loss: 0.58027 train_acc: 84.68750 val_loss: 0.98865 val_acc: 80.00000\n",
      "[2, 9940] train_loss: 0.66654 train_acc: 82.50000 val_loss: 0.88643 val_acc: 76.87500\n",
      "Finished Runing\n"
     ]
    }
   ],
   "source": [
    "tr_loss_lis, tr_acc_lis, val_loss_lis, val_acc_lis = trainNN (model , lossFunc, optimizer , epochs , train_loader , val_loader , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model weights\n",
    "torch.save(model.state_dict(), 'Saved weights/FFNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the progress\n",
    "with open(\"FFNN Acc and Loss.txt\", \"w\") as file:\n",
    "    file.write(str(tr_loss_lis)+'seperator')\n",
    "    file.write(str(tr_acc_lis)+'seperator')\n",
    "    file.write(str(val_loss_lis)+'seperator')\n",
    "    file.write(str(val_acc_lis)+'seperator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#that's the code to get the progress numbers again...just uncomment and use it\n",
    "\"\"\"\n",
    "with open(\"FFNN Acc and Loss.txt\", \"r\") as file:\n",
    "    nums = file.read()\n",
    "    \n",
    "tr_loss_lis, tr_acc_lis, val_loss_lis, val_acc_lis = nums.split('seperator')[0:4]\n",
    "tr_loss_lis = [float(re.findall(r'\\d+\\.\\d+' , num)[0]) for num in tr_loss_lis.split(',')]\n",
    "tr_acc_lis = [float(re.findall(r'\\d+\\.\\d+' , num)[0]) for num in tr_acc_lis.split(',')]\n",
    "val_loss_lis = [float(re.findall(r'\\d+\\.\\d+' , num)[0]) for num in val_loss_lis.split(',')]\n",
    "val_acc_lis = [float(re.findall(r'\\d+\\.\\d+' , num)[0]) for num in val_acc_lis.split(',')]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tr_loss_lis = np.array(tr_loss_lis).reshape(-1 , 10).mean(axis = 1) / 10\n",
    "new_val_loss_lis = np.array(val_loss_lis).reshape(-1 , 10).mean(axis = 1) / 10\n",
    "\n",
    "new_tr_acc_lis = 100 * np.array(tr_acc_lis).reshape(-1 , 10).mean(axis = 1) /10\n",
    "new_val_acc_lis = 100 * np.array(val_acc_lis).reshape(-1 , 10).mean(axis = 1) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23a38da15f8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (10,7))\n",
    "plt.grid(True)\n",
    "plt.plot(np.array(new_tr_loss_lis),'b',label='training loss')\n",
    "plt.plot(np.array(new_val_loss_lis),'orange',label='val loss')\n",
    "plt.xlabel('mini_batches through the training')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23a3a0f8400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (10,7))\n",
    "plt.grid(True)\n",
    "plt.plot(new_tr_acc_lis,'b',label='training accuracy')\n",
    "plt.plot(new_val_acc_lis,'orange',label='val accuracy')\n",
    "plt.xlabel('mini_batches through the training')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
